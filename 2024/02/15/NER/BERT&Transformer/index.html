<!-- build time:Thu Feb 15 2024 15:20:17 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="白骨生花" href="http://qiji5211.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="白骨生花" href="http://qiji5211.com/atom.xml"><link rel="alternate" type="application/json" title="白骨生花" href="http://qiji5211.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="NER"><link rel="canonical" href="http://qiji5211.com/2024/02/15/NER/BERT&Transformer/"><title>BERT & Transformer & CRF - NER | Alive = 白骨生花 = 嘿，来啦来啦！</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">BERT & Transformer & CRF</h1><div class="meta"><span class="item" title="创建时间：2024-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-02-15T00:00:00+08:00">2024-02-15</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Alive</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/wsKH9.webp"></li><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/whzBJ.webp"></li><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/wx2u9.webp"></li><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/whhlt.webp"></li><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/wsd6T.webp"></li><li class="item" data-background-image="https://i.imgs.ovh/2023/12/03/wsMqd.webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/NER/" itemprop="item" rel="index" title="分类于 NER"><span itemprop="name">NER</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://qiji5211.com/2024/02/15/NER/BERT&Transformer/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="奇冀"><meta itemprop="description" content="嘿，来啦来啦！, 同行者，拿起火把！"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="白骨生花"></span><div class="body md" itemprop="articleBody"><h1 id="bert"><a class="anchor" href="#bert">#</a> BERT</h1><h2 id="什么是bert"><a class="anchor" href="#什么是bert">#</a> 什么是 BERT</h2><ul><li>BERT 是 2018 年 10 月由 Google Al 研究院提出的一种预训练模型</li><li>BERT 的全称是 Bidirectional Encoder Representation from Transformers</li><li>BERT 在机器阅读理解顶级水平测试 SQuAD1.1 中表现出惊人的成绩：全部两个衡量指标上全面超越人类，并且在 11 种不同 NLP 测试中创出 S0TA 表现。包括将 GLUE 基准推高至 80.4%<br>(绝对改进 7.6%)，MultiNL 准确度达到 86.7%（绝对改进 5.6%）. 成为 NLP 发展史上的里程碑式的模型成就</li></ul><h2 id="bert的架构"><a class="anchor" href="#bert的架构">#</a> BERT 的架构</h2><p>总体架构：如下图所示，最左边的就是 BERT 的架构图，可以很清楚的看到 BERT 采用了<br>Transformer Encoder block 进行连接，因为是一个典型的双向编码模型。</p><p><img data-src="https://i0.imgs.ovh/2024/02/14/oHQFl.png" alt="tu" title="BERT的架构"></p><ul><li>从上面的架构图中可以看到，宏观上 BERT 分三个主要模块：<ul><li>最底层黄色标记的 Embedding 模块</li><li>中间层蓝色标记的 Transformer 模块</li><li>最上层绿色标记的预微调模块</li></ul></li></ul><h3 id="embedding模块"><a class="anchor" href="#embedding模块">#</a> Embedding 模块</h3><p>BERT 中的该模块是由三种 Embedding 共同组成而成，如下图:</p><p><img data-src="https://i0.imgs.ovh/2024/02/14/oHRhd.png" alt="tu" title="Embedding模块"></p><ul><li>Token Embeddings 是词嵌入张量，第一个单词是 CLS 标志，可以用于之后的分类任务</li><li>Segment Embeddings 是句子分段嵌入张量，是为了服务后续的两个句子为输入的预训练任务</li><li>Position Embeddings 是位置编码张量，此处注意和传统的 Transformer 不同，不是三角函数计算的固定位置编码，而是通过学习得出来的</li><li>整个 Embedding 模块的输出张量就是这 3 个张量的直接加和结果</li></ul><h3 id="双向transformer模块"><a class="anchor" href="#双向transformer模块">#</a> 双向 Transformer 模块</h3><p>BERT 中只使用了经典 Transformer 架构中的 Encoder 部分，完全舍弃了 Decoder 部分，而两大预训练任务也集中体现在训练 Transformer 模块中。</p><h3 id="预微调模块"><a class="anchor" href="#预微调模块">#</a> 预微调模块</h3><p>经过中间层 Transformer 的处理后，BERT 的最后一层根据任务的不同需求而做不同的调整<br>即可，比如对于 sequence-levelf 的分类任务，BERT 直接取第一个 [CLS] token 的 final hidden state, 再加一层全连接层后进行 softmax 来预测最终的标签。</p><blockquote><p>对于不同的任务，微调都集中在预微调模块，几种重要的 NLP 微调任务架构图展示如下</p></blockquote><p><img data-src="https://i0.imgs.ovh/2024/02/14/oHt6j.png" alt="tu"><br><img data-src="https://i0.imgs.ovh/2024/02/14/oHgP2.png" alt="tu" title="预微调模块"></p><p>从上图中可以发现，在面对特定任务时，只需要对预微调层进行微调，就可以利用 Transformer 强大的注意力机制来模拟很多下游任务，并得到 SOTA 的结果.（句子对关系判断，单文本主题分类，问答任务 —— 句子理解 (QA), 单句贴标签 (NER)。</p><p>若干可选的超参数建议如下</p><figure class="highlight raw"><figcaption data-lang=""></figcaption><table><tr><td data-num="1"></td><td><pre>Batch size:16,32</pre></td></tr><tr><td data-num="2"></td><td><pre>Learning rate (Adam):5e-5,3e-5,2e-5</pre></td></tr><tr><td data-num="3"></td><td><pre>Epochs:3,4</pre></td></tr></table></figure><h2 id="bert的预训练任务"><a class="anchor" href="#bert的预训练任务">#</a> BERT 的预训练任务</h2><p>BERT 包含两个预训练任务</p><ul><li>任务一：Masked LM (带 mask 的语言模型训练)</li><li>任务二：Next Sentence Prediction (下一句话预测任务)</li></ul><h3 id="任务一masked-lm带mask的语言模型训练"><a class="anchor" href="#任务一masked-lm带mask的语言模型训练">#</a> 任务一：Masked LM (带 mask 的语言模型训练)</h3><blockquote><p>关于传统的语言模型训练，都是采用 left-to-right, 或者 left-to-right+right-to-left 结合的方式，但这种单向方式或者拼接的方式提取特征的能力有限。为此 BET 提出一个深度双向表达模型 (deep bidirectional representation). 即采用 MASK 任务来训练模型。</p></blockquote><ul><li>在原始训练文本中，随机的抽取 15% 的 tokn 作为参与 MASK 任务的对象。</li><li>在这些被选中的 tokn 中，数据生成器并不是把它们全部变成 [MASK], 而是有下列 3 种情<br>况。<ul><li>在 80% 的概率下，用 MASK 标记替换该 token, 比如 my dog is hairy&gt;my dog is<br>[MASK]</li><li>在 10% 的概率下，用一个随机的单词替换 token, 比如 my dog is hairy&gt;my dog is<br>apple。</li><li>在 10% 的概率下，保持该 token 不变，比如 my dog is hairy-&gt;my dog is hairy。</li></ul></li><li>模型在训练的过程中，并不知道它将要预测哪些单词？哪些单词是原始的样子？哪些单词被遮掩成了 [MASK]? 哪些单词被替换成了其他单词？正是在这样一种高度不确定的情况下，反倒逼着模型快速学习该 tokn 的分布式上下文的语义，尽最大努力学习原始语言说话的样子。同时因为原始文本中只有 15% 的 tokn 参与了 MASK 操作，并不会破坏原语言的表达能力和语言规则。</li></ul><h3 id="任务二next-sentence-prediction下一句话预测任务"><a class="anchor" href="#任务二next-sentence-prediction下一句话预测任务">#</a> 任务二：Next Sentence Prediction (下一句话预测任务)</h3><blockquote><p>在 NLP 中有一类重要的问题比如 QA (Quention-Answer),NLI (Natural Language Inference), 需要模型能够很好的理解两个句子之间的关系，从而需要在模型的训练中引入对应的任务，在 BERT 中引入的就是 Next Sentence Prediction 任务。采用的方式是输入句子对 (A,B), 模型来预测句子 B 是不是句子 A 的真实的下一句话。</p></blockquote><ul><li>所有参与任务训练的语句都被选中作为句子 A。<ul><li>其中 50% 的 B 是原始文本中真实跟随 A 的下一句话。（标记为 IsNext, 代表正样本）</li><li>其中 50% 的 B 是原始文本中随机抽取的一句话。（标记为 NotNext, 代表负样本）</li></ul></li><li>在任务二中，BERT 模型可以在测试集上取得 97%-98% 的准确率。</li></ul><h1 id="transformer"><a class="anchor" href="#transformer">#</a> Transformer</h1><h2 id="encoder模块"><a class="anchor" href="#encoder模块">#</a> Encoder 模块</h2><h3 id="encoder模块的结构和作用"><a class="anchor" href="#encoder模块的结构和作用">#</a> Encoder 模块的结构和作用</h3><ul><li>经典的 Transformer 结构中的 Encoder 模块包含 6 个 Encoder Block</li><li>每个 Encoder Block 包含一个多头自注意力层，和一个前馈全连接层，</li></ul><h3 id="关于encoder-block"><a class="anchor" href="#关于encoder-block">#</a> 关于 Encoder Block</h3><p>在 Transformer 架构中，6 个一模一样的 Encoder Block 层层堆叠在一起，共同组成完整的 Encoder, 因此剖析一个 Block 就可以对整个 Encoder 的内部结构有清晰的认识。</p><h3 id="多头自注意力层self-attention"><a class="anchor" href="#多头自注意力层self-attention">#</a> 多头自注意力层 (self-attention)</h3><ul><li>self-attention 的计算规则图：</li></ul><p><img data-src="https://i0.imgs.ovh/2024/02/14/oHUMJ.png" alt="tu" title="self-attention的计算规则图"></p><blockquote><p>上述 attention 可以被描述为将 quey 和 key-value 键值对的一组集合映射到输出，输出被计算为 values 的加权和，其中分配给每个 value 的权重由 quey 与对应 key 的相似性函数计算得来。这种 attention 的形式被称为 Scaled Dot-Product Attention, 对应的数学公式形式如下：</p></blockquote><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.448331em;vertical-align:-.93em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em"><span style="top:-2.25278em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.85722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.18278000000000005em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span></span></p><p><img data-src="https://i0.imgs.ovh/2024/02/14/oHjdv.png" alt="tu" title="self-attention的计算规则图"></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">\text{MultiHead}(Q,K,V)= Concat (head_1,...,head_h)W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">MultiHead</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">O</span></span></span></span></span></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>w</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>e</mi><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mrow><mo fence="true">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator="true">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">where head_i = Attention \left(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-.65002em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">(</span></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9592389999999998em"><span style="top:-2.4231360000000004em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">)</span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo separator="true">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo separator="true">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mi>v</mi></msub></mrow></msup><mo separator="true">,</mo><msup><mi>W</mi><mi>O</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>h</mi><msub><mi>d</mi><mi>v</mi></msub><mo>×</mo><msub><mi>d</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W_i^Q\in\mathbb{R}^{d_{\mathrm{model}}\times d_k},W_i^K\in\mathbb{R}^{d_{\mathrm{model}}\times d_k},W_i^V\in\mathbb{R}^{d_{\mathrm{model}}\times d_v},W^O\in\mathbb{R}^{hd_v\times d_{\mathrm{model}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-.276864em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9592389999999998em"><span style="top:-2.4231360000000004em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.180908em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-.247em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">m</span><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">d</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">l</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.146108em;vertical-align:-.247em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">m</span><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">d</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">l</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0935479999999997em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">m</span><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">d</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">l</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">O</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8991079999999998em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991079999999998em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">m</span><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">d</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">l</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><blockquote><p>多头 self-attention, 层的作用：实验结果表明，Multi--head 可以在更细致的层面上提取不同 head 的特征，总体计算量和单一 head 相同的情况下，提取特征的效果更佳。</p></blockquote><h3 id="前馈全连接层模块"><a class="anchor" href="#前馈全连接层模块">#</a> 前馈全连接层模块</h3><p>前馈全连接层模块，由两个线性变换组成，中间有一个 Relu 激活函数（max ()），对应的数学公式形式如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">N</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo fence="true">)</mo></mrow><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{FFN}(x)=\max\left(0,xW_1+b_1\right)W_2+b_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">F</span><span class="mord mathrm">F</span><span class="mord mathrm">N</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><ul><li>注意：原版论文中的前馈全连接层，输入和输出的维度均为 d_model=512, 层内的连接维度 df 仟 = 2048，均采用 4 倍的大小关系。</li></ul><blockquote><p>前馈全连接层的作用：单纯的多头注意力机制并不足以提取到理想的特征，因此增加全连接层来提升网络的能力。</p></blockquote><h2 id="剩下的视频看完了还在写"><a class="anchor" href="#剩下的视频看完了还在写">#</a> 剩下的视频看完了还在写……</h2><h1 id="crf"><a class="anchor" href="#crf">#</a> CRF</h1><h2 id="crf模型的输入和输出"><a class="anchor" href="#crf模型的输入和输出">#</a> CRF 模型的输入和输出</h2><p>CRF (Conditional Random Fields), 中文称作条件随机场，同 HMM 一样，它一般也以文本序列数据为输入，以该序列对应的隐含序列为输出。</p><h2 id="crf模型的作用"><a class="anchor" href="#crf模型的作用">#</a> CRF 模型的作用：</h2><p>同 HMM 一样，在 NLP 领域，CRF 用来解决文本序列标注问题。如分词，词性标注，命名实体识别。</p><h2 id="crf模型使用过程简述"><a class="anchor" href="#crf模型使用过程简述">#</a> CRF 模型使用过程简述</h2><ul><li>首先，CRF 模型表示为：lambda=CRF (w1,w2,,wn), 其中 w1 到 wn 是模型参数</li><li>接着，我们开始训练 CRF 模型，语料同样是事先准备好的一定数量的观测序列及其对应的隐含序列</li><li>与此同时我们还需要做人工特征工程，然后通过不断训练求得一组参数，使由观测序列到对应隐含序列的概率最大</li><li>训练后，我们就得到了具备预测能力的新模型：lambda=CRF (w1,w2,.,wn), 其中的模型参数已经改变</li><li>之后给定输入序列 (x1,x2,,n), 经过模型计算 lambda (x1,x2,,n) 得到对应隐含序列的<br>条件概率分布</li><li>最后，还是使用维特比算法从隐含序列的条件概率分布中找出概率最大的一条序列路径就是我们需要的隐含序列：(y1,y2,,yn)</li></ul><h2 id="hmm与crf模型之间差异"><a class="anchor" href="#hmm与crf模型之间差异">#</a> HMM 与 CRF 模型之间差异</h2><ul><li>HMM 模型存在隐马假设，而 CRF 不存在，因此 HMM 的计算速度要比 CRF 模型快很多，适用于对预测性能要求较高的场合</li><li>同样因为隐马假设，当预测问题中隐含序列单元并不是只与上一个单元有关时，HMM 的准确率会大大降低，而 CRF 不受这样限制，准确率明显高于 HMM</li></ul><h2 id="hmm和crf的发展现状"><a class="anchor" href="#hmm和crf的发展现状">#</a> HMM 和 CRF 的发展现状</h2><ul><li>HMM 和 CRF 模型曾在多种序列任务中表现出色，伴随 NLP 工程师度过漫长的一段时期</li><li>但由于近年来深度学习发展迅速，经典序列模型，如 HMM 和 CRE 已经开始慢慢淡出人们的<br>视野</li><li>因此，我们这里也是对其做了简洁的总结知识，让大家对其有一定的基本认识</li></ul><div class="tags"><a href="/tags/NER/" rel="tag"><i class="ic i-tag"></i> NER</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-02-15 15:20:02" itemprop="dateModified" datetime="2024-02-15T15:20:02+08:00">2024-02-15</time> </span><span id="2024/02/15/NER/BERT&Transformer/" class="item leancloud_visitors" data-flag-title="BERT & Transformer & CRF" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="奇冀 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="奇冀 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="奇冀 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>奇冀 <i class="ic i-at"><em>@</em></i>白骨生花</li><li class="link"><strong>本文链接：</strong> <a href="http://qiji5211.com/2024/02/15/NER/BERT&Transformer/" title="BERT &amp; Transformer &amp; CRF">http://qiji5211.com/2024/02/15/NER/BERT&Transformer/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2024/02/15/NER/RNN%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;i.imgs.ovh&#x2F;2023&#x2F;12&#x2F;03&#x2F;wsjhN.webp" title="RNN模型"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> NER</span><h3>RNN模型</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#bert"><span class="toc-number">1.</span> <span class="toc-text">BERT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFbert"><span class="toc-number">1.1.</span> <span class="toc-text">什么是 BERT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bert%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">BERT 的架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#embedding%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.1.</span> <span class="toc-text">Embedding 模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8C%E5%90%91transformer%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.2.</span> <span class="toc-text">双向 Transformer 模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.3.</span> <span class="toc-text">预微调模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bert%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.</span> <span class="toc-text">BERT 的预训练任务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E4%B8%80masked-lm%E5%B8%A6mask%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.3.1.</span> <span class="toc-text">任务一：Masked LM (带 mask 的语言模型训练)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E4%BA%8Cnext-sentence-prediction%E4%B8%8B%E4%B8%80%E5%8F%A5%E8%AF%9D%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.2.</span> <span class="toc-text">任务二：Next Sentence Prediction (下一句话预测任务)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer"><span class="toc-number">2.</span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#encoder%E6%A8%A1%E5%9D%97"><span class="toc-number">2.1.</span> <span class="toc-text">Encoder 模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#encoder%E6%A8%A1%E5%9D%97%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E4%BD%9C%E7%94%A8"><span class="toc-number">2.1.1.</span> <span class="toc-text">Encoder 模块的结构和作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E4%BA%8Eencoder-block"><span class="toc-number">2.1.2.</span> <span class="toc-text">关于 Encoder Block</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%A4%B4%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%B1%82self-attention"><span class="toc-number">2.1.3.</span> <span class="toc-text">多头自注意力层 (self-attention)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E9%A6%88%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%A8%A1%E5%9D%97"><span class="toc-number">2.1.4.</span> <span class="toc-text">前馈全连接层模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%A9%E4%B8%8B%E7%9A%84%E8%A7%86%E9%A2%91%E7%9C%8B%E5%AE%8C%E4%BA%86%E8%BF%98%E5%9C%A8%E5%86%99"><span class="toc-number">2.2.</span> <span class="toc-text">剩下的视频看完了还在写……</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#crf"><span class="toc-number">3.</span> <span class="toc-text">CRF</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#crf%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA"><span class="toc-number">3.1.</span> <span class="toc-text">CRF 模型的输入和输出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#crf%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">3.2.</span> <span class="toc-text">CRF 模型的作用：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#crf%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E7%AE%80%E8%BF%B0"><span class="toc-number">3.3.</span> <span class="toc-text">CRF 模型使用过程简述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hmm%E4%B8%8Ecrf%E6%A8%A1%E5%9E%8B%E4%B9%8B%E9%97%B4%E5%B7%AE%E5%BC%82"><span class="toc-number">3.4.</span> <span class="toc-text">HMM 与 CRF 模型之间差异</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hmm%E5%92%8Ccrf%E7%9A%84%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6"><span class="toc-number">3.5.</span> <span class="toc-text">HMM 和 CRF 的发展现状</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/" rel="bookmark" title="pytorch安装环境问题">pytorch安装环境问题</a></li><li><a href="/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/" rel="bookmark" title="文本预处理">文本预处理</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/03%20%E4%BB%80%E4%B9%88%E6%98%AF%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88Transformer%20%E5%89%8D%E5%A5%8F%EF%BC%89/" rel="bookmark" title="什么是预训练（Transformer 前奏）">什么是预训练（Transformer 前奏）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/04%20%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88n%E5%85%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89/" rel="bookmark" title="统计语言模型（n元语言模型）">统计语言模型（n元语言模型）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/05%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81+%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E8%B5%B7%E6%BA%90%EF%BC%89/" rel="bookmark" title="神经网络语言模型（独热编码+词向量的起源）">神经网络语言模型（独热编码+词向量的起源）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/06%20Word2Vec%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%93%E9%97%A8%E5%81%9A%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8CCBOW%E5%92%8CSkip-gram%EF%BC%89/" rel="bookmark" title="Word2Vec模型（第一个专门做词向量的模型，CBOW和Skip-gram）">Word2Vec模型（第一个专门做词向量的模型，CBOW和Skip-gram）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/00%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E5%85%A8%E6%96%87%2024854%20%E4%B8%AA%E8%AF%8D%EF%BC%89/" rel="bookmark" title="预训练语言模型的前世今生">预训练语言模型的前世今生</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/07%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E6%94%B9%E9%80%A0%E7%AE%80%E4%BB%8B%EF%BC%88%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%EF%BC%89/" rel="bookmark" title="预训练语言模型的下游任务改造简介（如何使用词向量）">预训练语言模型的下游任务改造简介（如何使用词向量）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/Transformer/" rel="bookmark" title="Transformer">Transformer</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88Attention%20%EF%BC%89/" rel="bookmark" title="注意力机制（Attention ）">注意力机制（Attention ）</a></li><li><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/08%20ELMo%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%8F%8C%E5%90%91LSTM%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E8%AF%8D%E5%90%91%E9%87%8F%E5%A4%9A%E4%B9%89%E9%97%AE%E9%A2%98%EF%BC%89/" rel="bookmark" title="ELMo模型（双向LSTM模型解决词向量多义问题）">ELMo模型（双向LSTM模型解决词向量多义问题）</a></li><li class="active"><a href="/2024/02/15/NER/BERT&Transformer/" rel="bookmark" title="BERT & Transformer & CRF">BERT & Transformer & CRF</a></li><li><a href="/2024/02/15/NER/RNN%E6%A8%A1%E5%9E%8B/" rel="bookmark" title="RNN模型">RNN模型</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="奇冀" data-src="/images/avatar.jpg"><p class="name" itemprop="name">奇冀</p><div class="description" itemprop="description">同行者，拿起火把！</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">25</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">10</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">9</span> <span class="name">标签</span></a></div></nav><div class="social"><a href="https://qiji5211.com/yourname" title="https:&#x2F;&#x2F;qiji5211.com&#x2F;yourname" class="item github"><i class="ic i-github"></i></a> <span class="exturl item bilibili" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMTUwOTU1MzIzOD9zcG1faWRfZnJvbT0zMzMuMTAwNy4wLjA=" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;1509553238?spm_id_from&#x3D;333.1007.0.0"><i class="ic i-bilibili"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS85Ni0xNy01Ni00Nw==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;96-17-56-47"><i class="ic i-zhihu"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjk3MjQ3Nzg2N0BxcS5jb20=" title="mailto:972477867@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友链</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/NER/" title="分类于 NER">NER</a></div><span><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/00%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E5%85%A8%E6%96%87%2024854%20%E4%B8%AA%E8%AF%8D%EF%BC%89/" title="预训练语言模型的前世今生">预训练语言模型的前世今生</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/qianduan/" title="分类于 前端学习">前端学习</a> <i class="ic i-angle-right"></i> <a href="/categories/qianduan/VUE/" title="分类于 Vue3">Vue3</a></div><span><a href="/2023/11/23/qianduan/VUE/Vue3%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Vue3快速上手">Vue3快速上手</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/NER/" title="分类于 NER">NER</a></div><span><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/Transformer/" title="Transformer">Transformer</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/qianduan/" title="分类于 前端学习">前端学习</a> <i class="ic i-angle-right"></i> <a href="/categories/qianduan/JS/" title="分类于 JS">JS</a></div><span><a href="/2023/11/23/qianduan/JS/JS%E9%AB%98%E7%BA%A7/" title="JavaScript高级教程">JavaScript高级教程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/jike/" title="分类于 计科资料">计科资料</a></div><span><a href="/2023/11/23/jike/%E6%8F%90%E9%97%AE%E7%9A%84%E6%99%BA%E6%85%A7/" title="提问的智慧">提问的智慧</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/qi/" title="分类于 奇闻异事">奇闻异事</a></div><span><a href="/2023/11/23/qi/%E5%A4%A7%E5%88%9B%E9%A1%B9%E7%9B%AE%E5%90%88%E9%9B%86/" title="大创项目合集">大创项目合集</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/NER/" title="分类于 NER">NER</a></div><span><a href="/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/" title="pytorch安装环境问题">pytorch安装环境问题</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%AB%99%E7%82%B9%E6%90%AD%E5%BB%BA/" title="分类于 站点搭建">站点搭建</a></div><span><a href="/2023/11/23/zhan/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99%E7%9A%84%E6%90%AD%E5%BB%BA/" title="关于本站的搭建">关于本站的搭建</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/qianduan/" title="分类于 前端学习">前端学习</a> <i class="ic i-angle-right"></i> <a href="/categories/qianduan/JS/" title="分类于 JS">JS</a> <i class="ic i-angle-right"></i> <a href="/categories/qianduan/JS/mo/" title="分类于 模块化">模块化</a></div><span><a href="/2023/11/23/qianduan/JS/mo/%E6%A8%A1%E5%9D%97%E5%8C%96_%E7%AC%94%E8%AE%B0/" title="JS模块化（简版）">JS模块化（简版）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/qianduan/" title="分类于 前端学习">前端学习</a> <i class="ic i-angle-right"></i> <a href="/categories/qianduan/TSs/" title="分类于 TS">TS</a></div><span><a href="/2023/11/23/qianduan/TSs/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" title="TypeScript教程">TypeScript教程</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">奇冀 @ Alive</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">196k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">2:59</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2024/02/15/NER/BERT&Transformer/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->