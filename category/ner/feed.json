{
    "version": "https://jsonfeed.org/version/1",
    "title": "白骨生花 • All posts by \"ner\" category",
    "description": "同行者，拿起火把！",
    "home_page_url": "http://qiji5211.com",
    "items": [
        {
            "id": "http://qiji5211.com/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/",
            "url": "http://qiji5211.com/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/",
            "title": "pytorch安装环境问题",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"自己安\"><a class=\"anchor\" href=\"#自己安\">#</a> 自己安</h1>\n<p>突然兴起想重装 Anaconda 和 Pycharm, 好家伙，整整两天才给全部整明白，最大的原因见文末，在此记录一下我踩的坑。</p>\n<p>参考【PyTorch 深度学习快速入门教程（绝对通俗易懂！）【小土堆】】 <span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWhFNDExdDdSTi8/c2hhcmVfc291cmNlPWNvcHlfd2ViJmFtcDt2ZF9zb3VyY2U9NGJkODUyZjgzNGYyZDlhNmE4Y2UwNjA5YTM2MDAxZDQ=\">https://www.bilibili.com/video/BV1hE411t7RN/?share_source=copy_web&amp;vd_source=4bd852f834f2d9a6a8ce0609a36001d4</span></p>\n<p>Anaconda（ <code>Anaconda3-2023.09-0-Windows-x86 64.exe</code> ）,pycharm，pytorch 已下好且 pytorch（本机没有满足要求的 GPU，选的 CPU）可正常激活，中文路径问题可参考 CSDN 通过配置环境变量解决，仅最后一步不对。</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>(pytorch) PS C:\\Users\\ 王越洋 &gt; python</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)] on win32</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>&gt;&gt;&gt; import torch</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>&gt;&gt;&gt;</pre></td></tr></table></figure><p>但配置时报错如下：</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py:21: UserWarning: mkl-service package failed to import, therefore Intel (R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http:&#x2F;&#x2F;github.com&#x2F;IntelPython&#x2F;mkl-service</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Traceback (most recent call last):</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\__init__.py&quot;, line 22, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    from . import multiarray</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\multiarray.py&quot;, line 12, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    from . import overrides</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\overrides.py&quot;, line 7, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    from numpy.core._multiarray_umath import (</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>ImportError: DLL load failed: 找不到指定的模块。</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>During handling of the above exception, another exception occurred:</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>Traceback (most recent call last):</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\code.py&quot;, line 91, in runcode</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    exec (code, self.locals)</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\__init__.py&quot;, line 613, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    _C._initExtension (manager_path ())</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py&quot;, line 685, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    from . import amp</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\__init__.py&quot;, line 1, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    from .autocast_mode import autocast, custom_fwd, custom_bwd  # noqa: F401</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py&quot;, line 5, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    import numpy as np</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\__init__.py&quot;, line 140, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    from . import core</pre></td></tr><tr><td data-num=\"42\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"44\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\__init__.py&quot;, line 48, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"45\"></td><td><pre>    raise ImportError (msg)</pre></td></tr><tr><td data-num=\"46\"></td><td><pre>ImportError: </pre></td></tr><tr><td data-num=\"47\"></td><td><pre>IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!</pre></td></tr><tr><td data-num=\"48\"></td><td><pre>Importing the numpy C-extensions failed. This error can happen for</pre></td></tr><tr><td data-num=\"49\"></td><td><pre>many reasons, often due to issues with your setup or how NumPy was</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>installed.</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>We have compiled some common reasons and troubleshooting tips at:</pre></td></tr><tr><td data-num=\"52\"></td><td><pre>    https:&#x2F;&#x2F;numpy.org&#x2F;devdocs&#x2F;user&#x2F;troubleshooting-importerror.html</pre></td></tr><tr><td data-num=\"53\"></td><td><pre>Please note and check the following:</pre></td></tr><tr><td data-num=\"54\"></td><td><pre>  * The Python version is: Python3.6 from &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\python.exe&quot;</pre></td></tr><tr><td data-num=\"55\"></td><td><pre>  * The NumPy version is: &quot;1.19.2&quot;</pre></td></tr><tr><td data-num=\"56\"></td><td><pre>and make sure that they are the versions you expect.</pre></td></tr><tr><td data-num=\"57\"></td><td><pre>Please carefully study the documentation linked above for further help.</pre></td></tr><tr><td data-num=\"58\"></td><td><pre>Original error was: DLL load failed: 找不到指定的模块。</pre></td></tr></table></figure><p><s>初步怀疑问题在于</s>（是小白没错了，后面人家说和这个没关系，看到这个报错的 uu 不要惊慌）</p>\n<p>但当时我不知道啊，遂运行提示命令，无果，约半小时后提示某文件没有 admission，CSDN 有文指出该问题可以重新更新 conda，下载一小时没下完。两个都运行了两次左右，各种重装 Anaconda，结果人家输出我没有 admission，如果你和我一样装 Anaconda 时选的 <code>给所有人装</code> 的选项，记得在权限里设置 <code>所有人可修改</code> 即可解决。当然，不设置也可以。</p>\n<p>最后，这个错无伤大雅，重点不在这，不要运行 <code>conda update -n base -c defaults conda</code>  就是了。</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>(pytorch) PS C:\\Users\\ 王越洋 &gt; conda install pytorch torchvision torchaudio cpuonly -c pytorch</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Collecting package metadata (current_repodata.json): done</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Solving environment: done</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>&#x3D;&#x3D;&gt; WARNING: A newer version of conda exists. &lt;&#x3D;&#x3D;</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  current version: 23.7.4</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  latest version: 24.1.0</pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>Please update conda by running</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    $ conda update -n base -c defaults conda</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>Or to minimize the number of packages updated during conda update use</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>     conda install conda&#x3D;24.1.0</pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre># All requested packages already installed.</pre></td></tr></table></figure><p>这个报错的意思是你有库安了，但是没安全。</p>\n<h1 id=\"深夜寻求某宝\"><a class=\"anchor\" href=\"#深夜寻求某宝\">#</a> 深夜寻求某宝</h1>\n<p>凌晨 00:23，解决无果，遂面向某宝解决（cost20￥），次日早，某阿里员工给我一波各种操作，两小时后告诉我问题是 numpy 库没安全，然后各种调试，找版本，然后安，解决！</p>\n<p>下午，感觉自己又行了，于是自己重新建了一个虚拟环境，把人家建的删了，报错依旧，重装 numpy 无果，<s>发疯发疯</s>，感觉这个人解决问题不能一劳永逸（其实是我没学会。。。人家还是很厉害滴）~</p>\n<h1 id=\"晚上寻求拼夕夕\"><a class=\"anchor\" href=\"#晚上寻求拼夕夕\">#</a> 晚上寻求拼夕夕🌟</h1>\n<p>已是晚 10：20, 继第 10 次左右重新安装调试后，随便捞了个能安的人（cost15￥），看得出来他也很焦灼，甚至还出现了新错误:</p>\n<p>(1) Environment 创建失败（这个和库没关系，是说你的源或者网络问题，建议换源即可）</p>\n<p>(2) 系统找不到指定路径。这个就比较棘手了，人家配了环境变量，各种调试，无果。通过装 <code>Anaconda3-2020.11 Windows-x86 64.exe</code> ，再来一遍 pip 配置，成功！！！</p>\n<p>通过 pip 安装就不会像通过 conda 安装报错，成功解决！！！</p>\n<p>小问题：conda 安装的虚拟环境位置在 <code>C:/User/XXX/.conda/env/</code>  下的，但这种方式安装的虚拟环境位置在 Anaconda3 的安装目录下，其他运行均正常，虽然还是会报版本不一致的错，但无碍。本次配置终于完成！！</p>\n<h1 id=\"结果\"><a class=\"anchor\" href=\"#结果\">#</a> 结果</h1>\n<p>综上，出现此类错误的人建议装低版本一点的 Anaconda (卸的时候记得用自带的工具卸，写完检查环境变量删干净没)，安装时记得把 PATH 选项勾上（要不然要自己配，容易配错），最新版的 Anaconda 应该是有小毛病（库不全），<span class=\"red\">谨慎安装！！！</span></p>\n<p>祝看到这里的各位 PyTorch 学习顺利！🌟</p>\n",
            "tags": [
                "pytorch"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/",
            "url": "http://qiji5211.com/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/",
            "title": "文本预处理",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"文本处理的基本方法\"><a class=\"anchor\" href=\"#文本处理的基本方法\">#</a> 文本处理的基本方法</h1>\n<h2 id=\"分词\"><a class=\"anchor\" href=\"#分词\">#</a> 分词</h2>\n<h3 id=\"什么是分词\"><a class=\"anchor\" href=\"#什么是分词\">#</a> 什么是分词？</h3>\n<blockquote>\n<p>分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的<br />\n行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界<br />\n符来简单划界，唯独词没有一个形式上的分界符，分词过程就是找到这样分界符的过程，</p>\n</blockquote>\n<ul>\n<li>举例：</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>女干事每月经过下属科室都</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span>，<span class=\"token string\">'每月'</span>，<span class=\"token string\">'经过'</span>，<span class=\"token string\">'下属'</span>，<span class=\"token string\">'科室'</span>，<span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><h3 id=\"分词的作用\"><a class=\"anchor\" href=\"#分词的作用\">#</a> 分词的作用</h3>\n<ul>\n<li>词作为语言语义理解的最小单元，是人类理解文本语言的基础。因此也是 AI 解决 NLP 领域高阶任务，如自动问答，机器翻译，文本生成的重要基础环节。</li>\n</ul>\n<h3 id=\"流行中文分词工具jieba\"><a class=\"anchor\" href=\"#流行中文分词工具jieba\">#</a> 流行中文分词工具 jieba</h3>\n<blockquote>\n<p>&quot;结巴&quot; 中文分词，做最好的 Python 中文分词组件。</p>\n</blockquote>\n<ul>\n<li>\n<p>jiebal 的特性：</p>\n<ul>\n<li>支持多种分词模式</li>\n<li>精确模式</li>\n<li>全模式</li>\n<li>搜索引擎摸式</li>\n<li>支持中文繁体分词</li>\n<li>支持用户自定义词典</li>\n</ul>\n</li>\n<li>\n<p>jieba 使用</p>\n</li>\n</ul>\n<blockquote>\n<p>精确模式分词：试图将句子最精确地切开，适合文本分析</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">import</span> jieba</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>默认为<span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#生成器对象</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut at <span class=\"token number\">0x000001ED13237350</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#列表内容</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>Building prefix <span class=\"token builtin\">dict</span> <span class=\"token keyword\">from</span> the default dictionary <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>Dumping model to <span class=\"token builtin\">file</span> cache C<span class=\"token punctuation\">:</span>\\WINDOWS\\TEMP\\jieba<span class=\"token punctuation\">.</span>cache</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>Loading model cost <span class=\"token number\">0.607</span> seconds<span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>Prefix <span class=\"token builtin\">dict</span> has been built successfully<span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>Out<span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>全模式分词：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能消除歧义。</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut at <span class=\"token number\">0x000001ED13237D60</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre> <span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'月经'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>搜索引擎模式分词：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut_for_search at <span class=\"token number\">0x000001ED14A014A0</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>中文繁体分词：针对中国香港，台湾地区的繁体文本进行分词</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"烦惱即是菩提，我暂且不提\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token punctuation\">[</span><span class=\"token string\">'烦惱'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'即'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'是'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'菩提'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'，'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'我'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'暂且'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'不提'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>使用用户自定义词典</p>\n</blockquote>\n<ul>\n<li>添加自定义词典后，jieba 能够准确识别词典中出现的词汇，提升整体的识别准确率，</li>\n<li>词典格式：每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开<br />\n顺序不可颠倒</li>\n<li>词典样式如下，具体词性含义请参照附录：jieba 词性对照表，将该词典存 userdict.txt, 方便之后加载使用。</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>云计算5n</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>李小福2nr</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>easy_install <span class=\"token number\">3</span> eng</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>好用<span class=\"token number\">300</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>韩玉赏鉴3nZ</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>八一双鹿3nz</pre></td></tr></table></figure><hr />\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span> <span class=\"token keyword\">import</span> jieba</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>1cut<span class=\"token punctuation\">(</span><span class=\"token string\">\"八一双鹿更名为八一南昌篮球队！\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\">#没有使用用户自定义词典前的结果：</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span><span class=\"token punctuation\">[</span><span class=\"token string\">'八一双鹿'</span>，<span class=\"token string\">'更名'</span>，<span class=\"token string\">'为'</span>，<span class=\"token string\">'八一'</span>，<span class=\"token string\">'南昌'</span>，<span class=\"token string\">'篮球队'</span>，<span class=\"token string\">'!'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token operator\">>></span>jieba<span class=\"token punctuation\">.</span>load_userdict<span class=\"token punctuation\">(</span><span class=\"token string\">\"./userdict.txt\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#使用了用户自定义词典后的结果：</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'八一双鹿'</span>，<span class=\"token string\">'更名'</span>，<span class=\"token string\">'为'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'八一'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'南昌'</span>，<span class=\"token string\">'篮球队'</span>，<span class=\"token string\">'!'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><h2 id=\"命名实体识别\"><a class=\"anchor\" href=\"#命名实体识别\">#</a> 命名实体识别</h2>\n<p>顾名思义，命名实体识别 (Named Entity Recognition, 简称 NER) 就是识别出一段文本中可能存在的命名实体。</p>\n<ul>\n<li>命名实体识别的作用：</li>\n</ul>\n<p>同词汇一样，命名实体也是人类理解文本的基础单元，因此也是 A 解决 NLP 领域高阶任务的重要基础环节</p>\n<h2 id=\"词性标注\"><a class=\"anchor\" href=\"#词性标注\">#</a> 词性标注</h2>\n<blockquote>\n<p>词性：语言中对词的一种分类方法，以语法特征为主要依据、兼顾词汇意义对词进行划分的结果，常见的词性有 143 如：名词，动词，形容词等</p>\n</blockquote>\n<p>顾名思义，词性标注 (Part-Of-Speech tagging, 简称 POS) 就是标注出一段文本中每个词汇的词性。</p>\n<ul>\n<li>词性标注的作用</li>\n</ul>\n<p>词性标注以分词为基础，是对文本语言的另一个角度的理解，因此也常常成为 A 解决 NLP 领域高阶任务的重要基础环节。</p>\n<ul>\n<li>使用 jieba 进行中文词性标注</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">import</span> jieba<span class=\"token punctuation\">.</span>posseg <span class=\"token keyword\">as</span> pseg</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> pseg<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span><span class=\"token string\">\"我爱北京天安门\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>pair<span class=\"token punctuation\">(</span><span class=\"token string\">'我'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'爱'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'v'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'北京'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ns'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'天安门'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ns'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>rr<span class=\"token punctuation\">:</span>人称代词</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>v<span class=\"token punctuation\">:</span>动词</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>n<span class=\"token punctuation\">:</span>名词</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>vn<span class=\"token punctuation\">:</span>动名词</pre></td></tr></table></figure><h1 id=\"文本张量表示方法\"><a class=\"anchor\" href=\"#文本张量表示方法\">#</a> 文本张量表示方法</h1>\n<ul>\n<li>什么是文本张量表示</li>\n</ul>\n<p>将一段文本使用张量进行表示，其中一般将词汇为表示成向量，称作词向量，再由各个词向量按顺序组成矩阵形成文本表示。</p>\n<p>举个栗子</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">\"人生\"</span>，<span class=\"token string\">\"该\"</span>，<span class=\"token string\">\"如何\"</span>，<span class=\"token string\">\"起头\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#每个词对应矩阵中的一个向量</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">3.1</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.43</span><span class=\"token punctuation\">,</span><span class=\"token number\">0.34</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">3.21</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.32</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">2.54</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.12</span><span class=\"token punctuation\">,</span><span class=\"token number\">9.54</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ul>\n<li>文本张量表示的作用</li>\n</ul>\n<p>将文本表示成张量（矩阵）形式，能够使语言文本可以作为计算机处理程序的输入，进行接下来一系列的解析工作。</p>\n<blockquote>\n<ul>\n<li>文本张量表示的方法：\n<ul>\n<li>one-hot 编码</li>\n<li>Word2vec</li>\n<li>Word Embedding</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h2 id=\"one-hot独热编码\"><a class=\"anchor\" href=\"#one-hot独热编码\">#</a> one-hot (独热编码)</h2>\n<ul>\n<li>什么是 one-hot (独热编码) 词向量表示</li>\n</ul>\n<p>又称独热编码，将每个词表示成具有个元素的向量，这个词向量中只有一个元素是 1，其他元素都是 0，不同词汇元素为 0 的位置不同，其中的大小是整个语料中不同词汇的总数。</p>\n<p>举个栗子</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">\"改变\"</span>，<span class=\"token string\">\"要\"</span>，<span class=\"token string\">\"如何\"</span>，<span class=\"token string\">\"起手\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ul>\n<li>实现</li>\n</ul>\n<ol>\n<li>进行 one-hot (独热编码)</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#导入用于对象保存与加载的 job11b</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>externals <span class=\"token keyword\">import</span> joblib</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#导入 keras 中的词汇映射器 Tokenizer</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> Tokenizer</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#假定 vocab 为语料集所有不同词汇集合</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>vocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"周杰伦\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"陈奕迅\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"王力宏\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"李宗盛\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"吴亦凡\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"鹿晗\"</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\">#实例化一个词汇映射器对象</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>t <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">(</span>num_words<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>char_level<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\">#使用映射器拟合现有文本数据</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>t<span class=\"token punctuation\">.</span>fit_on_texts<span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> vocab<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    zero_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token comment\">#使用映射器转化现有文本数据，** 每个词汇对应从 1 开始的自然数</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token comment\">#返回样式如：[[2]]，取出其中的数字需要使用 [0][0]</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    token_index <span class=\"token operator\">=</span> t<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    zero_list<span class=\"token punctuation\">[</span>token_index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">,</span><span class=\"token string\">\"的one-hot编码为：\"</span><span class=\"token punctuation\">,</span>zero_list<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>李宗盛 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>王力宏 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>鹿晗 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>吴亦凡 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>陈奕迅 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>周杰伦 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\">#使用 jobl1b 工具保存映射器，以便之后使用</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>tokenizer_path <span class=\"token string\">\"./Tokenizer\"</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>joblib<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">,</span>tokenizer_path<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><div class=\"note danger\">\n<p>注意！！！ 务必用 conda 安装 tensorflow, 会自动匹配对应的版本，pip 会有不兼容问题。<br />\ncpu 的直接 <code>conda install tensorflow</code>  即可，不要指定版本，会找不到包。然后根据对应的报错进行 <code>conda install chardet</code> , 大功告成！</p>\n</div>\n<ol start=\"2\">\n<li>使用</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#导入用于对象保存与加载的 job11b</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>externals <span class=\"token keyword\">import</span> joblib</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#加载之前保存的 Tokenizer, 实例化一个 t 对象</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>t <span class=\"token operator\">=</span> joblib<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>tokenizer_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\">#编码 token 为 \"李宗盛\"</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>token<span class=\"token operator\">=</span><span class=\"token string\">\"李宗盛\"</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#使用 t 获得 token-index</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>token_index <span class=\"token operator\">=</span> t<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#初始化一个 zero-11st</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>zero_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\">#令 zero-L1st 的对应索引为 1</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>zero_list<span class=\"token punctuation\">[</span>token_index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">,</span><span class=\"token string\">\"的one-hot编码为：\"</span>，zero_list<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ol start=\"3\">\n<li>输出效果</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>李宗盛的one<span class=\"token operator\">-</span>hot编码为：<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ol start=\"4\">\n<li>one-hot 编码的优劣势：</li>\n</ol>\n<p>优势：摄作简单，容易理解。</p>\n<p>劣势：完全割裂了词与词之间的联系，而且在大语料集下，每个向量的长度过大，占据大量内存。</p>\n<p><span class=\"label danger\">: 说明</span></p>\n<p>正因为 one-hot 编码明显的劣势，这种编码方式被应用的地方越来越少，取而代之的是<br />\n接下来我们要学习的稠密向量的表示方法 word2vec 和 word embedding。</p>\n<h2 id=\"word2vec\"><a class=\"anchor\" href=\"#word2vec\">#</a> Word2vec</h2>\n<p>是一种流行的将词汇表示成向量的无监督训练方法，该过程将构建神经网络模型，将网络参<br />\n数作为词汇的向量表示，它包含 CBOW 和 skipgram 两种训练模式。</p>\n<h3 id=\"cbowcontinuous-bag-of-words模式\"><a class=\"anchor\" href=\"#cbowcontinuous-bag-of-words模式\">#</a> CBOW (Continuous bag of words) 模式</h3>\n<p>给定一段用于训练的文本语料，再选定某段长度（窗口）作为研究对象，使用上下文词汇预测<br />\n目标词汇。</p>\n<p><img data-src=\"https://imgloc.com/image/olDK3\" alt=\"tu\" title=\"CBOW模式\" /></p>\n<p>图中窗口大小为 9，使用前后 4 个词汇对目标词汇进行预测。</p>\n<h4 id=\"word2vec过程\"><a class=\"anchor\" href=\"#word2vec过程\">#</a> Word2vec 过程</h4>\n<p>假设我们给定的训练语料只有一句话： <code>Hope can set you free</code>  (愿你自由成长)，窗口大小为<br />\n 3, 因此模型的第一个训练样本来自 <code>Hope can set</code> , 因为是 CBOW 模式，所以将使用 <code>Hope</code>  和<br />\n <code>set</code>  作为输入， <code>can</code>  作为输出，在模型训练时， <code>Hope</code> , <code>can</code> , <code>set</code>  等词汇都使用它们的 one-hot 编码。如图所示：每个 one-hot 编码的单词与各自的变换矩阵 (即参数矩阵 3x5, 这里的 3 是指最后得到的词向量维度) 相乘之后再相加，得到上下文表示矩阵 (3x1)。</p>\n<p><img data-src=\"https://imgloc.com/image/ol8Ze\" alt=\"tu\" title=\"CBOW模式\" /></p>\n<p>接着，将上下文表示矩阵与变换矩阵（参数矩阵 5x3, 所有的变换矩阵共享参数）相乘，得到 5x1 的结果矩阵，它将与我们真正的目标矩阵即 can 的 one-hot 编码矩阵 (5x1) 进行损失的计算，然后更新网络参数完成一次模型迭代。</p>\n<p><img data-src=\"https://i0.imgs.ovh/2024/02/13/olEj9.png\" alt=\"tu\" title=\"CBOW模式\" /></p>\n",
            "tags": [
                "NER"
            ]
        }
    ]
}