{
    "version": "https://jsonfeed.org/version/1",
    "title": "白骨生花 • All posts by \"ner\" category",
    "description": "同行者，拿起火把！",
    "home_page_url": "http://qiji5211.com",
    "items": [
        {
            "id": "http://qiji5211.com/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/",
            "url": "http://qiji5211.com/2024/02/07/NER/pytorch%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/",
            "title": "pytorch安装环境问题",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"自己安\"><a class=\"anchor\" href=\"#自己安\">#</a> 自己安</h1>\n<p>突然兴起想重装 Anaconda 和 Pycharm, 好家伙，整整两天才给全部整明白，最大的原因见文末，在此记录一下我踩的坑。</p>\n<p>参考【PyTorch 深度学习快速入门教程（绝对通俗易懂！）【小土堆】】 <span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWhFNDExdDdSTi8/c2hhcmVfc291cmNlPWNvcHlfd2ViJmFtcDt2ZF9zb3VyY2U9NGJkODUyZjgzNGYyZDlhNmE4Y2UwNjA5YTM2MDAxZDQ=\">https://www.bilibili.com/video/BV1hE411t7RN/?share_source=copy_web&amp;vd_source=4bd852f834f2d9a6a8ce0609a36001d4</span></p>\n<p>Anaconda（ <code>Anaconda3-2023.09-0-Windows-x86 64.exe</code> ）,pycharm，pytorch 已下好且 pytorch（本机没有满足要求的 GPU，选的 CPU）可正常激活，中文路径问题可参考 CSDN 通过配置环境变量解决，仅最后一步不对。</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>(pytorch) PS C:\\Users\\ 王越洋 &gt; python</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)] on win32</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>&gt;&gt;&gt; import torch</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>&gt;&gt;&gt;</pre></td></tr></table></figure><p>但配置时报错如下：</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py:21: UserWarning: mkl-service package failed to import, therefore Intel (R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http:&#x2F;&#x2F;github.com&#x2F;IntelPython&#x2F;mkl-service</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Traceback (most recent call last):</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\__init__.py&quot;, line 22, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    from . import multiarray</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\multiarray.py&quot;, line 12, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    from . import overrides</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\overrides.py&quot;, line 7, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    from numpy.core._multiarray_umath import (</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>ImportError: DLL load failed: 找不到指定的模块。</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>During handling of the above exception, another exception occurred:</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>Traceback (most recent call last):</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\code.py&quot;, line 91, in runcode</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    exec (code, self.locals)</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\__init__.py&quot;, line 613, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    _C._initExtension (manager_path ())</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py&quot;, line 685, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    from . import amp</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\__init__.py&quot;, line 1, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    from .autocast_mode import autocast, custom_fwd, custom_bwd  # noqa: F401</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py&quot;, line 5, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    import numpy as np</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\__init__.py&quot;, line 140, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    from . import core</pre></td></tr><tr><td data-num=\"42\"></td><td><pre>  File &quot;D:\\ruanjian\\Pycharm\\PyCharm 2023.3.2\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py&quot;, line 21, in do_import</pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    module &#x3D; self._system_import (name, *args, **kwargs)</pre></td></tr><tr><td data-num=\"44\"></td><td><pre>  File &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\__init__.py&quot;, line 48, in &lt;module&gt;</pre></td></tr><tr><td data-num=\"45\"></td><td><pre>    raise ImportError (msg)</pre></td></tr><tr><td data-num=\"46\"></td><td><pre>ImportError: </pre></td></tr><tr><td data-num=\"47\"></td><td><pre>IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!</pre></td></tr><tr><td data-num=\"48\"></td><td><pre>Importing the numpy C-extensions failed. This error can happen for</pre></td></tr><tr><td data-num=\"49\"></td><td><pre>many reasons, often due to issues with your setup or how NumPy was</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>installed.</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>We have compiled some common reasons and troubleshooting tips at:</pre></td></tr><tr><td data-num=\"52\"></td><td><pre>    https:&#x2F;&#x2F;numpy.org&#x2F;devdocs&#x2F;user&#x2F;troubleshooting-importerror.html</pre></td></tr><tr><td data-num=\"53\"></td><td><pre>Please note and check the following:</pre></td></tr><tr><td data-num=\"54\"></td><td><pre>  * The Python version is: Python3.6 from &quot;C:\\Users\\ 王越洋 \\.conda\\envs\\pytorch\\python.exe&quot;</pre></td></tr><tr><td data-num=\"55\"></td><td><pre>  * The NumPy version is: &quot;1.19.2&quot;</pre></td></tr><tr><td data-num=\"56\"></td><td><pre>and make sure that they are the versions you expect.</pre></td></tr><tr><td data-num=\"57\"></td><td><pre>Please carefully study the documentation linked above for further help.</pre></td></tr><tr><td data-num=\"58\"></td><td><pre>Original error was: DLL load failed: 找不到指定的模块。</pre></td></tr></table></figure><p><s>初步怀疑问题在于</s>（是小白没错了，后面人家说和这个没关系，看到这个报错的 uu 不要惊慌）</p>\n<p>但当时我不知道啊，遂运行提示命令，无果，约半小时后提示某文件没有 admission，CSDN 有文指出该问题可以重新更新 conda，下载一小时没下完。两个都运行了两次左右，各种重装 Anaconda，结果人家输出我没有 admission，如果你和我一样装 Anaconda 时选的 <code>给所有人装</code> 的选项，记得在权限里设置 <code>所有人可修改</code> 即可解决。当然，不设置也可以。</p>\n<p>最后，这个错无伤大雅，重点不在这，不要运行 <code>conda update -n base -c defaults conda</code>  就是了。</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>(pytorch) PS C:\\Users\\ 王越洋 &gt; conda install pytorch torchvision torchaudio cpuonly -c pytorch</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Collecting package metadata (current_repodata.json): done</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Solving environment: done</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>&#x3D;&#x3D;&gt; WARNING: A newer version of conda exists. &lt;&#x3D;&#x3D;</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  current version: 23.7.4</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  latest version: 24.1.0</pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>Please update conda by running</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    $ conda update -n base -c defaults conda</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>Or to minimize the number of packages updated during conda update use</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>     conda install conda&#x3D;24.1.0</pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre># All requested packages already installed.</pre></td></tr></table></figure><p>这个报错的意思是你有库安了，但是没安全。</p>\n<h1 id=\"深夜寻求某宝\"><a class=\"anchor\" href=\"#深夜寻求某宝\">#</a> 深夜寻求某宝</h1>\n<p>凌晨 00:23，解决无果，遂面向某宝解决（cost20￥），次日早，某阿里员工给我一波各种操作，两小时后告诉我问题是 numpy 库没安全，然后各种调试，找版本，然后安，解决！</p>\n<p>下午，感觉自己又行了，于是自己重新建了一个虚拟环境，把人家建的删了，报错依旧，重装 numpy 无果，<s>发疯发疯</s>，感觉这个人解决问题不能一劳永逸（其实是我没学会。。。人家还是很厉害滴）~</p>\n<h1 id=\"晚上寻求拼夕夕\"><a class=\"anchor\" href=\"#晚上寻求拼夕夕\">#</a> 晚上寻求拼夕夕🌟</h1>\n<p>已是晚 10：20, 继第 10 次左右重新安装调试后，随便捞了个能安的人（cost15￥），看得出来他也很焦灼，甚至还出现了新错误:</p>\n<p>(1) Environment 创建失败（这个和库没关系，是说你的源或者网络问题，建议换源即可）</p>\n<p>(2) 系统找不到指定路径。这个就比较棘手了，人家配了环境变量，各种调试，无果。通过装 <code>Anaconda3-2020.11 Windows-x86 64.exe</code> ，再来一遍 pip 配置，成功！！！</p>\n<p>通过 pip 安装就不会像通过 conda 安装报错，成功解决！！！</p>\n<p>小问题：conda 安装的虚拟环境位置在 <code>C:/User/XXX/.conda/env/</code>  下的，但这种方式安装的虚拟环境位置在 Anaconda3 的安装目录下，其他运行均正常，虽然还是会报版本不一致的错，但无碍。本次配置终于完成！！</p>\n<h1 id=\"结果\"><a class=\"anchor\" href=\"#结果\">#</a> 结果</h1>\n<p>综上，出现此类错误的人建议装低版本一点的 Anaconda (卸的时候记得用自带的工具卸，写完检查环境变量删干净没)，安装时记得把 PATH 选项勾上（要不然要自己配，容易配错），最新版的 Anaconda 应该是有小毛病（库不全），<span class=\"red\">谨慎安装！！！</span></p>\n<p>祝看到这里的各位 PyTorch 学习顺利！🌟</p>\n",
            "tags": [
                "pytorch"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/",
            "url": "http://qiji5211.com/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/",
            "title": "文本预处理",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"文本处理的基本方法\"><a class=\"anchor\" href=\"#文本处理的基本方法\">#</a> 文本处理的基本方法</h1>\n<h2 id=\"分词\"><a class=\"anchor\" href=\"#分词\">#</a> 分词</h2>\n<h3 id=\"什么是分词\"><a class=\"anchor\" href=\"#什么是分词\">#</a> 什么是分词？</h3>\n<blockquote>\n<p>分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的<br />\n行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界<br />\n符来简单划界，唯独词没有一个形式上的分界符，分词过程就是找到这样分界符的过程，</p>\n</blockquote>\n<ul>\n<li>举例：</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>女干事每月经过下属科室都</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span>，<span class=\"token string\">'每月'</span>，<span class=\"token string\">'经过'</span>，<span class=\"token string\">'下属'</span>，<span class=\"token string\">'科室'</span>，<span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><h3 id=\"分词的作用\"><a class=\"anchor\" href=\"#分词的作用\">#</a> 分词的作用</h3>\n<ul>\n<li>词作为语言语义理解的最小单元，是人类理解文本语言的基础。因此也是 AI 解决 NLP 领域高阶任务，如自动问答，机器翻译，文本生成的重要基础环节。</li>\n</ul>\n<h3 id=\"流行中文分词工具jieba\"><a class=\"anchor\" href=\"#流行中文分词工具jieba\">#</a> 流行中文分词工具 jieba</h3>\n<blockquote>\n<p>&quot;结巴&quot; 中文分词，做最好的 Python 中文分词组件。</p>\n</blockquote>\n<ul>\n<li>\n<p>jiebal 的特性：</p>\n<ul>\n<li>支持多种分词模式</li>\n<li>精确模式</li>\n<li>全模式</li>\n<li>搜索引擎摸式</li>\n<li>支持中文繁体分词</li>\n<li>支持用户自定义词典</li>\n</ul>\n</li>\n<li>\n<p>jieba 使用</p>\n</li>\n</ul>\n<blockquote>\n<p>精确模式分词：试图将句子最精确地切开，适合文本分析</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">import</span> jieba</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>默认为<span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#生成器对象</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut at <span class=\"token number\">0x000001ED13237350</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#列表内容</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>Building prefix <span class=\"token builtin\">dict</span> <span class=\"token keyword\">from</span> the default dictionary <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>Dumping model to <span class=\"token builtin\">file</span> cache C<span class=\"token punctuation\">:</span>\\WINDOWS\\TEMP\\jieba<span class=\"token punctuation\">.</span>cache</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>Loading model cost <span class=\"token number\">0.607</span> seconds<span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>Prefix <span class=\"token builtin\">dict</span> has been built successfully<span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>Out<span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>全模式分词：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能消除歧义。</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut at <span class=\"token number\">0x000001ED13237D60</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span>cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre> <span class=\"token punctuation\">[</span><span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'月经'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>搜索引擎模式分词：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"女干事每月经过下属科室都\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>cut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token operator\">&lt;</span>generator <span class=\"token builtin\">object</span> Tokenizer<span class=\"token punctuation\">.</span>cut_for_search at <span class=\"token number\">0x000001ED14A014A0</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'女干事'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'每月'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'经过'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'下属'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'科室'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'都'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>中文繁体分词：针对中国香港，台湾地区的繁体文本进行分词</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> content <span class=\"token operator\">=</span> <span class=\"token string\">\"烦惱即是菩提，我暂且不提\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>lcut_for_search<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> <span class=\"token punctuation\">[</span><span class=\"token string\">'烦惱'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'即'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'是'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'菩提'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'，'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'我'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'暂且'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'不提'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><blockquote>\n<p>使用用户自定义词典</p>\n</blockquote>\n<ul>\n<li>添加自定义词典后，jieba 能够准确识别词典中出现的词汇，提升整体的识别准确率，</li>\n<li>词典格式：每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开<br />\n顺序不可颠倒</li>\n<li>词典样式如下，具体词性含义请参照附录：jieba 词性对照表，将该词典存 userdict.txt, 方便之后加载使用。</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>云计算5n</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>李小福2nr</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>easy_install <span class=\"token number\">3</span> eng</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>好用<span class=\"token number\">300</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>韩玉赏鉴3nZ</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>八一双鹿3nz</pre></td></tr></table></figure><hr />\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span> <span class=\"token keyword\">import</span> jieba</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> jieba<span class=\"token punctuation\">.</span>1cut<span class=\"token punctuation\">(</span><span class=\"token string\">\"八一双鹿更名为八一南昌篮球队！\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\">#没有使用用户自定义词典前的结果：</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span><span class=\"token punctuation\">[</span><span class=\"token string\">'八一双鹿'</span>，<span class=\"token string\">'更名'</span>，<span class=\"token string\">'为'</span>，<span class=\"token string\">'八一'</span>，<span class=\"token string\">'南昌'</span>，<span class=\"token string\">'篮球队'</span>，<span class=\"token string\">'!'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token operator\">>></span>jieba<span class=\"token punctuation\">.</span>load_userdict<span class=\"token punctuation\">(</span><span class=\"token string\">\"./userdict.txt\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#使用了用户自定义词典后的结果：</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'八一双鹿'</span>，<span class=\"token string\">'更名'</span>，<span class=\"token string\">'为'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'八一'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'南昌'</span>，<span class=\"token string\">'篮球队'</span>，<span class=\"token string\">'!'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><h2 id=\"命名实体识别\"><a class=\"anchor\" href=\"#命名实体识别\">#</a> 命名实体识别</h2>\n<p>顾名思义，命名实体识别 (Named Entity Recognition, 简称 NER) 就是识别出一段文本中可能存在的命名实体。</p>\n<ul>\n<li>命名实体识别的作用：</li>\n</ul>\n<p>同词汇一样，命名实体也是人类理解文本的基础单元，因此也是 A 解决 NLP 领域高阶任务的重要基础环节</p>\n<h2 id=\"词性标注\"><a class=\"anchor\" href=\"#词性标注\">#</a> 词性标注</h2>\n<blockquote>\n<p>词性：语言中对词的一种分类方法，以语法特征为主要依据、兼顾词汇意义对词进行划分的结果，常见的词性有 143 如：名词，动词，形容词等</p>\n</blockquote>\n<p>顾名思义，词性标注 (Part-Of-Speech tagging, 简称 POS) 就是标注出一段文本中每个词汇的词性。</p>\n<ul>\n<li>词性标注的作用</li>\n</ul>\n<p>词性标注以分词为基础，是对文本语言的另一个角度的理解，因此也常常成为 A 解决 NLP 领域高阶任务的重要基础环节。</p>\n<ul>\n<li>使用 jieba 进行中文词性标注</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">import</span> jieba<span class=\"token punctuation\">.</span>posseg <span class=\"token keyword\">as</span> pseg</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span> pseg<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span><span class=\"token string\">\"我爱北京天安门\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>pair<span class=\"token punctuation\">(</span><span class=\"token string\">'我'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'爱'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'v'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'北京'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ns'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> pair<span class=\"token punctuation\">(</span><span class=\"token string\">'天安门'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ns'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>rr<span class=\"token punctuation\">:</span>人称代词</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>v<span class=\"token punctuation\">:</span>动词</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>n<span class=\"token punctuation\">:</span>名词</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>vn<span class=\"token punctuation\">:</span>动名词</pre></td></tr></table></figure><h1 id=\"文本张量表示方法\"><a class=\"anchor\" href=\"#文本张量表示方法\">#</a> 文本张量表示方法</h1>\n<ul>\n<li>什么是文本张量表示</li>\n</ul>\n<p>将一段文本使用张量进行表示，其中一般将词汇为表示成向量，称作词向量，再由各个词向量按顺序组成矩阵形成文本表示。</p>\n<p>举个栗子</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">\"人生\"</span>，<span class=\"token string\">\"该\"</span>，<span class=\"token string\">\"如何\"</span>，<span class=\"token string\">\"起头\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#每个词对应矩阵中的一个向量</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">3.1</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.43</span><span class=\"token punctuation\">,</span><span class=\"token number\">0.34</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">3.21</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.32</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">2.54</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.32</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.12</span><span class=\"token punctuation\">,</span><span class=\"token number\">9.54</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ul>\n<li>文本张量表示的作用</li>\n</ul>\n<p>将文本表示成张量（矩阵）形式，能够使语言文本可以作为计算机处理程序的输入，进行接下来一系列的解析工作。</p>\n<blockquote>\n<ul>\n<li>文本张量表示的方法：\n<ul>\n<li>one-hot 编码</li>\n<li>Word2vec</li>\n<li>Word Embedding</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h2 id=\"one-hot独热编码\"><a class=\"anchor\" href=\"#one-hot独热编码\">#</a> one-hot (独热编码)</h2>\n<ul>\n<li>什么是 one-hot (独热编码) 词向量表示</li>\n</ul>\n<p>又称独热编码，将每个词表示成具有个元素的向量，这个词向量中只有一个元素是 1，其他元素都是 0，不同词汇元素为 0 的位置不同，其中的大小是整个语料中不同词汇的总数。</p>\n<p>举个栗子</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">\"改变\"</span>，<span class=\"token string\">\"要\"</span>，<span class=\"token string\">\"如何\"</span>，<span class=\"token string\">\"起手\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">==</span><span class=\"token operator\">></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ul>\n<li>实现</li>\n</ul>\n<ol>\n<li>进行 one-hot (独热编码)</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#导入用于对象保存与加载的 job11b</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>externals <span class=\"token keyword\">import</span> joblib</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#导入 keras 中的词汇映射器 Tokenizer</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> Tokenizer</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#假定 vocab 为语料集所有不同词汇集合</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>vocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"周杰伦\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"陈奕迅\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"王力宏\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"李宗盛\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"吴亦凡\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"鹿晗\"</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\">#实例化一个词汇映射器对象</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>t <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">(</span>num_words<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>char_level<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\">#使用映射器拟合现有文本数据</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>t<span class=\"token punctuation\">.</span>fit_on_texts<span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> vocab<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    zero_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token comment\">#使用映射器转化现有文本数据，** 每个词汇对应从 1 开始的自然数</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token comment\">#返回样式如：[[2]]，取出其中的数字需要使用 [0][0]</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    token_index <span class=\"token operator\">=</span> t<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    zero_list<span class=\"token punctuation\">[</span>token_index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">,</span><span class=\"token string\">\"的one-hot编码为：\"</span><span class=\"token punctuation\">,</span>zero_list<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>李宗盛 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>王力宏 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>鹿晗 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>吴亦凡 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>陈奕迅 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>周杰伦 的one<span class=\"token operator\">-</span>hot编码为： <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\">#使用 jobl1b 工具保存映射器，以便之后使用</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>tokenizer_path <span class=\"token string\">\"./Tokenizer\"</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>joblib<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">,</span>tokenizer_path<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><div class=\"note danger\">\n<p>注意！！！ 务必用 conda 安装 tensorflow, 会自动匹配对应的版本，pip 会有不兼容问题。<br />\ncpu 的直接 <code>conda install tensorflow</code>  即可，不要指定版本，会找不到包。然后根据对应的报错进行 <code>conda install chardet</code> , 大功告成！</p>\n</div>\n<ol start=\"2\">\n<li>使用</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#导入用于对象保存与加载的 job11b</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>externals <span class=\"token keyword\">import</span> joblib</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#加载之前保存的 Tokenizer, 实例化一个 t 对象</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>t <span class=\"token operator\">=</span> joblib<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>tokenizer_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\">#编码 token 为 \"李宗盛\"</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>token<span class=\"token operator\">=</span><span class=\"token string\">\"李宗盛\"</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#使用 t 获得 token-index</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>token_index <span class=\"token operator\">=</span> t<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#初始化一个 zero-11st</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>zero_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\">#令 zero-L1st 的对应索引为 1</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>zero_list<span class=\"token punctuation\">[</span>token_index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">,</span><span class=\"token string\">\"的one-hot编码为：\"</span>，zero_list<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ol start=\"3\">\n<li>输出效果</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>李宗盛的one<span class=\"token operator\">-</span>hot编码为：<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ol start=\"4\">\n<li>one-hot 编码的优劣势：</li>\n</ol>\n<p>优势：摄作简单，容易理解。</p>\n<p>劣势：完全割裂了词与词之间的联系，而且在大语料集下，每个向量的长度过大，占据大量内存。</p>\n<p><span class=\"label danger\">说明</span></p>\n<p>正因为 one-hot 编码明显的劣势，这种编码方式被应用的地方越来越少，取而代之的是<br />\n接下来我们要学习的稠密向量的表示方法 word2vec 和 word embedding。</p>\n<h2 id=\"word2vec\"><a class=\"anchor\" href=\"#word2vec\">#</a> Word2vec</h2>\n<p>是一种流行的将词汇表示成向量的无监督训练方法，该过程将构建神经网络模型，将网络参<br />\n数作为词汇的向量表示，它包含 CBOW 和 skipgram 两种训练模式。</p>\n<h3 id=\"cbowcontinuous-bag-of-words模式\"><a class=\"anchor\" href=\"#cbowcontinuous-bag-of-words模式\">#</a> CBOW (Continuous bag of words) 模式</h3>\n<p>给定一段用于训练的文本语料，再选定某段长度（窗口）作为研究对象，使用上下文词汇预测目标词汇。</p>\n<p><img data-src=\"https://i0.imgs.ovh/2024/02/13/olDK3.png\" alt=\"tu\" title=\"CBOW模式\" /></p>\n<p>图中窗口大小为 9，使用前后 4 个词汇对目标词汇进行预测。</p>\n<h4 id=\"word2vec过程\"><a class=\"anchor\" href=\"#word2vec过程\">#</a> Word2vec 过程</h4>\n<p>假设我们给定的训练语料只有一句话： <code>Hope can set you free</code>  (愿你自由成长)，窗口大小为<br />\n 3, 因此模型的第一个训练样本来自 <code>Hope can set</code> , 因为是 CBOW 模式，所以将使用 <code>Hope</code>  和<br />\n <code>set</code>  作为输入， <code>can</code>  作为输出，在模型训练时， <code>Hope</code> , <code>can</code> , <code>set</code>  等词汇都使用它们的 one-hot 编码。如图所示：每个 one-hot 编码的单词与各自的变换矩阵 (即参数矩阵 3x5, 这里的 3 是指最后得到的词向量维度) 相乘之后再相加，得到上下文表示矩阵 (3x1)。</p>\n<p><img data-src=\"https://i0.imgs.ovh/2024/02/13/ol8Ze.png\" alt=\"tu\" title=\"CBOW模式\" /></p>\n<p>接着，将上下文表示矩阵与变换矩阵（参数矩阵 5x3, 所有的变换矩阵共享参数）相乘，得到 5x1 的结果矩阵，它将与我们真正的目标矩阵即 can 的 one-hot 编码矩阵 (5x1) 进行损失的计算，然后更新网络参数完成一次模型迭代。</p>\n<p><img data-src=\"https://i0.imgs.ovh/2024/02/13/olEj9.png\" alt=\"tu\" title=\"CBOW模式\" /></p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/03%20%E4%BB%80%E4%B9%88%E6%98%AF%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88Transformer%20%E5%89%8D%E5%A5%8F%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/03%20%E4%BB%80%E4%B9%88%E6%98%AF%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88Transformer%20%E5%89%8D%E5%A5%8F%EF%BC%89/",
            "title": "什么是预训练（Transformer 前奏）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"预训练有什么用\"><a class=\"anchor\" href=\"#预训练有什么用\">#</a> 预训练有什么用</h1>\n<p>机器学习：偏数学（《统计学习方法》- 李航）</p>\n<p>深度学习（人工智能）的项目：大数据支持（主流）</p>\n<p>我们很多项目没有大数据支持（小数据）</p>\n<p>猫狗分类任务：100 张猫和狗的图片 --》给你一张图片，分出是猫还是狗（无法解决的一个问题，精度很低）</p>\n<p>100000 张鹅和鸭的图片（已知，有人做过的，通过这 10w 张图片做了一个模型 A）</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/%E5%9B%BE%E5%83%8F%E9%A2%84%E8%AE%AD%E7%BB%83%E7%A4%BA%E4%BE%8B.jpg\" alt=\"img\" /></p>\n<p>有人发现，浅层通用的（横竖撇捺）</p>\n<p>我通过 10w 个鹅和鸭训练了一个模型 A，100 层的 CNN</p>\n<p>任务 B：100 张猫和狗的图片，分类 --》 训练处 100 层的 CNN，不可能实现的</p>\n<p>尝试使用 A 的前 50 层，使用 100 层去完成任务 B</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%BA%94%E7%94%A8.jpg\" alt=\"img\" /></p>\n<ol>\n<li>冻结：浅层参数不变</li>\n<li>微调：浅层参数会跟着任务 B 训练而改变</li>\n</ol>\n<h1 id=\"预训练是什么\"><a class=\"anchor\" href=\"#预训练是什么\">#</a> 预训练是什么</h1>\n<p>通过一个已经训练好的模型 A，去完成一个小数据量的任务 B（使用了模型 A 的浅层参数）</p>\n<p>任务 A 和任务 B 极其相似</p>\n<h1 id=\"预训练怎么用\"><a class=\"anchor\" href=\"#预训练怎么用\">#</a> 预训练怎么用</h1>\n<p>fairseq 、transformers 库</p>\n<h1 id=\"总结\"><a class=\"anchor\" href=\"#总结\">#</a> 总结</h1>\n<p>一个任务 A，一个任务 B，两者极其相似，任务 A 已经训练处一个模型 A，使用模型 A 的浅层参数去训练任务 B，得到模型 B，1.</p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/04%20%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88n%E5%85%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/04%20%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88n%E5%85%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89/",
            "title": "统计语言模型（n元语言模型）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"预训练\"><a class=\"anchor\" href=\"#预训练\">#</a> 预训练</h1>\n<p>预先训练</p>\n<p>我们有两个相似的任务 A 和 B，任务 A 已经完成了得到了一个模型 A</p>\n<p>任务 B（数据量小）</p>\n<p>用到了一个特性：CNN 浅层参数通用</p>\n<p>任务 B 就可以使用模型 A 的浅层参数，后面的参数通过任务 B 训练 --》1. 冻结（浅层参数不变）2. 微调（变）</p>\n<p>任务 B（大数据）可以训练出模型 B（我还可以使用模型 A 的浅层参数，节省训练时间，节省成本）</p>\n<h1 id=\"统计语言模型\"><a class=\"anchor\" href=\"#统计语言模型\">#</a> 统计语言模型</h1>\n<h2 id=\"语言模型\"><a class=\"anchor\" href=\"#语言模型\">#</a> 语言模型</h2>\n<p>语言（人说的话）+ 模型（表示某个东西，完成某个任务）</p>\n<ol>\n<li>P (“判断这个词的词性”)，P (“判断这个词的磁性”)</li>\n<li>“判断这个词的 <code>______</code> ”</li>\n</ol>\n<h2 id=\"统计语言模型-2\"><a class=\"anchor\" href=\"#统计语言模型-2\">#</a> 统计语言模型</h2>\n<p>用统计的方法去解决上述两个问题</p>\n<p>“判断这个词的词性” = “判断”，“这个”，“词”，“的”，“词性”</p>\n<p>这句话是序列（有顺序的）</p>\n<p>用了一个条件概率的链式法则（概率论）</p>\n<p>![image-20220611203051818](../../Library/Application Support/typora-user-images/image-20220611203051818.png)</p>\n<p>通过这个法则，我们可以求出每一个词出现的概率，然后连乘，就是这句话出现的概率</p>\n<p>解决第二个问题：</p>\n<p>“判断这个词的 <code>__</code> ”</p>\n<p>P (w_next | “判断”，“这个”，“词”，“的”)  （1）</p>\n<p>词库（词典）V--》新华字典，高处一个集合，把所有词装到集合 V 里</p>\n<p>把集合里的每一个词，都进行上一步（1）的计算</p>\n<p “词性”，=\"\" “火星”=\"\">词库 V =</p>\n<p>P (词性 | “判断”，“这个”，“词”，“的”)</p>\n<p>P (火星 | “判断”，“这个”，“词”，“的”)</p>\n<p>P (词性 | “判断”，“这个”，“词”，“的”，……， “……”)</p>\n<p>![image-20220611203813910](../../Library/Application Support/typora-user-images/image-20220611203813910.png)</p>\n<h2 id=\"n-元统计语言模型\"><a class=\"anchor\" href=\"#n-元统计语言模型\">#</a> n 元统计语言模型</h2>\n<p>P (词性 |“这个”，“词”，“的”)</p>\n<p>P (火星 | “这个”，“词”，“的”)</p>\n<p>P (词性 |“词”，“的”)</p>\n<p>P (火星 |“词”，“的”)</p>\n<p>P (词性 |“的”)</p>\n<p>P (火星 |“的”)</p>\n<p>把 n 个词，取 2 个词（2 元），取 3 个词（3 元）</p>\n<h1 id=\"如何去计算\"><a class=\"anchor\" href=\"#如何去计算\">#</a> 如何去计算</h1>\n<figure class=\"highlight basic\"><figcaption data-lang=\"BASIC\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>“词性是动词”</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>“判断单词的词性”</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>“磁性很强的磁铁”</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>“北京的词性是名词”</pre></td></tr></table></figure><p 3=\"\">𝑃(词性 | 的) = <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mtext>词性，的</mtext><mo stretchy=\"false\">)</mo></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mtext>的</mtext><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{cout(词性，的)}{count(的)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mopen mtight\">(</span><span class=\"mord cjk_fallback mtight\">的</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mopen mtight\">(</span><span class=\"mord cjk_fallback mtight\">词</span><span class=\"mord cjk_fallback mtight\">性</span><span class=\"mord cjk_fallback mtight\">，</span><span class=\"mord cjk_fallback mtight\">的</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> = \\frac{2}</p>\n<h1 id=\"平滑策略\"><a class=\"anchor\" href=\"#平滑策略\">#</a> 平滑策略</h1>\n<p 0=\"\">P (策略 | 平滑) = \\frac{0}</p>\n<p>![image-20220611204401168](../../Library/Application Support/typora-user-images/image-20220611204401168.png)</p>\n<h1 id=\"统计语言模型-3\"><a class=\"anchor\" href=\"#统计语言模型-3\">#</a> 统计语言模型</h1>\n<p>语言模型：计算一句话的概率，计算下一个词可能是什么</p>\n<p>统计语言模型：统计的方法去解决语言模型的问题（条件概率）</p>\n<p>a 元语言模型：只取 a 个词（马尔科夫链）</p>\n<p>平滑策略：</p>\n<h1 id=\"下节课神经网络语言模型\"><a class=\"anchor\" href=\"#下节课神经网络语言模型\">#</a> 下节课：神经网络语言模型</h1>\n<p>统计语言模型：神经网络的方法去解决语言模型的问题</p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/05%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81+%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E8%B5%B7%E6%BA%90%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/05%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81+%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E8%B5%B7%E6%BA%90%EF%BC%89/",
            "title": "神经网络语言模型（独热编码+词向量的起源）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"统计语言模型\"><a class=\"anchor\" href=\"#统计语言模型\">#</a> 统计语言模型</h1>\n<p>统计 + 语言模型 --》用统计的方法去完成以下两个和人说的话相关的任务</p>\n<p>语言模型 = 语言（人说的话） + 模型（去完成两个任务）</p>\n<ol>\n<li>比较，“词性”，“磁性”</li>\n<li>预测下一个单词（填空）</li>\n</ol>\n<h2 id=\"n-元语言模型\"><a class=\"anchor\" href=\"#n-元语言模型\">#</a> n 元语言模型</h2>\n<p>取 a（2，3，4） 个词</p>\n<h1 id=\"神经网络语言模型\"><a class=\"anchor\" href=\"#神经网络语言模型\">#</a> 神经网络语言模型</h1>\n<p>神经网络 + 语言模型 --》用神经网络的方法去完成以下两个和人说的话相关的任务。</p>\n<p>第二个任务：</p>\n<p>“判断”，“一个”，“词”，“的”，“ <code>___</code> ”</p>\n<p>假设词库里有 “词性” 和 “火星”</p>\n<p>P( <code>__</code> |“判断”，“一个”，“词”，“的”)</p>\n<p>词性</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNyVBNSU5RSVFNyVCQiU4RiVFNyVCRCU5MSVFNyVCQiU5QyVFOCVBRiVBRCVFOCVBOCU4MCVFNiVBOCVBMSVFNSU5RSU4Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 神经网络语言模型.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:67%;&quot; /&gt;</p>\n<p>w1,w2,w3,w4（上述 4 个单词的独热编码）</p>\n<pre><code>w1*Q=c1,\nw2*Q=c2,\nw3*Q=c3,\nw4*Q=c4,\n\nC=[c1,c2,c3,c4]\nQ就是一个随机矩阵，是一个参数（可学习）\n</code></pre>\n<p>“判断”，“这个”，“词”，“的”，“词性”</p>\n<p>softmax（U[tanh(WC+b1)]+b2）== [0.1, 0.1, 0.2, 0.2, 0.4] <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><msub><mi>V</mi><mi>L</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\in[1,V_L]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">L</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></p>\n<h2 id=\"独热编码-one-hot-编码\"><a class=\"anchor\" href=\"#独热编码-one-hot-编码\">#</a> 独热编码 （one-hot 编码）</h2>\n<p>独热编码：让计算机认识单词</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU4RCU5NSVFOCVBRiU4RCVFNyU5QSU4NCVFNyU4QiVBQyVFNyU4MyVBRCVFOCVBMSVBOCVFNyVBNCVCQS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 单词的独热表示.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>词典 V（新华字典里面把所有词集合成一个集合 V）</p>\n<p>假设词典里面只有 8 个单词</p>\n<p>计算机不认识单词的</p>\n<p>但是我们要计算机认识单词</p>\n<p>“fruit”</p>\n<p>独热编码：给出一个 8*8 的矩阵</p>\n<p>“time” --》 10000000</p>\n<p>“fruit” --》 01000000</p>\n<p>“banana” --》 00000001</p>\n<p>余弦相似度 去计算两者的相似度（0）-- 词向量（矩阵乘法）</p>\n<h1 id=\"词向量神经网络语言模型的副产品-q\"><a class=\"anchor\" href=\"#词向量神经网络语言模型的副产品-q\">#</a> 词向量（神经网络语言模型的副产品 Q）</h1>\n<p>给我任何一个词，</p>\n<p>“判断” --》 独热编码 w1 [1,0,0,0,0]</p>\n<p>w1*Q =c1  （“判断” 这个词的词向量）</p>\n<p>词向量：就是用一个向量来表示一个单词</p>\n<p>可以控制词向量的维度（大小）</p>\n<p>如果我们得到的词向量，第一个问题也被解决了，（下游任务）</p>\n<h1 id=\"总结\"><a class=\"anchor\" href=\"#总结\">#</a> 总结</h1>\n<p>神经网络语言模型：通过神经网络解决两个人说的话的问题</p>\n<p>有一个副产品：Q 矩阵 --》新的词向量（词向量可以选择词向量的维度，可以求两个词之间的相似程度）</p>\n<p>下游任务</p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/06%20Word2Vec%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%93%E9%97%A8%E5%81%9A%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8CCBOW%E5%92%8CSkip-gram%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/06%20Word2Vec%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%93%E9%97%A8%E5%81%9A%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8CCBOW%E5%92%8CSkip-gram%EF%BC%89/",
            "title": "Word2Vec模型（第一个专门做词向量的模型，CBOW和Skip-gram）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"神经网络语言模型nnlm-为了预测下一个词\"><a class=\"anchor\" href=\"#神经网络语言模型nnlm-为了预测下一个词\">#</a> 神经网络语言模型（NNLM）--》为了预测下一个词</h1>\n<p>NNLM（）--》预测下一个词</p>\n<p>神经网络 + 语言模型：用神经网络去解决和人说话有关的两个任务的一个东西</p>\n<p>softmax(w2(tanh(（w1x+b1）))+b2)</p>\n<p>得到一个副产品（词向量）</p>\n<p>Q 矩阵，对于任何一个独热编码的词向量都可以通过 Q 矩阵得到新的词向量</p>\n<ol>\n<li>可以转换维度</li>\n<li>相似词之间的词向量之间也有了关系</li>\n</ol>\n<h1 id=\"word2vec-为了得到词向量\"><a class=\"anchor\" href=\"#word2vec-为了得到词向量\">#</a> Word2Vec --》 为了得到词向量</h1>\n<p>神经网络语言模型 --》主要目的就是为了得到词向量</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.jpg\" alt=\"img\" /></p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/word2vec.jpg\" alt=\"img\" /></p>\n<p>NNLM 和 Word2Vec 基本一致（一模一样），不考虑细节，网络架构就是一模一样</p>\n<h2 id=\"cbow\"><a class=\"anchor\" href=\"#cbow\">#</a> CBOW</h2>\n<p>给出一个词的<mark>上下文</mark>，得到这个词</p>\n<p>“我是最 <code>_</code> 的 Nick”</p>\n<p>“帅” <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<h2 id=\"skip-gram\"><a class=\"anchor\" href=\"#skip-gram\">#</a> Skip-gram</h2>\n<p>给出一个词，得到这个词的上下文</p>\n<p>“帅”</p>\n<p>“我是 <code>_</code> 的 Nick”</p>\n<h1 id=\"nnlm-和-word2vec-的区别\"><a class=\"anchor\" href=\"#nnlm-和-word2vec-的区别\">#</a> NNLM 和 Word2Vec 的区别</h1>\n<p>NNNL --》 重点是预测下一词，双层感知机 softmax (w2 (tanh (（w1 (xQ)+b1）))+b2)</p>\n<p>Word2Vec --》 CBOW 和 Skip-gram 的两种架构的重点都是得到一个 Q 矩阵，softmax (w1 (xQ) +b1)</p>\n<ol>\n<li>CBOW：一个老师告诉多个学生，Q 矩阵怎么变</li>\n<li>Skip：多个老师告诉一个学生，Q 矩阵怎么变</li>\n</ol>\n<h1 id=\"word2vec的缺点\"><a class=\"anchor\" href=\"#word2vec的缺点\">#</a> Word2Vec 的缺点</h1>\n<p>Q 矩阵的设计</p>\n<p>![image-20220614193540503](../../Library/Application Support/typora-user-images/image-20220614193540503.png)</p>\n<p>00010 代表 apple × Q = 10，12，19</p>\n<p>apple（苹果，）</p>\n<p>假设数据集里面的 apple 只有苹果这个意思，没有这个意思（训练）</p>\n<p>（测试，应用）10，12，19 apple, 无法表示这个意思</p>\n<p>词向量不能进行多意 ---》 ELMO</p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/00%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E5%85%A8%E6%96%87%2024854%20%E4%B8%AA%E8%AF%8D%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/00%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E5%85%A8%E6%96%87%2024854%20%E4%B8%AA%E8%AF%8D%EF%BC%89/",
            "title": "预训练语言模型的前世今生",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<p>&lt;h1 style='text-align:center;'&gt; 预训练语言模型的前世今生 - 从 Word Embedding 到 BERT&lt;/h1&gt;</p>\n<p>本篇文章共 25027 个词，一个字一个字手码的不容易，转载请标明出处：<br />\n&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbmlja2NoZW4xMjEvcC8xNTEwNTA0OC5odG1s\">https://www.cnblogs.com/nickchen121/p/15105048.html</span>'&gt; 预训练语言模型的前世今生 - 从 Word Embedding 到 BERT - 二十三岁的有德 &lt;/a&gt;</p>\n<p>[TOC]</p>\n<p>Bert 最近很火，应该是最近最火爆的 AI 进展，网上的评价很高，从模型创新角度看一般，创新不算大。但是架不住效果太好了，基本刷新了很多 NLP 的任务的最好性能，有些任务还被刷爆了，这个才是关键。另外一点是 Bert 具备广泛的通用性，就是说绝大部分 NLP 任务都可以采用类似的两阶段模式直接去提升效果，这个第二关键。客观的说，把 Bert 当做最近两年 NLP 重大进展的集大成者更符合事实。</p>\n<p>本文的主题是预训练语言模型的前世今生，会大致说下 NLP 中的预训练技术是一步一步如何发展到 Bert 模型的，从中可以很自然地看到 Bert 的思路是如何逐渐形成的，Bert 的历史沿革是什么，继承了什么，创新了什么，为什么效果那么好，主要原因是什么，以及为何说模型创新不算太大，为何说 Bert 是近年来 NLP 重大进展的集大成者。</p>\n<p>预训练语言模型的发展并不是一蹴而就的，而是伴随着诸如词嵌入、序列到序列模型及 Attention 的发展而产生的。</p>\n<p>DeepMind 的计算机科学家 Sebastian Ruder 给出了 21 世纪以来，从神经网络技术的角度分析，自然语言处理的里程碑式进展，如下表所示：</p>\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>2013 年</th>\n<th>2014 年</th>\n<th>2015 年</th>\n<th>2016 年</th>\n<th>2017 年</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>技术</td>\n<td>word2vec</td>\n<td>GloVe</td>\n<td>LSTM/Attention</td>\n<td>Self-Attention</td>\n<td>Transformer</td>\n</tr>\n</tbody>\n<tbody>\n<tr>\n<td>年份</td>\n<td>2018 年</td>\n<td>2019 年</td>\n<td>2020 年</td>\n</tr>\n<tr>\n<td>----</td>\n<td>-----------------</td>\n<td>----------------------------</td>\n<td>--------------------</td>\n</tr>\n<tr>\n<td>技术</td>\n<td>GPT/ELMo/BERT/GNN</td>\n<td>XLNet/BoBERTa/GPT-2/ERNIE/T5</td>\n<td>GPT-3/ELECTRA/ALBERT</td>\n</tr>\n</tbody>\n</table>\n<p>本篇文章将会通过上表显示的 NLP 中技术的发展史一一叙述，由于 19 年后的技术大都是 BERT 的变体，在这里不会多加叙述，读者可以自行加以了解。</p>\n<h1 id=\"一-预训练\"><a class=\"anchor\" href=\"#一-预训练\">#</a> 一、预训练</h1>\n<h2 id=\"11-图像领域的预训练\"><a class=\"anchor\" href=\"#11-图像领域的预训练\">#</a> 1.1 图像领域的预训练</h2>\n<p>在介绍图像领域的预训练之前，我们首先介绍下卷积神经网络（CNN），CNN 一般用于图片分类任务，并且 CNN 由多个层级结构组成，不同层学到的图像特征也不同，<strong>越浅的层学到的特征越通用（横竖撇捺），越深的层学到的特征和具体任务的关联性越强（人脸 - 人脸轮廓、汽车 - 汽车轮廓）</strong>，如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU5QiVCRSVFNSU4MyU4RiVFOSVBMiU4NCVFOCVBRSVBRCVFNyVCQiU4MyVFNyVBNCVCQSVFNCVCRSU4Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 图像预训练示例.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>由此，当领导给我们一个任务：阿猫、阿狗、阿虎的图片各十张，然后让我们设计一个深度神经网络，通过该网络把它们三者的图片进行分类。</p>\n<p>对于上述任务，如果我们亲手设计一个深度神经网络基本是不可能的，<strong>因为深度学习一个弱项就是在训练阶段对于数据量的需求特别大</strong>，而领导只给我们合计三十张图片，显然这是不够的。</p>\n<p>虽然领导给我们的数据量很少，<strong>但是我们是否可以利用网上现有的大量已做好分类标注的图片</strong>。比如 ImageNet 中有 1400 万张图片，并且这些图片都已经做好了分类标注。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFOSVBMiU4NCVFOCVBRSVBRCVFNyVCQiU4MyVFNyU5QSU4NCVFNSVCQSU5NCVFNyU5NCVBOC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 预训练的应用.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上述利用网络上现有图片的思想就是预训练的思想，具体做法就是：</p>\n<ol>\n<li>通过 ImageNet 数据集我们训练出一个模型 A</li>\n<li>由于上面提到 CNN 的浅层学到的特征通用性特别强，我们可以对模型 A 做出一部分改进得到模型 B（两种方法）：\n<ol>\n<li>冻结：浅层参数使用模型 A 的参数，高层参数随机初始化，<strong>浅层参数一直不变</strong>，然后利用领导给出的 30 张图片训练参数</li>\n<li>微调：浅层参数使用模型 A 的参数，高层参数随机初始化，然后利用领导给出的 30 张图片训练参数，<strong>但是在这里浅层参数会随着任务的训练不断发生变化</strong></li>\n</ol>\n</li>\n</ol>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFOSVBMiU4NCVFOCVBRSVBRCVFNyVCQiU4MyVFNSU5QyVBOCVFNSU5QiVCRSVFNSU4MyU4RiVFOSVBMiU4NiVFNSU5RiU5RiVFNyU5QSU4NCVFNSVCQSU5NCVFNyU5NCVBOC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 预训练在图像领域的应用.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>通过上述的讲解，对图像预训练做个总结（可参照上图）：对于一个具有少量数据的任务 A，首先通过一个现有的大量数据搭建一个 CNN 模型 A，由于 CNN 的浅层学到的特征通用性特别强，因此在搭建一个 CNN 模型 B，其中模型 B 的浅层参数使用模型 A 的浅层参数，模型 B 的高层参数随机初始化，然后通过冻结或微调的方式利用任务 A 的数据训练模型 B，模型 B 就是对应任务 A 的模型。</p>\n<h2 id=\"12-预训练的思想\"><a class=\"anchor\" href=\"#12-预训练的思想\">#</a> 1.2 预训练的思想</h2>\n<p>有了图像领域预训练的引入，我们在此给出预训练的思想：任务 A 对应的模型 A 的参数不再是随机初始化的，而是通过任务 B 进行预先训练得到模型 B，然后利用模型 B 的参数对模型 A 进行初始化，再通过任务 A 的数据对模型 A 进行训练。注：模型 B 的参数是随机初始化的。</p>\n<h1 id=\"二-语言模型\"><a class=\"anchor\" href=\"#二-语言模型\">#</a> 二、语言模型</h1>\n<p>想了解预训练语言模型，首先得了解什么是语言模型。</p>\n<p>语言模型通俗点讲就是 ** 计算一个句子的概率。** 也就是说，对于语言序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_1,w_2,\\cdots,w_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，语言模型就是计算该序列的概率，即 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_1,w_2,\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p>下面通过两个实例具体了解上述所描述的意思：</p>\n<ol>\n<li>假设给定两句话 “判断这个词的磁性” 和 “判断这个词的词性”，语言模型会认为后者更自然。转化成数学语言也就是：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>判断，这个，词，的，词性</mtext><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>判断，这个，词，的，磁性</mtext><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(判断，这个，词，的，词性) \\gt P(判断，这个，词，的，磁性)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">性</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">磁</span><span class=\"mord cjk_fallback\">性</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>假设给定一句话做填空 “判断这个词的____”，则问题就变成了给定前面的词，找出后面的一个词是什么，转化成数学语言就是：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>词性</mtext><mi mathvariant=\"normal\">∣</mi><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>磁性</mtext><mi mathvariant=\"normal\">∣</mi><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(词性|判断，这个，词，的) \\gt P(磁性|判断，这个，词，的)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">性</span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">磁</span><span class=\"mord cjk_fallback\">性</span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span></span></span></span></li>\n</ol>\n<p>通过上述两个实例，可以给出语言模型更加具体的描述：给定一句由 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个词组成的句子 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">W=w_1,w_2,\\cdots,w_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，计算这个句子的概率 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_1,w_2,\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，或者计算根据上文计算下一个词的概率 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>n</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_n|w_1,w_2,\\cdots,w_{n-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p>下面将介绍语言模型的两个分支，统计语言模型和神经网络语言模型。</p>\n<h2 id=\"21-统计语言模型\"><a class=\"anchor\" href=\"#21-统计语言模型\">#</a> 2.1 统计语言模型</h2>\n<p>统计语言模型的基本思想就是<strong>计算条件概率</strong>。</p>\n<p>给定一句由 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个词组成的句子 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">W=w_1,w_2,\\cdots,w_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，计算这个句子的概率 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_1,w_2,\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 的公式如下（条件概率乘法公式的推广，链式法则）：</p>\n\\begin{align*}\nP(w_1,w_2,\\cdots,w_n) \n& =  P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)\\cdots p(w_n|w_1,w_2,\\cdots,w_{n-1}) \\\\\n& = \\prod_i P(w_i|w1,w_2,\\cdots,w_{i-1})\n\\end{align*}\n\n<p>对于上一节提到的 “判断这个词的词性” 这句话，利用上述的公式，可以得到：</p>\n\\begin{align*}\n& P(判断，这个，词，的，词性) = \\\\\n& P(判断)P(这个|判断)P(词|判断，这个) \\\\\n& P(的|判断，这个，词)P(词性|判断，这个，词，的)P(判断，这个，词，的，词性)\n\\end{align*}\n\n<p>对于上一节提到的另外一个问题，当给定前面词的序列 “判断，这个，词，的” 时，想要知道下一个词是什么，可以直接计算如下概率：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo><mspace width=\"1em\"/><mtext>公式(1)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_{next}|判断，这个，词，的)\\quad\\text{公式(1)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(1)</span></span></span></span></span></span></p>\n<p>其中，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mo>∈</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">w_{next} \\in V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6891em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 表示词序列的下一个词，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 是一个具有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi>V</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">|V|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\">∣</span></span></span></span> 个词的词典（词集合）。</p>\n<p>对于公式（1），可以展开成如下形式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mtext>，判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo></mrow></mfrac><mspace width=\"1em\"/><mtext>公式(2)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_{next}|判断，这个，词，的) = \\frac{count(w_{next}，判断，这个，词，的)}{count(判断，这个，词，的)} \\quad\\text{公式(2)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(2)</span></span></span></span></span></span></p>\n<p>对于公式（2），可以把字典 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 中的多有单词，逐一作为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{next}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，带入计算，最后取最大概率的词作为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{next}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的候选词。</p>\n<p>如果 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi>V</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">|V|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\">∣</span></span></span></span> 特别大，公式（2）的计算将会非常困难，但是我们可以引入马尔科夫链的概念（当然，在这里只是简单讲讲如何做，关于马尔科夫链的数学理论知识可以自行查看其他参考资料）。</p>\n<p>假设字典 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 中有 “火星” 一词，可以明显发现 “火星” 不可能出现在 “判断这个词的” 后面，因此（火星，判断，这个，词，的）这个组合是不存在的，并且词典中会存在很多类似于 “火星” 这样的词。</p>\n<p>进一步，可以发现我们把（火星，判断，这个，词，的）这个组合判断为不存在，是因为 “火星” 不可能出现在 “词的” 后面，也就是说我们可以考虑是否把公式（1）转化为</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mtext>判断，这个，词，的</mtext><mo stretchy=\"false\">)</mo><mo>≈</mo><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mtext>词，的</mtext><mo stretchy=\"false\">)</mo><mspace width=\"1em\"/><mtext>公式(3)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_{next}|判断，这个，词，的) \\approx P(w_{next}|词，的)\\quad\\text{公式(3)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">判</span><span class=\"mord cjk_fallback\">断</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">这</span><span class=\"mord cjk_fallback\">个</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(3)</span></span></span></span></span></span></p>\n<p>公式（3）就是马尔科夫链的思想：假设 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{next}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 只和它之前的 <strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 个词有相关性</strong>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 时称作一个单元语言模型，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">k=2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> 时称为二元语言模型。</p>\n<p>可以发现通过马尔科夫链后改写的公式计算起来将会简单很多，下面我们举个简单的例子介绍下如何计算一个二元语言模型的概率。</p>\n<p>其中二元语言模型的公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mfrac><mspace width=\"1em\"/><mtext>公式(4)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_{i-1})=\\frac{count(w_{i-1},w_i)}{count(w_{i-1})}\\quad\\text{公式(4)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(4)</span></span></span></span></span></span></p>\n<p>假设有一个文本集合：</p>\n<figure class=\"highlight basic\"><figcaption data-lang=\"BASIC\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>“词性是动词”</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>“判断单词的词性”</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>“磁性很强的磁铁”</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>“北京的词性是名词”</pre></td></tr></table></figure><p>对于上述文本，如果要计算 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>词性</mtext><mi mathvariant=\"normal\">∣</mi><mtext>的</mtext><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(词性|的)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">性</span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span></span></span></span> 的概率，通过公式（4），需要统计 “的，词性” 同时按序出现的次数，再除以 “的” 出现的次数：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mtext>词性</mtext><mi mathvariant=\"normal\">∣</mi><mtext>的</mtext><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mtext>的，词性</mtext><mo stretchy=\"false\">)</mo></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mtext>的</mtext><mo stretchy=\"false\">)</mo></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mspace width=\"1em\"/><mtext>公式(5)</mtext></mrow><annotation encoding=\"application/x-tex\">P(词性|的) = \\frac{count(的，词性)}{count(的)} = \\frac{2}{3}\\quad\\text{公式(5)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">性</span><span class=\"mord\">∣</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">的</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">性</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.00744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(5)</span></span></span></span></span></span></p>\n<p>上述文本集合是我们自定制的，然而对于绝大多数具有现实意义的文本，会出现数据稀疏的情况，例如<strong>训练时未出现，测试时出现了的未登录单词</strong>。</p>\n<p>由于数据稀疏问题，则会出现概率值为 0 的情况（填空题将无法从词典中选择一个词填入），为了避免 0 值的出现，会使用一种平滑的策略 —— 分子和分母都加入一个非 0 正数，例如可以把公式（4）改为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn></mrow><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi mathvariant=\"normal\">∣</mi><mi>V</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac><mspace width=\"1em\"/><mtext>公式(6)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_{i-1}) = \\frac{count(w_{i-1},w_i)+1}{count(w_{i-1})+|V|}\\quad\\text{公式(6)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(6)</span></span></span></span></span></span></p>\n<p>##2.2 神经网络语言模型</p>\n<p>上一节简单的介绍了统计语言模型，并且在结尾处讲到统计语言模型存在数据稀疏问题，针对该问题，我们也提出了平滑方法来应对这个问题。</p>\n<p>神经网络语言模型则引入神经网络架构来估计单词的分布，<strong>并且通过词向量的距离衡量单词之间的相似度，因此，对于未登录单词，也可以通过相似词进行估计，进而避免出现数据稀疏问题</strong>。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNyVBNSU5RSVFNyVCQiU4RiVFNyVCRCU5MSVFNyVCQiU5QyVFOCVBRiVBRCVFOCVBOCU4MCVFNiVBOCVBMSVFNSU5RSU4Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 神经网络语言模型.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图为神经网络语言模型结构图，它的学习任务是输入某个句中单词 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo>=</mo><mi>b</mi><mi>e</mi><mi>r</mi><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">w_t = bert</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">t</span></span></span></span> 前的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个单词，要求网络正确预测单词 “bert”，即最大化：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo>=</mo><mi>b</mi><mi>e</mi><mi>r</mi><mi>t</mi><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">;</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mspace width=\"1em\"/><mtext>公式(7)</mtext></mrow><annotation encoding=\"application/x-tex\">P(w_t=bert|w_1,w_2,\\cdots,w_{t-1};\\theta)\\quad\\text{公式(7)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">t</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(7)</span></span></span></span></span></span></p>\n<p>上图所示的神经网络语言模型分为三层，接下来我们详细讲解这三层的作用：</p>\n<ol>\n<li>神经网络语言模型的第一层，为输入层。首先将前 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个单词用 Onehot 编码（例如：0001000）作为原始单词输入，之后乘以一个随机初始化的矩阵 Q 后获得词向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C(w_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，对这 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个词向量处理后得到输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>，记作 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x=(C(w_1),C(w_2),\\cdots,C(w_{t-1}))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>神经网络语言模型的第二层，为隐层，包含 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span> 个隐变量，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>H</mi></mrow><annotation encoding=\"application/x-tex\">H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span></span></span></span> 代表权重矩阵，因此隐层的输出为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>H</mi><mi>x</mi><mo>+</mo><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">Hx+d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span>，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span> 为偏置项。并且在此之后使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">h</span></span></span></span> 作为激活函数。</li>\n<li>神经网络语言模型的第三层，为输出层，一共有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi>V</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">|V|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\">∣</span></span></span></span>  个输出节点（字典大小），直观上讲，每个输出节点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是词典中每一个单词概率值。最终得到的计算公式为：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi>b</mi><mo>+</mo><mi>W</mi><mi>x</mi><mo>+</mo><mi>U</mi><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>d</mi><mo>+</mo><mi>H</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y = softmax(b+Wx+U\\tanh(d+Hx))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">tanh</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span> 是直接从输入层到输出层的权重矩阵，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span></span></span></span> 是隐层到输出层的参数矩阵。</li>\n</ol>\n<h1 id=\"三-词向量\"><a class=\"anchor\" href=\"#三-词向量\">#</a> 三、词向量</h1>\n<p>在描述神经网络语言模型的时候，提到 Onehot 编码和词向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C(w_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，但是并没有具体提及他们到底是什么玩意。</p>\n<p>由于他们对于未来 BERT 的讲解非常重要，所以在这里重开一章来描述词向量到底是什么，如何表示。</p>\n<h2 id=\"31-独热onehot编码\"><a class=\"anchor\" href=\"#31-独热onehot编码\">#</a> 3.1 独热（Onehot）编码</h2>\n<p><strong>把单词用向量表示，是把深度神经网络语言模型引入自然语言处理领域的一个核心技术。</strong></p>\n<p>在自然语言处理任务中，训练集大多为一个字或者一个词，把他们转化为计算机适合处理的数值类数据非常重要。</p>\n<p>早期，人们想到的方法是使用独热（Onehot）编码，如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU4RCU5NSVFOCVBRiU4RCVFNyU5QSU4NCVFNyU4QiVBQyVFNyU4MyVBRCVFOCVBMSVBOCVFNyVBNCVCQS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 单词的独热表示.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>对于上图的解释，假设有一个包含 8 个次的字典 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>，“time” 位于字典的第 1 个位置，“banana” 位于字典的第 8 个位置，因此，采用独热表示方法，对于 “time” 的向量来说，除了第 1 个位置为 1，其余位置为 0；对于 “banana” 的向量来说，除了第 8 个位置为 1，其余位置为 0。</p>\n<p>但是，对于独热表示的向量，如果采用余弦相似度计算向量间的相似度，<strong>可以明显的发现任意两者向量的相似度结果都为 0</strong>，即任意二者都不相关，也就是说独热表示无法解决词之间的相似性问题。</p>\n<h2 id=\"32-word-embedding\"><a class=\"anchor\" href=\"#32-word-embedding\">#</a> 3.2 Word Embedding</h2>\n<p>由于独热表示无法解决词之间相似性问题，这种表示很快就被词向量表示给替代了，这个时候聪明的你可能想到了在神经网络语言模型中出现的一个词向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C(w_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，对的，<strong>这个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C(w_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 其实就是单词对应的 Word Embedding 值，也就是我们这节的核心 —— 词向量。</strong></p>\n<p>在神经网络语言模型中，我们并没有详细解释词向量是如何计算的，现在让我们重看神经网络语言模型的架构图：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNyVBNSU5RSVFNyVCQiU4RiVFNyVCRCU5MSVFNyVCQiU5QyVFOCVBRiVBRCVFOCVBOCU4MCVFNiVBOCVBMSVFNSU5RSU4Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 神经网络语言模型.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图所示有一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">V×m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span> 的矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span>，这个矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> 包含 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 行，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 代表词典大小，每一行的内容代表对应单词的 Word Embedding 值。</p>\n<p>只不过 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> 的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span>，当这个网络训练好之后，矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> 的内容被正确赋值，每一行代表一个单词对应的 Word embedding 值。</p>\n<p>但是这个词向量有没有解决词之间的相似度问题呢？为了回答这个问题，我们可以看看词向量的计算过程：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>17</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>23</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>5</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>7</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>6</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>13</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>10</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>19</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>11</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>18</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>25</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>10</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>19</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mspace width=\"1em\"/><mtext>公式(8)</mtext></mrow><annotation encoding=\"application/x-tex\">\\begin{bmatrix}\n0&amp;0&amp;0&amp;1&amp;0\n\\end{bmatrix}\n\n\\begin{bmatrix}\n17&amp;24&amp;1\\\\\n23&amp;5&amp;7\\\\\n4&amp;6&amp;13\\\\\n10&amp;12&amp;19\\\\\n11&amp;18&amp;25\n\\end{bmatrix}\n\n=\n\n\\begin{bmatrix}\n10&amp;12&amp;19\n\\end{bmatrix}\n\\quad\\text{公式(8)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:6.00503em;vertical-align:-2.75004em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2549900000000003em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-2.1999800000000005em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-2.79598em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-3.39198em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-3.9879800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-4.0139700000000005em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-5.25499em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2500000000000004em;\"><span style=\"top:-5.410000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">7</span></span></span><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\">3</span></span></span><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span><span style=\"top:-1.8099999999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span></span><span style=\"top:-0.6099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2500000000000004em;\"><span style=\"top:-5.410000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\">4</span></span></span><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">5</span></span></span><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">6</span></span></span><span style=\"top:-1.8099999999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">2</span></span></span><span style=\"top:-0.6099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">8</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2500000000000004em;\"><span style=\"top:-5.410000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">7</span></span></span><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">3</span></span></span><span style=\"top:-1.8099999999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">9</span></span></span><span style=\"top:-0.6099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2549900000000003em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-2.1999800000000005em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-2.79598em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-3.39198em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-3.9879800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-4.0139700000000005em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-5.25499em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"><span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">9</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">]</span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(8)</span></span></span></span></span></span></p>\n<p>通过上述词向量的计算，可以发现第 4 个词的词向量表示为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>10</mn><mtext> </mtext><mn>12</mn><mtext> </mtext><mn>19</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[10\\,12\\,19]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">9</span><span class=\"mclose\">]</span></span></span></span>。</p>\n<p>如果再次采用余弦相似度计算两个词之间的相似度，结果不再是 0 ，既可以一定程度上描述两个词之间的相似度。</p>\n<p>下图给了网上找的几个例子，可以看出有些例子效果还是很不错的，一个单词表达成 Word Embedding 后，很容易找出语义相近的其它词汇。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3dvcmRlbWJlZGRpbmclRTQlQkUlOEIlRTUlQUQlOTAuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/wordembedding 例子.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"四-word2vec-模型\"><a class=\"anchor\" href=\"#四-word2vec-模型\">#</a> 四、Word2Vec 模型</h1>\n<p>2013 年最火的用语言模型做 Word Embedding 的工具是 Word2Vec ，后来又出了 Glove（由于 Glove 和 Word2Vec 的作用类似，并对 BERT 的讲解没有什么帮助，之后不再多加叙述），Word2Vec 是怎么工作的呢？看下图：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3dvcmQydmVjLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/word2vec.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>Word2Vec 的网络结构其实和神经网络语言模型（NNLM）是基本类似的，只是这个图长得清晰度差了点，看上去不像，其实它们是亲兄弟。不过这里需要指出：尽管网络结构相近，而且都是做语言模型任务，但是他们训练方法不太一样。</p>\n<p>Word2Vec 有两种训练方法：</p>\n<ol>\n<li>第一种叫 CBOW，<strong>核心思想是从一个句子里面把一个词抠掉</strong>，用这个词的上文和下文去预测被抠掉的这个词；</li>\n<li>第二种叫做 Skip-gram，和 CBOW 正好反过来，输入某个单词，要求网络预测它的上下文单词。</li>\n</ol>\n<p>而你回头看看，NNLM 是怎么训练的？是输入一个单词的上文，去预测这个单词。这是有显著差异的。</p>\n<p>为什么 Word2Vec 这么处理？原因很简单，因为 Word2Vec 和 NNLM 不一样，NNLM 的主要任务是要学习一个解决语言模型任务的网络结构，语言模型就是要看到上文预测下文，而 Word Embedding 只是 NNLM 无心插柳的一个副产品；但是 Word2Vec 目标不一样，它单纯就是要 Word Embedding 的，这是主产品，所以它完全可以随性地这么去训练网络。</p>\n<p>为什么要讲 Word2Vec 呢？这里主要是要引出 CBOW 的训练方法，BERT 其实跟它有关系，后面会讲解它们之间的关系，当然它们的关系 BERT 作者没说，是我猜的，至于我猜的对不对，你看完这篇文章之后可以自行判断。</p>\n<h1 id=\"五-自然语言处理的预训练模型\"><a class=\"anchor\" href=\"#五-自然语言处理的预训练模型\">#</a> 五、自然语言处理的预训练模型</h1>\n<p>突然在文章中插入这一段，其实就是给出一个问题：Word Embedding 这种做法能算是预训练吗？这其实就是标准的预训练过程。要理解这一点要看看学会 Word Embedding 后下游任务是怎么使用它的。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3dlJUU2JUE4JUExJUU1JUJDJThGJUU0JUI4JThCJUU3JTlBJTg0JUU5JUEyJTg0JUU4JUFFJUFEJUU3JUJCJTgzLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/we 模式下的预训练.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>假设如上图所示，我们有个 NLP 的下游任务，比如 QA，就是问答问题，所谓问答问题，指的是给定一个问题 X，给定另外一个句子 Y，要判断句子 Y 是否是问题 X 的正确答案。</p>\n<p>问答问题假设设计的网络结构如上图所示，这里不展开讲了，懂得自然懂，不懂的也没关系，因为这点对于本文主旨来说不关键，关键是网络如何使用训练好的 Word Embedding 的。</p>\n<p>它的使用方法其实和前面讲的 NNLM 是一样的，句子中每个单词以 Onehot 形式作为输入，然后乘上学好的 Word Embedding 矩阵 Q，就直接取出单词对应的 Word Embedding 了。</p>\n<p>这乍看上去好像是个查表操作，不像是预训练的做法是吧？其实不然，<strong>那个 Word Embedding 矩阵 Q 其实就是网络 Onehot 层到 embedding 层映射的网络参数矩阵。</strong></p>\n<p>所以你看到了，使用 Word Embedding 等价于什么？等价于把 Onehot 层到 embedding 层的网络用预训练好的参数矩阵 Q 初始化了。这跟前面讲的图像领域的低层预训练过程其实是一样的，<strong>区别无非 Word Embedding 只能初始化第一层网络参数，再高层的参数就无能为力了</strong>。</p>\n<p>下游 NLP 任务在使用 Word Embedding 的时候也类似图像有两种做法，一种是 Frozen，就是 Word Embedding 那层网络参数固定不动；另外一种是 Fine-Tuning，就是 Word Embedding 这层参数使用新的训练集合训练也需要跟着训练过程更新掉。</p>\n<p>上面这种做法就是 18 年之前 NLP 领域里面采用预训练的典型做法，并且 Word Embedding 其实对于很多下游 NLP 任务是有帮助的，只是帮助没有大到闪瞎忘记戴墨镜的围观群众的双眼而已。</p>\n<h1 id=\"六-rnn-和-lstm\"><a class=\"anchor\" href=\"#六-rnn-和-lstm\">#</a> 六、RNN 和 LSTM</h1>\n<p>为什么要在这里穿插一个 RNN（Recurrent Neural Network） 和 LSTM（Long Short-Term Memory） 呢？</p>\n<p>因为接下来要介绍的 ELMo（Embeddings from Language Models） 模型在训练过程中使用了双向长短期记忆网络（Bi-LSTM）。</p>\n<p>当然，这里只是简单地介绍，想要详细了解的可以去查看网上铺天盖地的参考资料。</p>\n<h2 id=\"61-rnn\"><a class=\"anchor\" href=\"#61-rnn\">#</a> 6.1 RNN</h2>\n<p>传统的神经网络无法获取时序信息，然而<strong>时序信息在自然语言处理任务中非常重要</strong>。</p>\n<p>例如对于这一句话 “我吃了一个苹果”，“苹果” 的词性和意思，在这里取决于前面词的信息，如果没有 “我吃了一个” 这些词，“苹果” 也可以翻译为乔布斯搞出来的那个被咬了一口的苹果。</p>\n<p>也就是说，RNN 的出现，让处理时序信息变为可能。</p>\n<p>RNN 的基本单元结构如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1JOTi11bnJvbGxlZC5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/RNN-unrolled.png</span>&quot; style=&quot;zoom:36%;&quot; /&gt;</p>\n<p>上图左边部分称作 RNN 的一个 timestep，在这个 timestep 中可以看到，在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 时刻，输入变量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，通过 RNN 的一个基础模块 A，输出变量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，而 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 时刻的信息，将会传递到下一个时刻 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>。</p>\n<p>如果把模块按照时序展开，则会如上图右边部分所示，<strong>由此可以看到 RNN 为多个基础模块 A 的互连，每一个模块都会把当前信息传递给下一个模块</strong>。</p>\n<p>RNN 解决了时序依赖问题，但这里的时序一般指的是短距离的，首先我们先介绍下短距离依赖和长距离依赖的区别：</p>\n<ul>\n<li>短距离依赖：对于这个填空题 “我想看一场篮球____”，我们很容易就判断出 “篮球” 后面跟的是 “比赛”，这种短距离依赖问题非常适合 RNN。</li>\n<li>长距离依赖：对于这个填空题 “我出生在中国的瓷都景德镇，小学和中学离家都很近，……，我的母语是____”，对于短距离依赖，“我的母语是” 后面可以紧跟着 “汉语”、“英语”、“法语”，但是如果我们想精确答案，则必须回到上文中很长距离之前的表述 “我出生在中国的瓷都景德镇”，进而判断答案为 “汉语”，而 RNN 是很难学习到这些信息的。</li>\n</ul>\n<h2 id=\"62-rnn-的梯度消失问题\"><a class=\"anchor\" href=\"#62-rnn-的梯度消失问题\">#</a> 6.2 RNN 的梯度消失问题</h2>\n<p>在这里我简单讲解下 RNN 为什么不适合长距离依赖问题。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1JOTiVFNiVBOCVBMSVFNSU5RSU4QiVFNyVCQiU5MyVFNiU5RSU4NC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/RNN 模型结构.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>如上图所示，为 RNN 模型结构，前向传播过程包括：</p>\n<ul (t)=\"\">\n<li><strong>隐藏状态：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>U</mi><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>+</mo><mi>W</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h^{(t)} = \\sigma (z^{(t)}) = \\sigma(Ux^{(t)} + Wh^{(t-1)} + b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9713299999999999em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mclose\">)</span></span></span></span> ，此处激活函数一般为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">h</span></span></span></span> 。</li>\n<li><strong>模型输出：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>V</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>+</mo><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">o^{(t)} = Vh^{(t)} + c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9713299999999999em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span></li>\n<li><strong>预测输出：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{y}^{(t)} = \\sigma(o^{(t)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> ，此处激活函数一般为 softmax。</li>\n<li><strong>模型损失：</strong>L = \\sum_{t = 1}^{T} L^</li>\n</ul>\n<p>RNN 所有的 timestep 共享一套参数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>U</mi><mo separator=\"true\">,</mo><mi>V</mi><mo separator=\"true\">,</mo><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">U,V,W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span>，在 RNN 反向传播过程中，需要计算 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>U</mi><mo separator=\"true\">,</mo><mi>V</mi><mo separator=\"true\">,</mo><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">U,V,W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span> 等参数的梯度，以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span> 的梯度表达式为例（假设 RNN 模型的损失函数为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi></mrow><annotation encoding=\"application/x-tex\">L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">L</span></span></span></span>）：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>W</mi></mrow></mfrac><mo>=</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mrow><mo fence=\"true\">(</mo><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></munderover><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>W</mi></mrow></mfrac><mtext> </mtext><mspace linebreak=\"newline\"></mspace><mo>=</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>o</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mrow><mo fence=\"true\">(</mo><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>t</mi><mi>a</mi><mi>n</mi><msup><mi>h</mi><msup><mrow></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></msup><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mi>W</mi><mo fence=\"true\">)</mo></mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>W</mi></mrow></mfrac><mtext> </mtext><mspace linebreak=\"newline\"></mspace><mspace width=\"1em\"/><mtext>公式(9)</mtext></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial L}{\\partial W} \n= \\sum_{t = 1}^{T} \\frac{\\partial L}{\\partial y^{(T)}} \\frac{\\partial y^{(T)}}{\\partial o^{(T)}} \\frac{\\partial o^{(T)}}{\\partial h^{(T)}} \\left( \\prod_{k=t + 1}^{T} \\frac{\\partial h^{(k)}}{\\partial h^{(k - 1)}} \\right) \\frac{\\partial h^{(t)}}{\\partial W} \\  \\\\ \n= \\sum_{t = 1}^{T} \\frac{\\partial L}{\\partial y^{(T)}} \\frac{\\partial y^{(T)}}{\\partial o^{(T)}} \\frac{\\partial o^{(T)}}{\\partial h^{(T)}} \\left( \\prod_{k=t+1}^{T} tanh^{&#x27;}(z^{(k)}) W \\right) \\frac{\\partial h^{(t)}}{\\partial W} \\  \\\\\n\\quad\\text{公式(9)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.05744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\">L</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1887800000000004em;vertical-align:-1.360444em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\">L</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8984399999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">(</span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.8478869999999998em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.0500049999999996em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.300005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.360444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\"> </span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1887800000000004em;vertical-align:-1.360444em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\">L</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8984399999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">(</span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.8478869999999998em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.0500049999999996em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.300005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.360444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.99248em;\"><span style=\"top:-2.99248em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.57948em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\"> </span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">公式</span><span class=\"mord\">(9)</span></span></span></span></span></span></p>\n<p>对于公式（9）中的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mrow><mo fence=\"true\">(</mo><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow><mo>=</mo><mrow><mo fence=\"true\">(</mo><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mi>t</mi><mi>a</mi><mi>n</mi><msup><mi>h</mi><msup><mrow></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></msup><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mi>W</mi><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left( \\prod_{k=t + 1}^{T} \\frac{\\partial h^{(k)}}{\\partial h^{(k - 1)}} \\right) = \\left( \\prod_{k=t+1}^{T} tanh^{&#x27;}(z^{(k)}) W \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0707em;\"><span style=\"top:-2.614575em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8220357142857143em;\"><span style=\"top:-2.8220357142857138em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9667142857142857em;\"><span style=\"top:-2.966714285714285em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.38542499999999996em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.94248em;\"><span style=\"top:-2.94248em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.57948em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> 的导数总是小于 1 的，由于是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>−</mo><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">T-(t+1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span> 个 timestep 参数的连乘，<strong>如果 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span> 的主特征值小于 1，梯度便会消失；如果 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span></span> 的特征值大于 1，梯度便会爆炸。</strong></p>\n<p>需要注意的是，RNN 和 DNN 梯度消失和梯度爆炸含义并不相同。</p>\n<p>RNN 中权重在各时间步内共享，最终的梯度是各个时间步的梯度和，梯度和会越来越大。因此，RNN 中总的梯度是不会消失的，即使梯度越传越弱，也只是远距离的梯度消失。 从公式（9）中的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mi>t</mi><mi>a</mi><mi>n</mi><msup><mi>h</mi><msup><mrow></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></msup><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mi>W</mi><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( \\prod_{k=t+1}^{T} tanh^{&#x27;}(z^{(k)}) W \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.94248em;\"><span style=\"top:-2.94248em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.57948em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span> 可以看到，<strong>RNN 所谓梯度消失的真正含义是，梯度被近距离（<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mtext>趋向于</mtext><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">t+1 趋向于 T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord cjk_fallback\">趋</span><span class=\"mord cjk_fallback\">向</span><span class=\"mord cjk_fallback\">于</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span>）梯度主导，远距离（<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mtext>远离</mtext><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">t+1 远离 T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord cjk_fallback\">远</span><span class=\"mord cjk_fallback\">离</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span>）梯度很小，导致模型难以学到远距离的信息。</strong></p>\n<h2 id=\"63-lstm\"><a class=\"anchor\" href=\"#63-lstm\">#</a> 6.3 LSTM</h2>\n<p>为了解决 RNN 缺乏的序列长距离依赖问题，LSTM 被提了出来，首先我们来看看 LSTM 相对于 RNN 做了哪些改进：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL0xTVE0lRTYlQTglQTElRTUlOUUlOEIlRTclQkIlOTMlRTYlOUUlODQuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/LSTM 模型结构.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>如上图所示，为 LSTM 的 RNN 门控结构（LSTM 的 timestep），LSTM 前向传播过程包括：</p>\n<ul>\n<li>** 遗忘门：** 决定了丢弃哪些信息，遗忘门接收 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 时刻的状态 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span>，以及当前的输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，经过 Sigmoid 函数后输出一个 0 到 1 之间的值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>\n<ul>\n<li>输出： <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mi>f</mi></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>U</mi><mi>f</mi></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>f</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_{t} = \\sigma(W_fh_{t-1} + U_fx_{t} + b_f)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n</ul>\n</li>\n<li>** 输入门：** 决定了哪些新信息被保留，并更新细胞状态，输入们的取值由 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 决定，通过 Sigmoid 函数得到一个 0 到 1 之间的值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>i</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">i_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，而 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> 函数则创造了一个当前细胞状态的候选 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">a_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>\n<ul>\n<li>输出：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>i</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mi>i</mi></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>U</mi><mi>i</mi></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">i_{t} = \\sigma(W_ih_{t-1} + U_ix_{t} + b_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> , <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><msub><mi>C</mi><mi>t</mi></msub><mo>~</mo></mover><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><msub><mi>W</mi><mi>a</mi></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>U</mi><mi>a</mi></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>a</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{C_{t} }= tanhW_ah_{t-1} + U_ax_{t} + b_a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">h</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n</ul>\n</li>\n<li>** 细胞状态：** 旧细胞状态 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>C</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">C_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.891661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 被更新到新的细胞状态 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>C</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">C_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 上，\n<ul>\n<li>输出：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>C</mi><mi>t</mi></msub><mo>=</mo><msub><mi>C</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>⊙</mo><msub><mi>f</mi><mi>t</mi></msub><mo>+</mo><msub><mi>i</mi><mi>t</mi></msub><mo>⊙</mo><mover accent=\"true\"><msub><mi>C</mi><mi>t</mi></msub><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">C_{t} = C_{t-1}\\odot f_{t} + i_{t}\\odot \\tilde{C_{t} }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.891661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⊙</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⊙</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></li>\n</ul>\n</li>\n<li t=\"\">** 输出门：** 决定了最后输出的信息，输出门取值由 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 决定，通过 Sigmoid 函数得到一个 0 到 1 之间的值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">o_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，最后通过 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> 函数决定最后输出的信息\n<ul>\n<li>输出：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mi>o</mi></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>U</mi><mi>o</mi></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">o_{t} = \\sigma(W_oh_{t-1} + U_ox_{t} + b_o)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> , h_{t} = o_{t}\\odot tanhC_</li>\n</ul>\n</li>\n<li><strong>预测输出：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>V</mi><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{t} = \\sigma(Vh_{t}+c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span></span></span></span></li>\n</ul>\n<h2 id=\"64-lstm-解决-rnn-的梯度消失问题\"><a class=\"anchor\" href=\"#64-lstm-解决-rnn-的梯度消失问题\">#</a> 6.4 LSTM 解决 RNN 的梯度消失问题</h2>\n<p>明白了 RNN 梯度消失的原因之后，我们看 LSTM 如何解决问题的呢？</p>\n<p>RNN 梯度消失的原因是，随着梯度的传导，梯度被近距离梯度主导，模型难以学习到远距离的信息。具体原因也就是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>h</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>h</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\prod_{k=t+1}^{T}\\frac{\\partial h_{k}}{\\partial h_{k - 1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4737559999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 部分，在迭代过程中，每一步 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>h</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>h</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial h_{k}}{\\partial h_{k - 1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3944929999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> <strong>始终在 [0,1) 之间或者始终大于 1。</strong></p>\n<p>而对于 LSTM 模型而言，针对 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\prod _{k=t+1}^{T} \\frac{\\partial C_{k}}{\\partial C_{k-1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4737559999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 求得：</p>\n\\begin{align}\n& \\frac{\\partial C_{k}}{\\partial C_{k-1}} = f_k + other \\\\\n& \\prod _{k=t+1}^{T} \\frac{\\partial C_{k}}{\\partial C_{k-1}} = f_{k}f_{k+1}...f_{T} + other  \\\\\n\\end{align}\n\n<p>在 LSTM 迭代过程中，针对 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\prod_{k=t+1}^{T} \\frac{\\partial C_{k}}{\\partial C_{k-1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4737559999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 而言，每一步<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial C_{k}}{\\partial C_{k-1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3944929999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> <strong>可以自主的选择在 [0,1] 之间，或者大于 1</strong>，因为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_{k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是可训练学习的。那么整体 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>C</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\prod _{k=t+1}^{T} \\frac{\\partial C_{k}}{\\partial C_{k-1}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4737559999999998em;vertical-align:-0.4925249999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35804100000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9019679999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.21074999999999994em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.41586em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4925249999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 也就不会一直减小，远距离梯度不至于完全消失，也就能够解决 RNN 中存在的梯度消失问题。</p>\n<p>LSTM 遗忘门值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 可以选择在 [0,1] 之间，让 LSTM 来改善梯度消失的情况。也可以选择接近 1，让遗忘门饱和，此时远距离信息梯度不消失；也可以选择接近 0，此时模型是故意阻断梯度流，遗忘之前信息。</p>\n<p>另外需要强调的是 LSTM 搞的这么复杂，<strong>除了在结构上天然地克服了梯度消失的问题，更重要的是具有更多的参数来控制模型</strong>；通过四倍于 RNN 的参数量，可以更加精细地预测时间序列变量。</p>\n<p>此外，我记得有一篇文章讲到，<strong>LSTM 在 200 左右长度的文本上，就已经捉襟见肘了</strong>。</p>\n<h1 id=\"七-elmo-模型\"><a class=\"anchor\" href=\"#七-elmo-模型\">#</a> 七、ELMo 模型</h1>\n<h2 id=\"71-elmo-的预训练\"><a class=\"anchor\" href=\"#71-elmo-的预训练\">#</a> 7.1 ELMo 的预训练</h2>\n<p>在讲解 Word Embedding 时，细心地读者一定已经发现，这些词表示方法本质上是静态的，每一个词都有一个唯一确定的词向量，不能根据句子的不同而改变，无法处理自然语言处理任务中的多义词问题。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3dlJUU1JUE0JTlBJUU0JUI5JTg5JUU4JUFGJThEJUU5JTk3JUFFJUU5JUEyJTk4LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/we 多义词问题.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>如上图所示，例如多义词 Bank，有两个常用含义，但是 Word Embedding 在对 bank 这个单词进行编码的时候，是区分不开这两个含义的。</p>\n<p>因为尽管这两句含有 bank 的句子中 bank 上下文环境中出现的单词不同，但是在用语言模型训练的时候，不论什么上下文的句子经过 Word2Vec，都是预测相同的单词 bank，而同一个单词占用的是同一行的参数空间，这会导致两种不同的上下文信息都会编码到相同的 Word Embedding 空间里，进而导致 Word Embedding 无法区分多义词的不同语义。</p>\n<p>所以对于比如 Bank 这个词，它事先学好的 Word Embedding 中混合了几种语义 ，在应用中来了个新句子，即使从上下文中（比如句子包含 money 等词）明显可以看出它代表的是 “银行” 的含义，但是对应的 Word Embedding 内容也不会变，它还是混合了多种语义。</p>\n<p>针对 Word Embedding 中出现的多义词问题，ELMo 提供了一个简洁优雅的解决方案。</p>\n<p>ELMo 的本质思想是：我事先用语言模型学好一个单词的 Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用 Word Embedding 的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义再去调整单词的 Word Embedding 表示，这样经过调整后的 Word Embedding 更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以 ELMo 本身是个根据当前上下文对 Word Embedding 动态调整的思路。</p>\n<p>ELMo 采用了典型的两阶段过程：</p>\n<ol>\n<li>第一个阶段是利用语言模型进行预训练；</li>\n<li>第二个阶段是在做下游任务时，从预训练网络中提取对应单词的网络各层的 Word Embedding 作为新特征补充到下游任务中。</li>\n</ol>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU5RiVCQSVFNCVCQSU4RSVFNCVCOCU4QSVFNCVCOCU4QiVFNiU5NiU4NyVFNyU5QSU4NGVtZWRkaW5nLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 基于上下文的 emedding.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图展示的是其第一阶段预训练过程，它的网络结构采用了双层双向 LSTM，目前语言模型训练的任务目标是根据单词 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的上下文去正确预测单词 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 之前的单词序列 Context-before 称为上文，之后的单词序列 Context-after 称为下文。</p>\n<p>图中左端的前向双层 LSTM 代表正方向编码器，输入的是从左到右顺序的除了预测单词外 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的上文 Context-before；右端的逆向双层 LSTM 代表反方向编码器，输入的是从右到左的逆序的句子下文 Context-after；每个编码器的深度都是两层 LSTM 叠加。</p>\n<p>这个网络结构其实在 NLP 中是很常用的。使用这个网络结构利用大量语料做语言模型任务就能预先训练好这个网络，如果训练好这个网络后，输入一个新句子 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{new}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ，句子中每个单词都能得到对应的三个 Embedding：</p>\n<ul>\n<li>最底层是单词的 Word Embedding；</li>\n<li>往上走是第一层双向 LSTM 中对应单词位置的 Embedding，这层编码单词的句法信息更多一些；</li>\n<li>再往上走是第二层 LSTM 中对应单词位置的 Embedding，这层编码单词的语义信息更多一些。</li>\n</ul>\n<p>也就是说，ELMo 的预训练过程不仅仅学会单词的 Word Embedding，还学会了一个双层双向的 LSTM 网络结构，而这两者后面都有用。</p>\n<h2 id=\"72-elmo-的-feature-based-pre-training\"><a class=\"anchor\" href=\"#72-elmo-的-feature-based-pre-training\">#</a> 7.2 ELMo 的 Feature-based Pre-Training</h2>\n<p>上面介绍的是 ELMo 的第一阶段：预训练阶段。那么预训练好网络结构后，如何给下游任务使用呢？</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VsbW8lRTglQUUlQUQlRTclQkIlODMlRTUlOTAlOEUlRTclOUElODQlRTQlQkQlQkYlRTclOTQlQTguanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/elmo 训练后的使用.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图展示了下游任务的使用过程，比如我们的下游任务仍然是 QA 问题，此时对于问句 X：</p>\n<ol>\n<li>我们可以先将句子 X 作为预训练好的 ELMo 网络的输入，这样句子 X 中每个单词在 ELMO 网络中都能获得对应的三个 Embedding；</li>\n<li>之后给予这三个 Embedding 中的每一个 Embedding 一个权重 a，这个权重可以学习得来，根据各自权重累加求和，将三个 Embedding 整合成一个；</li>\n<li>然后将整合后的这个 Embedding 作为 X 句在自己任务的那个网络结构中对应单词的输入，以此作为补充的新特征给下游任务使用。</li>\n<li>对于上图所示下游任务 QA 中的回答句子 Y 来说也是如此处理。</li>\n</ol>\n<p><strong>因为 ELMo 给下游提供的是每个单词的特征形式，所以这一类预训练的方法被称为 “Feature-based Pre-Training”。</strong></p>\n<p>至于为何这么做能够达到区分多义词的效果，原因在于在训练好 ELMo 后，<strong>在特征提取的时候，每个单词在两层 LSTM 上都会有对应的节点，这两个节点会编码单词的一些句法特征和语义特征，并且它们的 Embedding 编码是动态改变的</strong>，会受到上下文单词的影响，周围单词的上下文不同应该会强化某种语义，弱化其它语义，进而就解决了多义词的问题。</p>\n<h1 id=\"八-attention\"><a class=\"anchor\" href=\"#八-attention\">#</a> 八、Attention</h1>\n<p>上面巴拉巴拉了一堆，都在为 BERT 的讲解做铺垫，而接下来要叙述的 Attention 和 Transformer 同样如此，它们都只是 BERT 构成的一部分。</p>\n<h2 id=\"81-人类的视觉注意力\"><a class=\"anchor\" href=\"#81-人类的视觉注意力\">#</a> 8.1 人类的视觉注意力</h2>\n<p>Attention 是注意力的意思，从它的命名方式看，很明显借鉴了人类的注意力机制，因此，我们首先介绍人类的视觉注意力。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCQSVCQSVFNyVCMSVCQiVFNyU5QSU4NCVFOCVBNyU4NiVFOCVBNyU4OSVFNiVCMyVBOCVFNiU4NCU4RiVFNSU4QSU5Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 人类的视觉注意力.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>视觉注意力机制是人类视觉所特有的大脑信号处理机制。人类视觉通过快速扫描全局图像，获得需要重点关注的目标区域，也就是一般所说的注意力焦点，而后对这一区域投入更多注意力资源，以获取更多所需要关注目标的细节信息，而抑制其他无用信息。</p>\n<p>这是人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段，是人类在长期进化中形成的一种生存机制，人类视觉注意力机制极大地提高了视觉信息处理的效率与准确性。</p>\n<p>上图形象化展示了人类在看到一副图像时是如何高效分配有限的注意力资源的，<strong>其中红色区域表明视觉系统更关注的目标</strong>，很明显对于上图所示的场景，人们会把注意力更多投入到人的脸部，文本的标题以及文章首句等位置。</p>\n<p>深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，<strong>核心目标也是从众多信息中选择出对当前任务目标更关键的信息。</strong></p>\n<h2 id=\"82-attention-的本质思想\"><a class=\"anchor\" href=\"#82-attention-的本质思想\">#</a> 8.2 Attention 的本质思想</h2>\n<p>从人类的视觉注意力可以看出，注意力模型 Attention 的本质思想为：从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略不重要的信息。</p>\n<p>在详细讲解 Attention 之前，我们在讲讲 Attention 的其他作用。之前我们讲解 LSTM 的时候说到，虽然 LSTM 解决了序列长距离依赖问题，但是单词超过 200 的时候就会失效。<strong>而 Attention 机制可以更加好的解决序列长距离依赖问题，并且具有并行计算能力</strong>。现在不明白这点不重要，随着我们对 Attention 的慢慢深入，相信你会明白。</p>\n<p>首先我们得明确一个点，注意力模型从大量信息 Values 中筛选出少量重要信息，这些重要信息一定是相对于另外一个信息 Query 而言是重要的，例如对于上面那张婴儿图，Query 就是观察者。也就是说，我们要搭建一个注意力模型，我们必须得要有一个 Query 和一个 Values，然后通过 Query 这个信息从 Values 中筛选出重要信息。</p>\n<p>通过 Query 这个信息从 Values 中筛选出重要信息，简单点说，<strong>就是计算 Query 和 Values 中每个信息的相关程度。</strong></p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2F0dGVudGlvbi0lRTglQUUlQTElRTclQUUlOTclRTUlOUIlQkUucG5n\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention - 计算图.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>再具体点，通过上图，Attention 通常可以进行如下描述，表示为将 Query (Q) 和 key-value pairs（<strong>把 Values 拆分成了键值对的形式</strong>） 映射到输出上，其中 query、每个 key、每个 value 都是向量，输出是 V 中所有 values 的加权，其中权重是由 Query 和每个 key 计算出来的，计算方法分为三步：</p>\n<ol>\n<li>第一步：计算比较 Q 和 K 的相似度，用 f 来表示：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mspace width=\"1em\"/><mi>i</mi><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">f(Q,K_i)\\quad i=1,2,\\cdots,m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>，一般第一步计算方法包括四种\n<ol>\n<li>点乘（<strong>Transformer 使用</strong>）：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>Q</mi><mi>T</mi></msup><msub><mi>K</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">f(Q,K_i) = Q^T K_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>权重：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>Q</mi><mi>T</mi></msup><mi>W</mi><msub><mi>K</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">f(Q,K_i) = Q^TWK_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>拼接权重：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mo stretchy=\"false\">[</mo><msup><mi>Q</mi><mi>T</mi></msup><mo separator=\"true\">;</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">f(Q,K_i) = W[Q^T;K_i]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></li>\n<li>感知器：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>V</mi><mi>T</mi></msup><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>W</mi><mi>Q</mi><mo>+</mo><mi>U</mi><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(Q,K_i)=V^T \\tanh(WQ+UK_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">tanh</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n</ol>\n</li>\n<li>第二步：将得到的相似度进行 softmax 操作，进行归一化：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><msub><msqrt><mi>d</mi></msqrt><mi>k</mi></msub></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha_i = softmax(\\frac{f(Q,K_i)}{\\sqrt d_k})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.5979999999999999em;vertical-align:-0.588em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.5335085em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.937845em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal mtight\" style=\"padding-left:0.833em;\">d</span></span><span style=\"top:-2.8978450000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.102155em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3224449999999999em;\"><span style=\"top:-2.3264164285714286em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17358357142857145em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">Q</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.07153em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.588em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span>\n<ol>\n<li>这里简单讲解除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><msqrt><mi>d</mi></msqrt><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\sqrt d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0897000000000001em;vertical-align:-0.15747999999999998em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93222em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"padding-left:0.833em;\">d</span></span><span style=\"top:-2.89222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.10777999999999999em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3286279999999999em;\"><span style=\"top:-2.54252em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15747999999999998em;\"><span></span></span></span></span></span></span></span></span></span> 的作用：假设 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> , <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 里的元素的均值为 0，方差为 1，那么 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mo>=</mo><msup><mi>Q</mi><mi>T</mi></msup><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">A^T=Q^TK</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 中元素的均值为 0，方差为 d。当 d 变得很大时， <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 中的元素的方差也会变得很大，如果 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 中的元素方差很大 (分布的方差大，分布集中在绝对值大的区域)，<strong>在数量级较大时， softmax 将几乎全部的概率分布都分配给了最大值对应的标签</strong>，由于某一维度的数量级较大，进而会导致 softmax 未来求梯度时会消失。总结一下就是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">softmax</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mi>A</mi><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\operatorname{softmax}\\left(A\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">s</span><span class=\"mord mathrm\">o</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span><span class=\"mord mathrm\">t</span><span class=\"mord mathrm\">m</span><span class=\"mord mathrm\">a</span><span class=\"mord mathrm\">x</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span> 的分布会和 d 有关。因此 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 中每一个元素乘上 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{\\sqrt{d_k}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.538em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.5864385em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8622307142857143em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8222307142857144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17776928571428574em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 后，方差又变为 1，并且 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 的数量级也将会变小。</li>\n</ol>\n</li>\n<li>第三步：针对计算出来的权重 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\alpha_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，对 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 中的所有 values 进行加权求和计算，得到 Attention 向量：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><msub><mi>α</mi><mi>i</mi></msub><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">Attention = \\sum_{i=1}^m \\alpha_i V_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.104002em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n</ol>\n<h2 id=\"83-self-attention-模型\"><a class=\"anchor\" href=\"#83-self-attention-模型\">#</a> 8.3 Self Attention 模型</h2>\n<p>上面已经讲了 Attention 就是从一堆信息中筛选出重要的信息，现在我们来通过 Self Attention 模型来详细讲解如何找到这些重要的信息。</p>\n<p>Self Attention 模型的架构如下图所示，接下来我们将按照这个模型架构的顺序来逐一解释。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>首先可以看到 Self Attention 有三个输入 Q、K、V：<strong>对于 Self Attention，Q、K、V 来自句子 X 的 词向量 x 的线性转化，即对于词向量 x，给定三个可学习的矩阵参数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>Q</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>k</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_Q,W_k,W_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，x 分别右乘上述矩阵得到 Q、K、V</strong>。</p>\n<p>接下来为了表示的方便，我们先通过向量的计算叙述 Self Attention 计算的流程，然后再描述 Self Attention 的矩阵计算过程</p>\n<ol>\n<li>\n<p>第一步，Q、K、V 的获取</p>\n<ol>\n<li></li>\n</ol>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3Frdi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qkv.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图操作：两个单词 Thinking 和 Machines。通过线性变换，即 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 两个向量分别与<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>k</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_q,W_k,W_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 三个矩阵点乘得到 ${q_1,q_2},{k_1,k_2},{v_1,v_2} $ 共 6 个向量。矩阵 Q 则是向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">q_1,q_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的拼接，K、V 同理。</p>\n</li>\n<li>\n<p>第二步，MatMul</p>\n<ol>\n<li>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1EtSyVFNCVCOSU5OCVFNyVBNyVBRi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/Q-K 乘积.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图操作：向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">{q_1,k_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 做点乘得到得分 112， <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">{q_1,k_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 做点乘得到得分 96。注意：<strong>这里是通过 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">q_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 这个信息找到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1,x_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 中的重要信息。</strong></p>\n</li>\n</ol>\n</li>\n<li>\n<p>第三步和第四步，Scale + Softmax</p>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3FrLXNjYWxlLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qk-scale.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n<p>上图操作：对该得分进行规范，除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo>=</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">\\sqrt {d_k} = 8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.18278000000000005em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">8</span></span></span></span></p>\n</li>\n<li>\n<p>第五步，MatMul</p>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3FrLXNvZnRtYXguanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qk-softmax.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n</li>\n</ol>\n<p>用得分比例 [0.88，0.12] 乘以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[v_1,v_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span> 值得到一个加权后的值，将这些值加起来得到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。</p>\n<p>上述所说就是 Self Attention 模型所做的事，仔细感受一下，用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">q_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">K=[k_1,k_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span> 去计算一个 Thinking 相对于 Thinking 和 Machine 的权重，再用权重乘以 Thinking 和 Machine 的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">V=[v_1,v_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span> 得到加权后的 Thinking 和 Machine 的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">V=[v_1,v_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>，最后求和得到针对各单词的输出 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。</p>\n<p>同理可以计算出 Machine 相对于 Thinking 和 Machine 的加权输出 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，拼接 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 即可得到 Attention 值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">Z=[z_1,z_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>，这就是 Self Attention 的矩阵计算，如下所示。</p>\n<p>之前的例子是单个向量的运算例子。这张图展示的是矩阵运算的例子，输入是一个 [2x4] 的矩阵（句子中每个单词的词向量的拼接），每个运算是 [4x3] 的矩阵，求得 Q、K、V。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1FLVi0lRTclOUYlQTklRTklOTglQjUlRTglQTElQTglRTclQTQlQkEuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV - 矩阵表示.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>Q 对 K 转制做点乘，除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><msqrt><mi>d</mi></msqrt><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\sqrt d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0897000000000001em;vertical-align:-0.15747999999999998em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93222em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"padding-left:0.833em;\">d</span></span><span style=\"top:-2.89222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.10777999999999999em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3286279999999999em;\"><span style=\"top:-2.54252em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15747999999999998em;\"><span></span></span></span></span></span></span></span></span></span>，做一个 softmax 得到合为 1 的比例，对 V 做点乘得到输出 Z。那么这个 Z 就是一个考虑过 Thinking 周围单词 Machine 的输出。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1FLVlotJUU3JUJCJTkzJUU2JTlFJTlDLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKVZ - 结果.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>注意看这个公式，<strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">QK^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span> 其实就会组成一个 word2word 的 attention map！</strong>（加了 softmax 之后就是一个合为 1 的权重了）。比如说你的输入是一句话 &quot;i have a dream&quot; 总共 4 个单词，这里就会形成一张 4x4 的注意力机制的图：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNiVCMyVBOCVFNiU4NCU4RiVFNSU4QSU5QiVFNiU5QyVCQSVFNSU4OCVCNiVFNyU5RiVBOSVFOSU5OCVCNSVFNSU5QiVCRS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 注意力机制矩阵图.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>这样一来，每一个单词对应每一个单词都会有一个权重，<strong>这也是 Self Attention 名字的来源，即 Attention 的计算来源于 Source（源句） 和 Source 本身，通俗点讲就是 Q、K、V 都来源于输入 X 本身。</strong></p>\n<h2 id=\"84-self-attention-和-rnn-lstm-的区别\"><a class=\"anchor\" href=\"#84-self-attention-和-rnn-lstm-的区别\">#</a> 8.4 Self Attention 和 RNN、LSTM 的区别</h2>\n<p>引入 Self Attention 有什么好处呢？或者说通过 Self Attention 到底学到了哪些规律或者抽取出了哪些特征呢？我们可以通过下述两幅图来讲解：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLSVFNSVBNSVCRCVFNSVBNCU4NDEuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention - 好处 1.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLSVFNSVBNSVCRCVFNSVBNCU4NDIuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention - 好处 2.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>从上述两张图可以看出，Self Attention 可以捕获同一个句子中单词之间的一些句法特征（例如第一张图展示的有一定距离的短语结构）或者语义特征（例如第二张图展示的 its 的指代对象为 Law）。</p>\n<p>有了上述的讲解，我们现在可以来看看 Self Attention 和 RNN、LSTM 的区别：</p>\n<ul>\n<li>RNN、LSTM：如果是 RNN 或者 LSTM，需要依次序列计算，对于远距离的相互依赖的特征，<strong>要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小</strong>。</li>\n<li>Self Attention：\n<ul>\n<li>通过上述两幅图，很明显的可以看出，引入 Self Attention 后会更容易捕获句子中长距离的相互依赖的特征，<strong>因为 Self Attention 在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征</strong>；</li>\n<li>除此之外，Self<br />\nAttention 对于<strong>一句话中的每个单词都可以单独的进行 Attention 值的计算</strong>，也就是说 Self Attention 对计算的并行性也有直接帮助作用，而对于必须得依次序列计算的 RNN 而言，是无法做到并行计算的。</li>\n</ul>\n</li>\n</ul>\n<p>从上面的计算步骤和图片可以看出，<strong>无论句子序列多长，都可以充分捕获近距离上往下问中的任何依赖关系，进而可以很好的提取句法特征还可以提取语义特征</strong>；而且对于一个句子而言，<strong>每个单词的计算是可以并行处理的</strong>。</p>\n<p>理论上 Self-Attention （Transformer 50 个左右的单词效果最好）解决了 RNN 模型的长序列依赖问题，但是由于文本长度增加时，训练时间也将会呈指数增长，因此在处理长文本任务时可能不一定比 LSTM（200 个左右的单词效果最好） 等传统的 RNN 模型的效果好。</p>\n<p>上述所说的，则是为何 Self Attention 逐渐替代 RNN、LSTM 被广泛使用的原因所在。</p>\n<h2 id=\"85-masked-self-attention-模型\"><a class=\"anchor\" href=\"#85-masked-self-attention-模型\">#</a> 8.5 Masked Self Attention 模型</h2>\n<p>趁热打铁，我们讲讲 Transformer 未来会用到的 Masked Self Attention 模型，这里的 Masked 就是要在做语言模型（或者像翻译）的时候，不给模型看到未来的信息，它的结构如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2tlZC1hdHRlbnRpb24uanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/masked-attention.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图中和 Self Attention 重复的部分此处就不讲了，主要讲讲 Mask 这一块。</p>\n<p>假设在此之前我们已经通过 scale 之前的步骤得到了一个 attention map，<strong>而 mask 就是沿着对角线把灰色的区域用 0 覆盖掉，不给模型看到未来的信息</strong>，如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2stYXR0ZW50aW9uLW1hcC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>详细来说：</p>\n<ol>\n<li>&quot;i&quot; 作为第一个单词，只能有和 &quot;i&quot; 自己的 attention；</li>\n<li>&quot;have&quot; 作为第二个单词，有和 &quot;i、have&quot; 前面两个单词的 attention；</li>\n<li>&quot;a&quot; 作为第三个单词，有和 &quot;i、have、a&quot; 前面三个单词的 attention；</li>\n<li>&quot;dream&quot; 作为最后一个单词，才有对整个句子 4 个单词的 attention。</li>\n</ol>\n<p>并且在做完 softmax 之后，横轴结果合为 1。如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2stYXR0ZW50aW9uLW1hcC1zb2Z0bWF4LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>具体为什么要 mask，未来再讲解 Transformer 的时候我们会详细解释。</p>\n<h2 id=\"86-multi-head-self-attention-模型\"><a class=\"anchor\" href=\"#86-multi-head-self-attention-模型\">#</a> 8.6 Multi-head Self Attention 模型</h2>\n<p>由于 Transformer 使用的都是 Self Attention 的进阶版 Multi-head Self Attention，我们简单讲讲  Multi-head Self Attention 的架构，并且在该小节结尾处讲讲它的优点。</p>\n<p>Multi-Head Attention 就是把 Self Attention 得到的注意力值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi></mrow><annotation encoding=\"application/x-tex\">Z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span></span> 切分成 n 个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Z</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>Z</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>Z</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">Z_1,Z_2,\\cdots,Z_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，然后通过全连接层获得新的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>Z</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></mrow><annotation encoding=\"application/x-tex\">Z&#x27;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span>.</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL211bHRpLWhlYWQtYXR0ZW50aW9uLnBuZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-attention.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>我们还是以上面的形式来解释，我们对 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi></mrow><annotation encoding=\"application/x-tex\">Z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span></span> 进行 8 等份的切分得到 8 个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">Z_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLzgtaGVhZC1hdHRlbnRpb24uanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/8-head-attention.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>为了使得输出与输入结构相同，拼接矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">Z_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 后乘以一个线性 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">W_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 得到最终的 Z：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLzgtei0lRTYlOEIlQkMlRTYlOEUlQTUuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/8-z - 拼接.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>可以通过下图看看 multi-head attention 的整个流程：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL211bHRpLWhlYWQtJUU2JThCJUJDJUU2JThFJUE1LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head - 拼接.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上述操作有什么好处呢？<strong>多头相当于把原始信息 Source 放入了多个子空间中，也就是捕捉了多个信息，对于使用 multi-head（多头） attention 的简单回答就是，多头保证了 attention 可以注意到不同子空间的信息，捕捉到更加丰富的特征信息</strong>。其实本质上是论文原作者发现这样效果确实好。</p>\n<h1 id=\"九-position-embedding\"><a class=\"anchor\" href=\"#九-position-embedding\">#</a> 九、Position Embedding</h1>\n<p>在 Attention 和 RNN、LSTM 的对比中，我们说到 Attention 解决了长距离依赖问题，并且可以支持并行化，但是它就真的百利而无一害了吗？</p>\n<p>其实不然，我们往前回顾，Self Attention 的 Q、K、V 三个矩阵是由同一个输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub><mo>=</mo><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">X_1=(x_1,x_2,\\cdots,x_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 线性转换而来，也就是说对于这样的一个被打乱序列顺序的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub><mo>=</mo><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">X_2=(x_2,x_1,\\cdots,x_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 而言，<strong>由于 Attention 值的计算最终会被加权求和，也就是说两者最终计算的 Attention 值都是一样的，进而也就表明了 Attention 丢掉了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">X_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的序列顺序信息。</strong></p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSU5MCU5MSVFOSU4NyU4Ri5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置向量.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>如上图所示，为了解决 Attention 丢失的序列顺序信息，Transformer 的提出者提出了 Position Embedding，也就是对于输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> 进行 Attention 计算之前，在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> 的词向量中加上位置信息，也就是说 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> 的词向量为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mrow><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi mathvariant=\"normal\">_</mi><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>=</mo><mi>E</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo>+</mo><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>a</mi><mi>l</mi><mtext> </mtext><mi>E</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">X_{final\\_embedding} = Embedding + Positional\\, Embedding</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05033em;vertical-align:-0.367em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mtight\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">b</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.367em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span></p>\n<p>但是如何得到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> 的位置向量呢？</p>\n<p>其中位置编码公式如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU4NSVBQyVFNSVCQyU4Ri5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码公式.png</span>&quot; style=&quot;zoom:33%;&quot; /&gt;</p>\n<p>其中 pos 表示位置、i 表示维度、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示位置向量的向量维度 、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>i</mi><mtext>、</mtext><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">2i、2i+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">i</span><span class=\"mord cjk_fallback\">、</span><span class=\"mord\">2</span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 表示的是奇偶数（奇偶维度），上图所示就是偶数位置使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>sin</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\sin</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66786em;vertical-align:0em;\"></span><span class=\"mop\">sin</span></span></span></span> 函数，奇数位置使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>cos</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\cos</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mop\">cos</span></span></span></span> 函数。</p>\n<p>有了位置编码，我们再来看看位置编码是如何嵌入单词编码的（其中 512 表示编码维度），<strong>通过把单词的词向量和位置向量进行叠加，这种方式就称作位置嵌入</strong>，如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU5MiU4QyVFOCVBRiU4RCVFNSU5MCU5MSVFOSU4NyU4RiVFNCVCOSU4QiVFNSU5MiU4Qy5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码和词向量之和.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p><strong>Position Embedding 本身是一个绝对位置的信息</strong>，但在语言模型中，相对位置也很重要。那么为什么位置嵌入机制有用呢？</p>\n<p>我们不要去关心三角函数公式，可以看看下图公式（3）中的第一行，我们做如下的解释，对于 “我爱吃苹果” 这一句话，有 5 个单词，假设序号分别为 1、2、3、4、5。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSVCNSU4QyVFNSU4NSVBNSVFOCVBNyVBMyVFOSU4NyU4QS5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置嵌入解释.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>假设 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>=</mo><mn>1</mn><mo>=</mo><mtext>我、</mtext><mi>k</mi><mo>=</mo><mn>2</mn><mo>=</mo><mtext>爱、</mtext><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi><mo>=</mo><mn>3</mn><mo>=</mo><mtext>吃</mtext></mrow><annotation encoding=\"application/x-tex\">pos=1=我、k=2=爱、pos+k=3=吃</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">我</span><span class=\"mord cjk_fallback\">、</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord cjk_fallback\">爱</span><span class=\"mord cjk_fallback\">、</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">吃</span></span></span></span>，也就是说 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">pos+k=3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 位置的位置向量的某一维可以通过 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">pos=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 位置的位置向量的某一维线性组合加以线性表示，通过该线性表示可以得出 “吃” 的位置编码信息蕴含了相对于前两个字 “我” 的位置编码信息。</p>\n<p>总而言之就是，<strong>某个单词的位置信息是其他单词位置信息的线性组合，这种线性组合就意味着位置向量中蕴含了相对位置信息。</strong></p>\n<h1 id=\"十-transformer\"><a class=\"anchor\" href=\"#十-transformer\">#</a> 十、Transformer</h1>\n<h2 id=\"101-transformer-的结构\"><a class=\"anchor\" href=\"#101-transformer-的结构\">#</a> 10.1 Transformer 的结构</h2>\n<p>万事俱备，只欠东风，下面我们来讲讲我们的重点之一，Transformer，你可以先记住这一句话：<strong>Transformer 简单点看其实就是 self-attention 模型的叠加</strong>，首先我们来看看 Transformer 的整体框架。</p>\n<p>Transformer 的整体框架如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5NSVCNCVFNCVCRCU5MyVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 整体框架.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图所示的整体框架乍一眼一看非常复杂，由于 Transformer 起初是作为翻译模型，因此我们以翻译举例，简化一下上述的整体框架：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiVBMSU4NiVFNiU5RSVCNiVFNyVBRSU4MCVFNSU4QyU5Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 框架简化.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>从上图可以看出 Transformer 相当于一个黑箱，左边输入 “Je suis etudiant”，右边会得到一个翻译结果 “I am a student”。</p>\n<p>再往细里讲，Transformer 也是一个 Seq2Seq 模型（Encoder-Decoder 框架的模型），左边一个 Encoders 把输入读进去，右边一个 Decoders 得到输出，如下所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLWVkLSVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-ed - 框架.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<blockquote>\n<p>在这里，我们穿插描述下 Encoder-Decoder 框架的模型是如何进行文本翻译的：</p>\n<ol>\n<li>将序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_1,x_2,\\cdots,x_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 作为 Encoders 的输入，得到输出序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(z_1,z_2,\\cdots,z_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>把 Encoders 的输出序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>z</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(z_1,z_2,\\cdots,z_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 作为 Decoders 的输入，生成一个输出序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(y_1,y_2,\\cdots,y_m)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。注：<strong>Decoders 每个时刻输出一个结果</strong></li>\n</ol>\n</blockquote>\n<p>第一眼看到上述的 Encodes-Decoders 框架图，随之产生问题就是 Transformer 中 左边 Encoders 的输出是怎么和右边 Decoders 结合的。因为 decoders 里面是有 N 层的，再画张图直观的看就是这样：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLWVkLSVFNSVBNCU4RCVFNiU5RCU4Mi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-ed - 复杂.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>也就是说，Encoders 的输出，会和<strong>每一层的 Decoder 进行结合</strong>。</p>\n<p>现在我们取其中一层进行详细的展示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>通过上述分析，发现我们想要详细了解 Transformer，只要了解 Transformer 中的 Encoder 和 Decoder 单元即可，接下来我们将详细阐述这两个单元。</p>\n<h2 id=\"102-encoder\"><a class=\"anchor\" href=\"#102-encoder\">#</a> 10.2 Encoder</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>有了上述那么多知识的铺垫，我们知道 Eecoders 是 N=6 层，通过上图我们可以看到每层 Encoder 包括两个 sub-layers：</p>\n<ul>\n<li>第一个 sub-layer 是 multi-head self-attention，用来计算输入的 self-attention；</li>\n<li>第二个 sub-layer 是简单的前馈神经网络层 Feed Forward；</li>\n</ul>\n<p>注意：在每个 sub-layer 我们都模拟了残差网络（在下面的数据流示意图中会细讲），每个 sub-layer 的输出都是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo>+</mo><mi>S</mi><mi>u</mi><mi>b</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">LayerNorm(x+Sub\\_layer(x))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">m</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">b</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mi>u</mi><mi>b</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">sub\\_layer</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.00444em;vertical-align:-0.31em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">b</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span></span></span></span> 表示的是该层的上一层的输出</p>\n<p>现在我们给出 Encoder 的数据流示意图，一步一步去剖析</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VuY29kZXItJUU4JUFGJUE2JUU3JUJCJTg2JUU1JTlCJUJFLnBuZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/encoder - 详细图.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<ol>\n<li>深绿色的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示 Embedding 层的输出，加上代表 Positional Embedding 的向量之后，得到最后输入 Encoder 中的特征向量，也就是浅绿色向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；</li>\n<li>浅绿色向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示单词 “Thinking” 的特征向量，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 经过 Self-Attention 层，变成浅粉色向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 作为残差结构的直连向量，直接和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 相加，之后进行 Layer Norm 操作，得到粉色向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；\n<ol>\n<li>残差结构的作用：避免出现梯度消失的情况</li>\n<li>Layer Norm 的作用：为了保证数据特征分布的稳定性，并且可以加速模型的收敛</li>\n</ol>\n</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 经过前馈神经网络（Feed Forward）层，经过残差结构与自身相加，之后经过 LN 层，得到一个输出向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">r_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；\n<ol>\n<li>该前馈神经网络包括两个线性变换和一个 ReLU 激活函数：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><mi>b</mi><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">FFN(x) = max(0,xW_1+b_1)W_2+b2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mord\">2</span></span></span></span></li>\n</ol>\n</li>\n<li>由于 Transformer 的 Encoders 具有 6 个 Encoder，<strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">r_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 也将会作为下一层 Encoder 的输入，代替 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的角色</strong>，如此循环，直至最后一层 Encoder。</li>\n</ol>\n<p>需要注意的是，<strong>上述的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mtext>、</mtext><mi>z</mi><mtext>、</mtext><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">x、z、r</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord cjk_fallback\">、</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord cjk_fallback\">、</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span></span></span></span> 都具有相同的维数</strong>，论文中为 512 维。</p>\n<h2 id=\"103-decoder\"><a class=\"anchor\" href=\"#103-decoder\">#</a> 10.3 Decoder</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>Decoders 也是 N=6 层，通过上图我们可以看到每层 Decoder 包括 3 个 sub-layers：</p>\n<ul>\n<li>第一个 sub-layer 是 Masked multi-head self-attention，也是计算输入的 self-attention；\n<ul>\n<li>在这里，先不解释为什么要做 Masked，后面在 “Transformer 动态流程展示” 这一小节会解释</li>\n</ul>\n</li>\n<li>第二个 sub-layer 是 Encoder-Decoder Attention 计算，对 Encoder 的输入和 Decoder 的 Masked multi-head self-attention 的输出进行 attention 计算；\n<ul>\n<li>在这里，同样不解释为什么要对 Encoder 和 Decoder 的输出一同做 attention 计算，后面在 “Transformer 动态流程展示” 这一小节会解释</li>\n</ul>\n</li>\n<li>第三个 sub-layer 是前馈神经网络层，与 Encoder 相同。</li>\n</ul>\n<h2 id=\"104-transformer-输出结果\"><a class=\"anchor\" href=\"#104-transformer-输出结果\">#</a> 10.4 Transformer 输出结果</h2>\n<p>以上，就讲完了 Transformer 编码和解码两大模块，那么我们回归最初的问题，将 “机器学习” 翻译成 “machine learing”，解码器的输出是一个浮点型的向量，怎么转化成 “machine learing” 这两个词呢？让我们来看看 Encoders 和 Decoders 交互的过程寻找答案：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNCVCQSVBNCVFNCVCQSU5Mi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 交互.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>从上图可以看出，Transformer 最后的工作是让解码器的输出通过线性层 Linear 后接上一个 softmax</p>\n<ul>\n<li>其中线性层是一个简单的全连接神经网络，它将解码器产生的向量 A 投影到一个更高维度的向量 B 上，假设我们模型的词汇表是 10000 个词，那么向量 B 就有 10000 个维度，每个维度对应一个惟一的词的得分。</li>\n<li>之后的 softmax 层将这些分数转换为概率。选择概率最大的维度，并对应地生成与之关联的单词作为此时间步的输出就是最终的输出啦！</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5QyU4MCVFNSU5MCU4RSVFOCVCRSU5MyVFNSU4NyVCQS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 最后输出.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>假设词汇表维度是 6，那么输出最大概率词汇的过程如下：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5QyU4MCVFNyVCQiU4OCVFOCVCRSU5MyVFNSU4NyVCQSVFNyVCQiU5MyVFNiU5RSU5Qy5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 最终输出结果.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"十一-transformer-动态流程展示\"><a class=\"anchor\" href=\"#十一-transformer-动态流程展示\">#</a> 十一、Transformer 动态流程展示</h1>\n<p>首先我们来看看拿 Transformer 作翻译时，如何生成翻译结果的：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNSU4QSVBOCVFNiU4MCU4MSVFNyU5NCU5RiVFNiU4OCU5MC5naWY=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 动态生成.gif</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>继续进行：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNSU4QSVBOCVFNiU4MCU4MSVFNyVCQiU5MyVFNiU5RSU5Qy0yLmdpZg==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 动态结果 - 2.gif</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5NSVCNCVFNCVCRCU5MyVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 整体框架.jpg</span>&quot; style=&quot;zoom:33%;&quot; /&gt;</p>\n<p>假设上图是训练模型的某一个阶段，我们来结合 Transformer 的完整框架描述下这个动态的流程图：</p>\n<ol>\n<li>输入 “je suis etudiant” 到 Encoders，然后得到一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵；</li>\n<li>输入 “I am a student” 到 Decoders ，首先通过 Masked Multi-head Attention 层得到 “I am a student” 的 attention 值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，然后用 attention 值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 Encoders 的输出 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵进行 attention 计算，得到第 1 个输出 “I”；</li>\n<li>输入 “I am a student” 到 Decoders ，首先通过 Masked Multi-head Attention 层得到 “I am a student” 的 attention 值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，然后用 attention 值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 Encoders 的输出 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵进行 attention 计算，得到第 2 个输出 “am”；</li>\n<li>……</li>\n</ol>\n<p>现在我们来解释我们之前遗留的两个问题。</p>\n<h2 id=\"111-为什么-decoder-需要做-mask\"><a class=\"anchor\" href=\"#111-为什么-decoder-需要做-mask\">#</a> 11.1 为什么 Decoder 需要做 Mask</h2>\n<ul>\n<li>\n<p>训练阶段：我们知道 “je suis etudiant” 的翻译结果为 “I am a student”，我们把 “I am a student” 的 Embedding 输入到 Decoders 里面，翻译第一个词 “I” 时</p>\n<ul>\n<li>如果对 “I am a student” attention 计算不做 mask，“am，a，student” 对 “I” 的翻译将会有一定的贡献</li>\n<li>如果对 “I am a student” attention 计算做 mask，“am，a，student” 对 “I” 的翻译将没有贡献</li>\n</ul>\n</li>\n<li>\n<p>测试阶段：我们不知道 “我爱中国” 的翻译结果为 “I love China”，我们只能随机初始化一个 Embedding 输入到 Decoders 里面，翻译第一个词 “I” 时：</p>\n<ul>\n<li>无论是否做 mask，“love，China” 对 “I” 的翻译都不会产生贡献</li>\n<li>但是翻译了第一个词 “I” 后，随机初始化的 Embedding 有了 “I” 的 Embedding，也就是说在翻译第二词 “love” 的时候，“I” 的 Embedding 将有一定的贡献，但是 “China” 对 “love” 的翻译毫无贡献，随之翻译的进行，<strong>已经翻译的结果将会对下一个要翻译的词都会有一定的贡献，这就和做了 mask 的训练阶段做到了一种匹配</strong></li>\n</ul>\n</li>\n</ul>\n<p>总结下就是：Decoder 做 Mask，是为了让训练阶段和测试阶段行为一致，不会出现间隙，避免过拟合</p>\n<h2 id=\"112-为什么-encoder-给予-decoders-的是-k-v-矩阵\"><a class=\"anchor\" href=\"#112-为什么-encoder-给予-decoders-的是-k-v-矩阵\">#</a> 11.2 为什么 Encoder 给予 Decoders 的是 K、V 矩阵</h2>\n<p>我们在讲解 Attention 机制中曾提到，Query 的目的是借助它从一堆信息中找到重要的信息。</p>\n<p>现在 Encoder 提供了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>e</mi></msub><mtext>、</mtext><msub><mi>V</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_e、V_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">、</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵，Decoder 提供了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵，通过 “我爱中国” 翻译为 “I love China” 这句话详细解释下。</p>\n<p>当我们翻译 “I” 的时候，由于 Decoder 提供了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵，通过与 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>e</mi></msub><mtext>、</mtext><msub><mi>V</mi><mi>e</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_e、V_e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">、</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">e</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 矩阵的计算，它可以在 “我爱中国” 这四个字中找到对 “I” 翻译最有用的单词是哪几个，并以此为依据翻译出 “I” 这个单词，这就很好的体现了注意力机制想要达到的目的，把焦点放在对自己而言更为重要的信息上。</p>\n<ul>\n<li>其实上述说的就是 Attention 里的 soft attention 机制，解决了曾经的 Encoder-Decoder 框架的一个问题，在这里不多做叙述，有兴趣的可以参考网上的一些资料。\n<ul>\n<li>早期的 Encoder-Decoder 框架中的 Encoder 通过 LSTM 提取出源句（Source） “我爱中国” 的特征信息 C，然后 Decoder 做翻译的时候，目标句（Target）“I love China” 中的任何一个单词的翻译都来源于相同特征信息 C，这种做法是极其不合理的，例如翻译 “I” 时应该着眼于 “我”，翻译 “China” 应该着眼于 “中国”，而早期的这种做法并没有体现出，然而 Transformer 却通过 Attention 的做法解决了这个问题。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"十二-gpt-模型\"><a class=\"anchor\" href=\"#十二-gpt-模型\">#</a> 十二、GPT 模型</h1>\n<h2 id=\"121-gpt-模型的预训练\"><a class=\"anchor\" href=\"#121-gpt-模型的预训练\">#</a> 12.1 GPT 模型的预训练</h2>\n<p>在讲解 ELMo 的时候，我们说到 ELMo 这一类预训练的方法被称为 “Feature-based Pre-Training”。并且如果把 ELMo 这种预训练方法和图像领域的预训练方法对比，发现两者模式看上去还是有很大差异的。</p>\n<p>除了以 ELMo 为代表的这种基于特征融合的预训练方法外，NLP 里还有一种典型做法，这种做法和图像领域的方式就是看上去一致的了，一般将这种方法称为 “基于 Fine-tuning 的模式”，而 GPT 就是这一模式的典型开创者，下面先让我们看看 GPT 的网络结构。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2dwdC0lRTYlQTglQTElRTUlOUUlOEIuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/gpt - 模型.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>GPT 是 “Generative Pre-Training” 的简称，从名字看其含义是指的生成式的预训练。</p>\n<p>GPT 也采用两阶段过程：</p>\n<ol>\n<li>第一个阶段：利用语言模型进行预训练；</li>\n<li>第二个阶段：通过 Fine-tuning 的模式解决下游任务。</li>\n</ol>\n<p>上图展示了 GPT 的预训练过程，其实和 ELMo 是类似的，主要不同在于两点：</p>\n<ol>\n<li>首先，特征抽取器用的不是 RNN，而是用的 Transformer，它的特征抽取能力要强于 RNN，这个选择很明显是很明智的；</li>\n<li>其次，\n<ol>\n<li>GPT 的预训练虽然仍然是以语言模型作为目标任务，但是采用的是单向的语言模型，所谓 “单向” 的含义是指：语言模型训练的任务目标是根据 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 单词的上下文去正确预测单词 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ， <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 之前的单词序列 Context-before 称为上文，之后的单词序列 Context-after 称为下文。</li>\n<li>ELMo 在做语言模型预训练的时候，预测单词 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 同时使用了上文和下文，而 GPT 则只采用 Context-before 这个单词的上文来进行预测，而抛开了下文。</li>\n<li>GPT 这个选择现在看不是个太好的选择，原因很简单，它没有把单词的下文融合进来，这限制了其在更多应用场景的效果，比如阅读理解这种任务，在做任务的时候是可以允许同时看到上文和下文一起做决策的。如果预训练时候不把单词的下文嵌入到 Word Embedding 中，是很吃亏的，白白丢掉了很多信息。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"122-gpt-模型的-fine-tuning\"><a class=\"anchor\" href=\"#122-gpt-模型的-fine-tuning\">#</a> 12.2 GPT 模型的 Fine-tuning</h2>\n<p>上面讲的是 GPT 如何进行第一阶段的预训练，那么假设预训练好了网络模型，后面下游任务怎么用？它有自己的个性，和 ELMO 的方式大有不同。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2dwdC1maW5lLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/gpt-fine.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>上图展示了 GPT 在第二阶段如何使用：</p>\n<ol>\n<li>\n<p>首先，对于不同的下游任务来说，本来你可以任意设计自己的网络结构，现在不行了，你要向 GPT 的网络结构看齐，把任务的网络结构改造成和 GPT 一样的网络结构。</p>\n</li>\n<li>\n<p>然后，在做下游任务的时候，利用第一步预训练好的参数初始化 GPT 的网络结构，这样通过预训练学到的语言学知识就被引入到你手头的任务里来了。</p>\n</li>\n<li>\n<p>再次，你可以用手头的任务去训练这个网络，对网络参数进行 Fine-tuning，使得这个网络更适合解决手头的问题。就是这样。</p>\n</li>\n</ol>\n<p>这有没有让你想起最开始提到的图像领域如何做预训练的过程，对，这跟那个预训练的模式是一模一样的。</p>\n<p>对于 NLP 各种花样的不同任务，怎么改造才能靠近 GPT 的网络结构呢？由于 GPT 对下游任务的改造过程和 BERT 对下游任务的改造极其类似，并且我们主要目的是为了讲解 BERT，所以这个问题将会在 BERT 那里得到回答。</p>\n<h1 id=\"十三-bert-模型\"><a class=\"anchor\" href=\"#十三-bert-模型\">#</a> 十三、BERT 模型</h1>\n<h2 id=\"131-bert公认的里程碑\"><a class=\"anchor\" href=\"#131-bert公认的里程碑\">#</a> 13.1 BERT：公认的里程碑</h2>\n<p>BERT 模型可以作为公认的里程碑式的模型，但是它最大的优点不是创新，而是集大成者，并且这个集大成者有了各项突破，下面让我们看看 BERT 是怎么集大成者的。</p>\n<ul>\n<li>BERT 的意义在于：从大量无标记数据集中训练得到的深度模型，可以显著提高各项自然语言处理任务的准确率。</li>\n<li>近年来优秀预训练语言模型的集大成者：参考了 ELMO 模型的双向编码思想、借鉴了 GPT 用 Transformer 作为特征提取器的思路、采用了 word2vec 所使用的 CBOW 方法</li>\n<li>BERT 和 GPT 之间的区别：\n<ul>\n<li>GPT：<strong>GPT 使用 Transformer Decoder 作为特征提取器、具有良好的文本生成能力</strong>，然而当前词的语义只能由其前序词决定，并且在语义理解上不足</li>\n<li>BERT：使用了 Transformer Encoder 作为特征提取器，并使用了与其配套的掩码训练方法。<strong>虽然使用双向编码让 BERT 不再具有文本生成能力，但是 BERT 的语义信息提取能力更强</strong></li>\n</ul>\n</li>\n<li>单向编码和双向编码的差异，以该句话举例 “今天天气很 {}，我们不得不取消户外运动”，分别从单向编码和双向编码的角度去考虑 {} 中应该填什么词：\n<ul>\n<li>单向编码：单向编码只会考虑 “今天天气很”，以人类的经验，大概率会从 “好”、“不错”、“差”、“糟糕” 这几个词中选择，这些词可以被划为截然不同的两类</li>\n<li>双向编码：<strong>双向编码会同时考虑上下文的信息</strong>，即除了会考虑 “今天天气很” 这五个字，还会考虑 “我们不得不取消户外运动” 来帮助模型判断，则大概率会从 “差”、“糟糕” 这一类词中选择</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"132-bert-的结构强大的特征提取能力\"><a class=\"anchor\" href=\"#132-bert-的结构强大的特征提取能力\">#</a> 13.2 BERT 的结构：强大的特征提取能力</h2>\n<ul>\n<li>\n<p>如下图所示，我们来看看 ELMo、GPT 和 BERT 三者的区别</p>\n<ul>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL0JFUlQtR1BULSVFNiVBRiU5NCVFOCVCRSU4My5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/BERT-GPT - 比较.png</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n<li>ELMo 使用自左向右编码和自右向左编码的两个 LSTM 网络，分别以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_1,\\cdots,w_{i-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_{i+1},\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 为目标函数独立训练，<strong>将训练得到的特征向量以拼接的形式实现双向编码，本质上还是单向编码，只不过是两个方向上的单向编码的拼接而成的双向编码</strong>。</li>\n<li>GPT 使用 Transformer Decoder 作为 Transformer Block，以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_1,\\cdots,w_{i-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 为目标函数进行训练，<strong>用 Transformer Block 取代 LSTM 作为特征提取器，实现了单向编码，是一个标准的预训练语言模型，即使用 Fine-Tuning 模式解决下游任务。</strong></li>\n<li>BERT 也是一个标准的预训练语言模型，<strong>它以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_1,\\cdots,w_{i-1},w_{i+1},\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 为目标函数进行训练，BERT 使用的编码器属于双向编码器</strong>。\n<ul>\n<li>BERT 和 ELMo 的区别在于使用 Transformer Block 作为特征提取器，加强了语义特征提取的能力；</li>\n<li>BERT 和 GPT 的区别在于使用 Transformer Encoder 作为 Transformer Block，并且将 GPT 的单向编码改成双向编码，也就是说 BERT 舍弃了文本生成能力，换来了更强的语义理解能力。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>BERT 的模型结构如下图所示：</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2JlcnQtJUU2JUE4JUExJUU1JTlFJThCJUU3JUJCJTkzJUU2JTlFJTg0LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/bert - 模型结构.jpg</span>&quot; style=&quot;zoom:51%;&quot; /&gt;</p>\n<p>从上图可以发现，BERT 的模型结构其实就是 Transformer Encoder 模块的堆叠。在模型参数选择上，论文给出了两套大小不一致的模型。</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>E</mi><mi>R</mi><msub><mi>T</mi><mrow><mi>B</mi><mi>A</mi><mi>S</mi><mi>E</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">BERT_{BASE}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal mtight\">A</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ：L = 12，H = 768，A = 12，总参数量为 1.1 亿</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>E</mi><mi>R</mi><msub><mi>T</mi><mrow><mi>L</mi><mi>A</mi><mi>R</mi><mi>G</mi><mi>E</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">BERT_{LARGE}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">L</span><span class=\"mord mathnormal mtight\">A</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\">G</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：L = 24，H = 1024，A = 16，总参数量为 3.4 亿</p>\n</blockquote>\n<p>其中 L 代表 Transformer Block 的层数；H 代表特征向量的维数（此处默认 Feed Forward 层中的中间隐层的维数为 4H）；A 表示 Self-Attention 的头数，使用这三个参数基本可以定义 BERT 的量级。</p>\n<p>BERT 参数量级的计算公式：</p>\n\\begin{align*}\n& 词向量参数+ 12 * （Multi-Heads参数 + 全连接层参数 + layernorm参数）\\\\ \n& = （30522+512 + 2）* 768 + 768 * 2 \\\\\n& + 12 * （768 * 768 / 12 * 3 * 12 + 768 * 768 + 768 * 3072 * 2 + 768 * 2 * 2） \\\\ \n& = 108808704.0 \\\\ \n& \\approx 110M\n\\end{align*}\n\n<p>训练过程也是很花费计算资源和时间的，<strong>总之表示膜拜，普通人即便有 idea 没有算力也只能跪着。</strong></p>\n<h2 id=\"133-bert-之无监督训练\"><a class=\"anchor\" href=\"#133-bert-之无监督训练\">#</a> 13.3 BERT 之无监督训练</h2>\n<p>和 GPT 一样，BERT 也采用二段式训练方法：</p>\n<ol>\n<li>第一阶段：使用易获取的大规模无标签余料，来训练基础语言模型；</li>\n<li>第二阶段：根据指定任务的少量带标签训练数据进行微调训练。</li>\n</ol>\n<p>不同于 GPT 等标准语言模型使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_1,\\cdots,w_{i-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 为目标函数进行训练，能看到全局信息的 BERT 使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_i|w_1,\\cdots,w_{i-1},w_{i+1},\\cdots,w_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 为目标函数进行训练。</p>\n<p>并且 BERT 用语言掩码模型（MLM）方法训练词的语义理解能力；用下句预测（NSP）方法训练句子之间的理解能力，从而更好地支持下游任务。</p>\n<h2 id=\"134-bert之语言掩码模型mlm\"><a class=\"anchor\" href=\"#134-bert之语言掩码模型mlm\">#</a> 13.4 BERT 之语言掩码模型（MLM）</h2>\n<p>BERT 作者认为，<strong>使用自左向右编码和自右向左编码的单向编码器拼接而成的双向编码器，在性能、参数规模和效率等方面，都不如直接使用深度双向编码器强大</strong>，这也是为什么 BERT 使用 Transformer Encoder 作为特征提取器，而不使用自左向右编码和自右向左编码的两个 Transformer Decoder 作为特征提取器的原因。</p>\n<p>由于无法使用标准语言模型的训练模式，<strong>BERT 借鉴完形填空任务和 CBOW 的思想</strong>，使用语言掩码模型（MLM ）方法训练模型。</p>\n<p>MLM 方法也就是随机去掉句子中的部分 token（单词），然后模型来预测被去掉的 token 是什么。<strong>这样实际上已经不是传统的神经网络语言模型 (类似于生成模型) 了，而是单纯作为分类问题</strong>，根据这个时刻的 hidden state 来预测这个时刻的 token 应该是什么，而不是预测下一个时刻的词的概率分布了。</p>\n<p>随机去掉的 token 被称作掩码词，在训练中，掩码词将以 15% 的概率被替换成 [MASK]，也就是说随机 mask 语料中 15% 的 token，这个操作则称为掩码操作。注意：<strong>在 CBOW 模型中，每个词都会被预测一遍。</strong></p>\n<p>但是这样设计 MLM 的训练方法会引入弊端：<strong>在模型微调训练阶段或模型推理（测试）阶段，输入的文本中将没有 [MASK]，进而导致产生由训练和预测数据偏差导致的性能损失。</strong></p>\n<p>考虑到上述的弊端，BERT 并没有总用 [MASK] 替换掩码词，而是按照一定比例选取替换词。在选择 15% 的词作为掩码词后这些掩码词有三类替换选项：</p>\n<ul>\n<li>80% 练样本中：将选中的词用 [MASK] 来代替，例如：</li>\n</ul>\n<figure class=\"highlight text\"><figcaption data-lang=\"text\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>“地球是[MASK]八大行星之一”</pre></td></tr></table></figure><ul>\n<li>10% 的训练样本中：选中的词不发生变化，<strong>该做法是为了缓解训练文本和预测文本的偏差带来的性能损失</strong>，例如：</li>\n</ul>\n<figure class=\"highlight text\"><figcaption data-lang=\"text\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>“地球是太阳系八大行星之一”</pre></td></tr></table></figure><ul>\n<li>10% 的训练样本中：将选中的词用任意的词来进行代替，<strong>该做法是为了让 BERT 学会根据上下文信息自动纠错</strong>，例如：</li>\n</ul>\n<figure class=\"highlight text\"><figcaption data-lang=\"text\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>“地球是苹果八大行星之一”</pre></td></tr></table></figure><p>作者在论文中提到这样做的好处是，编码器不知道哪些词需要预测的，哪些词是错误的，因此<strong>被迫需要学习每一个 token 的表示向量</strong>，另外作者也<strong>表示双向编码器比单项编码器训练要慢</strong>，进而导致 BERT 的训练效率低了很多，但是实验也证明 MLM 训练方法可以让 BERT 获得超出同期所有预训练语言模型的语义理解能力，牺牲训练效率是值得的。</p>\n<h2 id=\"135-bert-之下句预测nsp\"><a class=\"anchor\" href=\"#135-bert-之下句预测nsp\">#</a> 13.5 BERT 之下句预测（NSP）</h2>\n<p>在很多自然语言处理的下游任务中，如问答和自然语言推断，都基于两个句子做逻辑推理，而语言模型并不具备直接捕获句子之间的语义联系的能力，或者可以说成<strong>单词预测粒度的训练到不了句子关系这个层级</strong>，为了<strong>学会捕捉句子之间的语义联系</strong>，BERT 采用了下句预测（NSP ）作为无监督预训练的一部分。</p>\n<p>NSP 的具体做法是，BERT 输入的语句将由两个句子构成，其中，50% 的概率将语义连贯的两个连续句子作为训练文本（<strong>连续句对一般选自篇章级别的语料，以此确保前后语句的语义强相关</strong>），另外 50% 的概率将完全随机抽取两个句子作为训练文本。</p>\n<blockquote>\n<p>连续句对：[CLS] 今天天气很糟糕 [SEP] 下午的体育课取消了 [SEP]</p>\n<p>随机句对：[CLS] 今天天气很糟糕 [SEP] 鱼快被烤焦啦 [SEP]</p>\n</blockquote>\n<p>其中 [SEP]  标签表示分隔符。 [CLS] 表示标签用于类别预测，结果为 1，表示输入为连续句对；结果为 0，表示输入为随机句对。</p>\n<p>通过训练 [CLS] 编码后的输出标签，<strong>BERT 可以学会捕捉两个输入句对的文本语义</strong>，在连续句对的预测任务中，BERT 的正确率可以达到 97%-98%。</p>\n<h2 id=\"136-bert-之输入表示\"><a class=\"anchor\" href=\"#136-bert-之输入表示\">#</a> 13.6 BERT 之输入表示</h2>\n<p>BERT 在预训练阶段使用了前文所述的两种训练方法，<strong>在真实训练中一般是两种方法混合使用</strong>。</p>\n<p>由于 BERT 通过 Transformer 模型堆叠而成，所以 BERT 的输入需要两套 Embedding 操作：</p>\n<ol>\n<li>一套为 One-hot 词表映射编码（对应下图的 Token Embeddings）；</li>\n<li>另一套为位置编码（对应下图的 Position Embeddings），<strong>不同于 Transformer 的位置编码用三角函数表示，BERT 的位置编码将在预训练过程中训练得到（训练思想类似于 Word Embedding 的 Q 矩阵）</strong></li>\n<li>由于在 MLM 的训练过程中，存在单句输入和双句输入的情况，因此 BERT 还需要一套区分输入语句的分割编码（对应下图的 Segment Embeddings），BERT 的分割编码也将在预训练过程中训练得到</li>\n</ol>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL0JFUlQtJUU4JUJFJTkzJUU1JTg1JUE1LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/BERT - 输入.jpg</span>&quot; style=&quot;zoom:51%;&quot; /&gt;</p>\n<p>对于分割编码，Segment Embeddings 层只有两种向量表示。前一个向量是把 0 赋给第一个句子中的各个 token，后一个向量是把 1 赋给第二个句子中的各个 token ；如果输入仅仅只有一个句子，那么它的 segment embedding 就是全 0，下面我们简单举个例子描述下：</p>\n<blockquote>\n<p>[CLS] I like dogs [SEP] I like cats [SEP] 对应编码 0 0 0 0 0 1 1 1 1</p>\n<p>[SEP] I Iike dogs and cats [SEP] 对应编码 0 0 0 0 0 0 0</p>\n</blockquote>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlZ21lbnQtZW1iZWRkaW5ncy5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/segment-embeddings.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"十四-bert-下游任务改造\"><a class=\"anchor\" href=\"#十四-bert-下游任务改造\">#</a> 十四、BERT 下游任务改造</h1>\n<p>BERT 根据自然语言处理下游任务的输入和输出的形式，将微调训练支持的任务分为四类，分别是句对分类、单句分类、文本问答和单句标注，接下来我们将简要的介绍下 BERT 如何通过微调训练适应这四类任务的要求。</p>\n<h2 id=\"141-句对分类\"><a class=\"anchor\" href=\"#141-句对分类\">#</a> 14.1 句对分类</h2>\n<p>给定两个句子，判断它们的关系，称为句对分类，例如判断句对是否相似、判断后者是否为前者的答案。</p>\n<p>针对句对分类任务，BERT 在预训练过程中就使用了 NSP 训练方法获得了直接捕获句对语义关系的能力。</p>\n<p><strong>如下图所示，句对用 [SEP] 分隔符拼接成文本序列，在句首加入标签 [CLS]，将句首标签所对应的输出值作为分类标签，计算预测分类标签与真实分类标签的交叉熵，将其作为优化目标，在任务数据上进行微调训练。</strong></p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU4RiVBNSVFNSVBRiVCOSVFNSU4OCU4NiVFNyVCMSVCQi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 句对分类.jpg</span>&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>针对二分类任务，BERT 不需要对输入数据和输出数据的结构做任何改动，直接使用与 NSP 训练方法一样的输入和输出结构就行。</p>\n<p>针对多分类任务，需要在句首标签 [CLS] 的输出特征向量后接一个全连接层和 Softmax 层，保证输出维数与类别数目一致，最后通过 arg max 操作（取最大值时对应的索引序号）得到相对应的类别结果。</p>\n<p>下面给出句对分相似性任务的实例：</p>\n<blockquote>\n<p>任务：判断句子 “我很喜欢你” 和句子 “我很中意你” 是否相似</p>\n<p>输入改写：“[CLS] 我很喜欢你 [SEP] 我很中意你”</p>\n<p>取 “[CLS]” 标签对应输出：[0.02, 0.98]</p>\n<p>通过 arg max 操作得到相似类别为 1（类别索引从 0 开始），即两个句子相似</p>\n</blockquote>\n<h2 id=\"142-单句分类\"><a class=\"anchor\" href=\"#142-单句分类\">#</a> 14.2 单句分类</h2>\n<p>给定一个句子，判断该句子的类别，统称为单句分类，例如判断情感类别、判断是否为语义连贯的句子。</p>\n<p>针对单句二分类任务，也无须对 BERT 的输入数据和输出数据的结构做任何改动。</p>\n<p><strong>如下图所示，单句分类在句首加入标签 [CLS]，将句首标签所对应的输出值作为分类标签，计算预测分类标签与真实分类标签的交叉熵，将其作为优化目标，在任务数据上进行微调训练。</strong></p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU4RCU5NSVFNSU4RiVBNSVFNSU4OCU4NiVFNyVCMSVCQi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 单句分类.jpg</span>&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>同样，针对多分类任务，需要在句首标签 [CLS] 的输出特征向量后接一个全连接层和 Softmax 层，保证输出维数与类别数目一致，最后通过 argmax 操作得到相对应的类别结果。</p>\n<p>下面给出语义连贯性判断任务的实例：</p>\n<blockquote>\n<p>任务：判断句子 “海大球星饭茶吃” 是否为一句话</p>\n<p>输入改写：“[CLS] 海大球星饭茶吃”</p>\n<p>取 “[CLS]” 标签对应输出：[0.99, 0.01]</p>\n<p>通过 arg max 操作得到相似类别为 0，即这个句子不是一个语义连贯的句子</p>\n</blockquote>\n<h2 id=\"143-文本问答\"><a class=\"anchor\" href=\"#143-文本问答\">#</a> 14.3 文本问答</h2>\n<p>给定一个问句和一个蕴含答案的句子，找出答案在后这种的位置，称为文本问答，例如给定一个问题（句子 A），在给定的段落（句子 B）中标注答案的其实位置和终止位置。</p>\n<p><strong>文本问答任何和前面讲的其他任务有较大的差别，无论是在优化目标上，还是在输入数据和输出数据的形式上，都需要做一些特殊的处理。</strong></p>\n<p>为了标注答案的起始位置和终止位置，BERT 引入两个辅助向量 s（start，判断答案的起始位置） 和 e（end，判断答案的终止位置）。</p>\n<p><strong>如下图所示，BERT 判断句子 B 中答案位置的做法是，将句子 B 中的每一个次得到的最终特征向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>T</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup></mrow><annotation encoding=\"application/x-tex\">T_i&#x27;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.010556em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 经过全连接层（利用全连接层将词的抽象语义特征转化为任务指向的特征）后，分别与向量 s 和 e 求内积，对所有内积分别进行 softmax 操作，即可得到词 Tok m（<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>M</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">m\\in [1,M]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">m</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mclose\">]</span></span></span></span>）作为答案其实位置和终止位置的概率。最后，去概率最大的片段作为最终的答案</strong>。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNiU5NiU4NyVFNiU5QyVBQyVFOSU5NyVBRSVFNyVBRCU5NC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 文本问答.jpg</span>&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>文本回答任务的微调训练使用了两个技巧：</p>\n<ol>\n<li>用全连接层把 BERT 提取后的深层特征向量转化为用于判断答案位置的特征向量</li>\n<li>引入辅助向量 s 和 e 作为答案其实位置和终止位置的基准向量，明确优化目标的方向和度量方法</li>\n</ol>\n<p>下面给出文本问答任务的实例：</p>\n<blockquote>\n<p>任务：给定问句 “今天的最高温度是多少”，在文本 “天气预报显示今天最高温度 37 摄氏度” 中标注答案的起始位置和终止位置</p>\n<p>输入改写：“[CLS] 今天的最高温度是多少 [SEP] 天气预报显示今天最高温度 37 摄氏度”</p>\n<p>BERT Softmax 结果：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">篇章文本</th>\n<th style=\"text-align:center\">天气</th>\n<th style=\"text-align:center\">预报</th>\n<th style=\"text-align:center\">显示</th>\n<th style=\"text-align:center\">今天</th>\n<th style=\"text-align:center\">最高温</th>\n<th style=\"text-align:center\">37</th>\n<th style=\"text-align:center\">摄氏度</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">起始位置概率</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.04</td>\n<td style=\"text-align:center\">0.10</td>\n<td style=\"text-align:center\">0.80</td>\n<td style=\"text-align:center\">0.03</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">终止位置概率</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.03</td>\n<td style=\"text-align:center\">0.04</td>\n<td style=\"text-align:center\">0.10</td>\n<td style=\"text-align:center\">0.80</td>\n</tr>\n</tbody>\n</table>\n<p>对 Softmax 的结果取 arg max，得到答案的起始位置为 6，终止位置为 7，即答案为 “37 摄氏度”</p>\n</blockquote>\n<h2 id=\"144-单句标注\"><a class=\"anchor\" href=\"#144-单句标注\">#</a> 14.4 单句标注</h2>\n<p>给定一个句子，标注每个次的标签，称为单句标注。例如给定一个句子，标注句子中的人名、地名和机构名。</p>\n<p>单句标注任务和 BERT 预训练任务具有较大差异，但与文本问答任务较为相似。</p>\n<p><strong>如下图所示，在进行单句标注任务时，需要在每个词的最终语义特征向量之后添加全连接层，将语义特征转化为序列标注任务所需的特征，单句标注任务需要对每个词都做标注，因此不需要引入辅助向量，直接对经过全连接层后的结果做 Softmax 操作，即可得到各类标签的概率分布。</strong></p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNSU4RCU5NSVFNSU4RiVBNSVFNiVBMCU4NyVFNiVCMyVBOC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 单句标注.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>由于 BERT 需要对输入文本进行分词操作，独立词将会被分成若干子词，因此 BERT 预测的结果将会是 5 类（细分为 13 小类）：</p>\n<ul>\n<li>O（非人名地名机构名，O 表示 Other）</li>\n<li>B-PER/LOC/ORG（人名 / 地名 / 机构名初始单词，B 表示 Begin）</li>\n<li>I-PER/LOC/ORG（人名 / 地名 / 机构名中间单词，I 表示 Intermediate）</li>\n<li>E-PER/LOC/ORG（人名 / 地名 / 机构名终止单词，E 表示 End）</li>\n<li>S-PER/LOC/ORG（人名 / 地名 / 机构名独立单词，S 表示 Single）</li>\n</ul>\n<p>将 5 大类的首字母结合，可得 IOBES，这是序列标注最常用的标注方法。</p>\n<p>下面给出命名实体识别（NER）任务的示例：</p>\n<blockquote>\n<p>任务：给定句子 “爱因斯坦在柏林发表演讲”，根据 IOBES 标注 NER 结果</p>\n<p>输入改写：“[CLS] 爱 因 斯坦 在 柏林 发表 演讲”</p>\n<p>BERT Softmax 结果：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">BOBES</th>\n<th style=\"text-align:center\">爱</th>\n<th style=\"text-align:center\">因</th>\n<th style=\"text-align:center\">斯坦</th>\n<th style=\"text-align:center\">在</th>\n<th style=\"text-align:center\">柏林</th>\n<th style=\"text-align:center\">发表</th>\n<th style=\"text-align:center\">演讲</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">O</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.90</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.90</td>\n<td style=\"text-align:center\">0.90</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">B-PER</td>\n<td style=\"text-align:center\">0.90</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">I-PER</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.90</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">E-PER</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.90</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">S-LOC</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n<td style=\"text-align:center\">0.01</td>\n</tr>\n</tbody>\n</table>\n<p>对 Softmax 的结果取 arg max，得到最终地 NER 标注结果为：“爱因斯坦” 是人名；“柏林” 是地名</p>\n</blockquote>\n<h2 id=\"145-bert效果展示\"><a class=\"anchor\" href=\"#145-bert效果展示\">#</a> 14.5 BERT 效果展示</h2>\n<p>无论如何，从上述讲解可以看出，NLP 四大类任务都可以比较方便地改造成 Bert 能够接受的方式，总之不同类型的任务需要对模型做不同的修改，但是修改都是非常简单的，最多加一层神经网络即可。这其实是 Bert 的非常大的优点，这意味着它几乎可以做任何 NLP 的下游任务，具备普适性，这是很强的。</p>\n<p>但是讲了这么多，** 一个新模型好不好，效果才是王道。** 那么 Bert 采用这种两阶段方式解决各种 NLP 任务效果如何？</p>\n<p>在 11 个各种类型的 NLP 任务中达到目前最好的效果，某些任务性能有极大的提升。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2JlcnQtJUU2JTk1JTg4JUU2JTlFJTlDLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/bert - 效果.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"十五-预训练语言模型总结\"><a class=\"anchor\" href=\"#十五-预训练语言模型总结\">#</a> 十五、预训练语言模型总结</h1>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNiU4MCVCQiVFNyVCQiU5My5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 总结.jpg</span>&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>到这里我们可以再梳理下几个模型之间的演进关系。</p>\n<p>从上图可见，Bert 其实和 ELMO 及 GPT 存在千丝万缕的关系，比如如果我们把 GPT 预训练阶段换成双向语言模型，那么就得到了 Bert；而如果我们把 ELMO 的特征抽取器换成 Transformer，那么我们也会得到 Bert。</p>\n<p>所以你可以看出：Bert 最关键两点，一点是特征抽取器采用 Transformer；第二点是预训练的时候采用双向语言模型。</p>\n<p>那么新问题来了：对于 Transformer 来说，怎么才能在这个结构上做双向语言模型任务呢？乍一看上去好像不太好搞。我觉得吧，其实有一种很直观的思路，怎么办？看看 ELMO 的网络结构图，只需要把两个 LSTM 替换成两个 Transformer，一个负责正向，一个负责反向特征提取，其实应该就可以。</p>\n<p>当然这是我自己的改造，Bert 没这么做。那么 Bert 是怎么做的呢？我们前面不是提过 Word2Vec 吗？我前面肯定不是漫无目的地提到它，提它是为了在这里引出那个 CBOW 训练方法，所谓写作时候埋伏笔的 “草蛇灰线，伏脉千里”，大概就是这个意思吧？</p>\n<p>前面提到了 CBOW 方法，它的核心思想是：在做语言模型任务的时候，我把要预测的单词抠掉，然后根据它的上文 Context-Before 和下文 Context-afte r 去预测单词。</p>\n<p>其实 Bert 怎么做的？Bert 就是这么做的。从这里可以看到方法间的继承关系。当然 Bert 作者没提 Word2Vec 及 CBOW 方法，这是我的判断，Bert 作者说是受到完形填空任务的启发，这也很可能，但是我觉得他们要是没想到过 CBOW 估计是不太可能的。</p>\n<p>从这里可以看出，在文章开始我说过 Bert 在模型方面其实没有太大创新，更像一个最近几年 NLP 重要技术的集大成者，原因在于此，当然我不确定你怎么看，是否认同这种看法，而且我也不关心你怎么看。其实 Bert 本身的效果好和普适性强才是最大的亮点。</p>\n<p><strong>最后，我讲讲我对 Bert 的评价和看法</strong>，我觉得 Bert 是 NLP 里里程碑式的工作，对于后面 NLP 的研究和工业应用会产生长久的影响，这点毫无疑问。但是从上文介绍也可以看出，从模型或者方法角度看，Bert 借鉴了 ELMO，GPT 及 CBOW，主要提出了 Masked 语言模型及 Next Sentence Prediction，但是这里 Next Sentence Prediction 基本不影响大局，而 Masked LM 明显借鉴了 CBOW 的思想。所以说 Bert 的模型没什么大的创新，更像最近几年 NLP 重要进展的集大成者，这点如果你看懂了上文估计也没有太大异议，如果你有大的异议，杠精这个大帽子我随时准备戴给你。</p>\n<p>如果归纳一下这些进展就是：首先是两阶段模型，第一阶段双向语言模型预训练，这里注意要用双向而不是单向，第二阶段采用具体任务 Fine-tuning 或者做特征集成；第二是特征抽取要用 Transformer 作为特征提取器而不是 RNN 或者 CNN；第三，双向语言模型可以采取 CBOW 的方法去做（当然我觉得这个是个细节问题，不算太关键，前两个因素比较关键）。Bert 最大的亮点在于效果好及普适性强，几乎所有 NLP 任务都可以套用 Bert 这种两阶段解决思路，而且效果应该会有明显提升。可以预见的是，未来一段时间在 NLP 应用领域，Transformer 将占据主导地位，而且这种两阶段预训练方法也会主导各种应用。</p>\n<p>另外，我们应该弄清楚预训练这个过程本质上是在做什么事情，本质上预训练是通过设计好一个网络结构来做语言模型任务，然后把大量甚至是无穷尽的无标注的自然语言文本利用起来，预训练任务把大量语言学知识抽取出来编码到网络结构中，当手头任务带有标注信息的数据有限时，这些先验的语言学特征当然会对手头任务有极大的特征补充作用，因为当数据有限的时候，很多语言学现象是覆盖不到的，泛化能力就弱，集成尽量通用的语言学知识自然会加强模型的泛化能力。如何引入先验的语言学知识其实一直是 NLP 尤其是深度学习场景下的 NLP 的主要目标之一，不过一直没有太好的解决办法，而 ELMO/GPT/Bert 的这种两阶段模式看起来无疑是解决这个问题自然又简洁的方法，这也是这些方法的主要价值所在。</p>\n<p>对于当前 NLP 的发展方向，我个人觉得有两点非常重要：</p>\n<ol>\n<li>一个是需要更强的特征抽取器，目前看 Transformer 会逐渐担当大任，但是肯定还是不够强的，需要发展更强的特征抽取器；</li>\n<li>第二个就是如何优雅地引入大量无监督数据中包含的语言学知识，注意我这里强调地是优雅，而不是引入，此前相当多的工作试图做各种语言学知识的嫁接或者引入，但是很多方法看着让人牙疼，就是我说的不优雅。</li>\n</ol>\n<p>目前看预训练这种两阶段方法还是很有效的，也非常简洁，当然后面肯定还会有更好的模型出现。</p>\n<p>完了，这就是预训练语言模型的前世今生。</p>\n<p>由于个人刚入门 NLP 方向，就不妄自总结，上述总结全部来自知乎文章：&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80OTI3MTY5OQ==\">https://zhuanlan.zhihu.com/p/49271699</span>' target='_blank'&gt; 从 Word Embedding 到 Bert 模型 — 自然语言处理中的预训练技术发展史 -<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS96aGFuZy1qdW4tbGluLTc2\"> 张俊林</span> &lt;/a&gt;</p>\n<h1 id=\"十六-参考资料\"><a class=\"anchor\" href=\"#十六-参考资料\">#</a> 十六、参考资料</h1>\n<p>我只是知识的搬运工，想详细了解各个知识点的读者可以自行选择参考下列资料。</p>\n<blockquote>\n<ul>\n<li>\n<p>参考书籍：</p>\n<ul>\n<li>\n<p>《预训练语言模型》- 卲浩、刘一烽</p>\n</li>\n<li>\n<p>《基于 BERT 模型的自然语言处理实战》- 李金洪</p>\n</li>\n</ul>\n</li>\n<li>\n<p>参考论文：</p>\n<ul>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE3MDYuMDM3NjI=\">https://arxiv.org/abs/1706.03762</span>' target='_blank'&gt;Attention Is All You Need&lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly90b29vYi5jb20vYXBpL29ianMvcmVhZC9ub3RlaWQvMjg3MTc5OTUv\">https://tooob.com/api/objs/read/noteid/28717995/</span>' target='_blank'&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;</li>\n</ul>\n</li>\n<li>\n<p>参考博客：</p>\n<ul>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNzYwMTE2MQ==\">https://zhuanlan.zhihu.com/p/37601161</span>' target='_blank'&gt; 深度学习中的注意力模型（2017 版）&lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvUkx4V2V2VldIWGdYLVVjb3hEUzcwdw==\">https://mp.weixin.qq.com/s/RLxWevVWHXgX-UcoxDS70w</span>' target='_blank'&gt; 细讲 | Attention Is All You Need&lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80OTI3MTY5OQ==\">https://zhuanlan.zhihu.com/p/49271699</span>' target='_blank'&gt; 从 Word Embedding 到 Bert 模型 — 自然语言处理中的预训练技术发展史 &lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbmlja2NoZW4xMjEvcC8xNTA3MTg0NC5odG1s\">https://www.cnblogs.com/nickchen121/p/15071844.html</span>' target='_blank'&gt;Attention 和 Transformer 详解 &lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDEyMTM3OA==\">https://zhuanlan.zhihu.com/p/44121378</span>' target='_blank'&gt;【NLP】Transformer 模型原理详解 &lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMzYyMjM1NTA=\">https://zhuanlan.zhihu.com/p/136223550</span>' target='_blank'&gt;LSTM 如何解决 RNN 带来的梯度消失问题 &lt;/a&gt;</li>\n<li>&lt;a href='<span class=\"exturl\" data-url=\"aHR0cDovL2phbGFtbWFyLmdpdGh1Yi5pby9pbGx1c3RyYXRlZC10cmFuc2Zvcm1lci8=\">http://jalammar.github.io/illustrated-transformer/</span>' target='_blank'&gt;The Illustrated Transformer&lt;/a&gt;</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/07%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E6%94%B9%E9%80%A0%E7%AE%80%E4%BB%8B%EF%BC%88%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/07%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E6%94%B9%E9%80%A0%E7%AE%80%E4%BB%8B%EF%BC%88%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%EF%BC%89/",
            "title": "预训练语言模型的下游任务改造简介（如何使用词向量）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"word2vec-是一个神经网络语言模型其次他的主要任务是做生成词向量q\"><a class=\"anchor\" href=\"#word2vec-是一个神经网络语言模型其次他的主要任务是做生成词向量q\">#</a> Word2Vec --》 是一个神经网络语言模型，其次他的主要任务是做（生成词向量，Q）</h1>\n<p>![image-20220614194418918](../../Library/Application Support/typora-user-images/image-20220614194418918.png)</p>\n<p>Word2Vec 模型是不是预训练模型？（是）</p>\n<p>一定是</p>\n<p>什么是预训练？</p>\n<p>给出两个任务 A 和 B，任务 A 已经做出了模型 A，任务 B 无法解决（通过使用模型 A，加快任务的解决）</p>\n<p>给你一个 NLP 里面的任务，给一个问题 X（Ni+ck），给出一个回答 Y（handsome）</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/we%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83.jpg\" alt=\"img\" /></p>\n<p>预训练语言模型终于出来（给出一句话，我们先使用独热编码（一一对应的一种表查询），再使用 Word2Vec 预训练好的 Q 矩阵直接得到词向量，然后进行接下来的任务）</p>\n<ol>\n<li>冻结：可以不改变 Q 矩阵</li>\n<li>微调：随着任务的改变，改变 Q 矩阵</li>\n</ol>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/Transformer/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/Transformer/",
            "title": "Transformer",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"框架概述\"><a class=\"anchor\" href=\"#框架概述\">#</a> 框架概述</h1>\n<p>1000*0.04=40--&gt;10</p>\n<p>5000*0.04=200--&gt;20</p>\n<p>预训练 --》NNLM--》word2Vec--》ELMo--》Attention</p>\n<p>NLP 中预训练的目的，其实就是为了生成词向量</p>\n<p>顺水推舟，transformer 其实就是 attention 的一个堆叠</p>\n<p>从一个宏观的角度，去看 transformer 到底在干嘛，然后在细分，再作总结</p>\n<p>总分总</p>\n<p>seq2seq</p>\n<p>一句话，一个视频</p>\n<p>序列（编码器）到序列（解码器）</p>\n<p>分成两部分，编码器和解码器</p>\n<h2 id=\"整体框架\"><a class=\"anchor\" href=\"#整体框架\">#</a> 整体框架</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5NSVCNCVFNCVCRCU5MyVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 整体框架.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:33%;&quot; /&gt;</p>\n<h2 id=\"机器翻译流程transformer\"><a class=\"anchor\" href=\"#机器翻译流程transformer\">#</a> 机器翻译流程（Transformer）</h2>\n<p>通过机器翻译来做解释</p>\n<p>给一个输入，给出一个输出（输出是输入的翻译的结果）</p>\n<p>“我是一个学生”  --》（通过 Transformer） I am a student</p>\n<p>流程 1</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-%E6%A1%86%E6%9E%B6%E7%AE%80%E5%8C%96.jpg\" alt=\"img\" /></p>\n<p>编码器和解码器</p>\n<p>编码器：把输入变成一个词向量（Self-Attetion）</p>\n<p>解码器：得到编码器输出的词向量后，生成翻译的结果</p>\n<p>流程 2</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLWVkLSVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-ed - 框架.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>Nx 的意思是，编码器里面又有 N 个小编码器（默认 N=6）</p>\n<p>通过 6 个编码器，对词向量一步又一步的强化（增强）</p>\n<p>流程 3</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLWVkLSVFNSVBNCU4RCVFNiU5RCU4Mi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-ed - 复杂.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>说了这么多，了解 Transformer 就是了解 Transformer 里的小的编码器（Encoder）和小的解码器（Decoder）</p>\n<p>FFN（Feed Forward）：w2(（w1x+b1）)+b2</p>\n<p>流程 4</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<h1 id=\"transformer-的编码器encodes我在做更优秀的词向量\"><a class=\"anchor\" href=\"#transformer-的编码器encodes我在做更优秀的词向量\">#</a> Transformer 的编码器（Encodes）—— 我在做更优秀的词向量</h1>\n<h2 id=\"transformer-框架\"><a class=\"anchor\" href=\"#transformer-框架\">#</a> Transformer 框架</h2>\n<p>seq（编码器）2seq（解码器）</p>\n<ol>\n<li>通过编码器对序列进行向量化（词向量）</li>\n<li>把词向量输入到解码器，得到结果（生成单词）</li>\n</ol>\n<h2 id=\"编码器概略图\"><a class=\"anchor\" href=\"#编码器概略图\">#</a> 编码器概略图</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>编码器包括两个子层，Self-Attention、Feed Forward</p>\n<p>每一个子层的传输过程中都会有一个（残差网络 + 归一化）</p>\n<h2 id=\"编码器详细图\"><a class=\"anchor\" href=\"#编码器详细图\">#</a> 编码器详细图</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VuY29kZXItJUU4JUFGJUE2JUU3JUJCJTg2JUU1JTlCJUJFLnBuZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/encoder - 详细图.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>Thinking</p>\n<p>--》得到绿色的 x1（词向量，可以通过 one-hot、word2vec 得到）+ 叠加位置编码（给 x1 赋予位置属性）得到黄色的 x1</p>\n<p>--》输入到 Self-Attention 子层中，做注意力机制（x1、x2 拼接起来的一句话做），得到 z1（x1 与 x1，x2 拼接起来的句子做了自注意力机制的词向量，表征的仍然是 thinking），也就是说 z1 拥有了位置特征、句法特征、语义特征的词向量</p>\n<p>--》残差网络（避免梯度消失，w3 (w2 (w1x+b1)+b2)+b3，如果 w1，w2，w3 特别小，0.0000000000000000……1，x 就没了，【w3 (w2 (w1x+b1)+b2)+b3+x】），归一化（LayerNorm），做标准化（避免梯度爆炸），得到了深粉色的 z1</p>\n<p>--》Feed Forward，Relu（w2 (w1x+b1)+b2），（前面每一步都在做线性变换，wx+b，线性变化的叠加永远都是线性变化（线性变化就是空间中平移和扩大缩小），通过 Feed Forward 中的 Relu 做一次非线性变换，这样的空间变换可以无限拟合任何一种状态了），得到 r1（是 thinking 的新的表征）</p>\n<p>总结下（这是重点，上面听不懂都没关系）：做词向量，只不过这个词向量更加优秀，让这个词向量能够更加精准的表示这个单词、这句话。</p>\n<h1 id=\"transformer-的解码器decoders我要生成一个又一个单词\"><a class=\"anchor\" href=\"#transformer-的解码器decoders我要生成一个又一个单词\">#</a> Transformer 的解码器（Decoders）—— 我要生成一个又一个单词</h1>\n<h2 id=\"transformer-编码器\"><a class=\"anchor\" href=\"#transformer-编码器\">#</a> Transformer 编码器</h2>\n<p>编码器在干吗：词向量、图片向量，总而言之，编码器就是让计算机能够更合理地（不确定性的）认识人类世界客观存在的一些东西</p>\n<h2 id=\"transformer-解码器\"><a class=\"anchor\" href=\"#transformer-解码器\">#</a> Transformer 解码器</h2>\n<p>解码器会接收编码器生成的词向量，然后通过这个词向量去生成翻译的结果。</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL2VkLSVFNyVCQiU4NiVFNSU4OCU4Ni5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ed - 细分.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>解码器的 Self-Attention 在编码已经生成的单词</p>\n<p>假如目标词 “我是一个学生”---》masked Self-Attention</p>\n<p>训练阶段：目标词 “我是一个学生” 是已知的，然后 Self-Attention 是对 “我是一个学生” 做计算</p>\n<p>如果不做 masked，每次训练阶段，都会获得全部的信息</p>\n<p>如果做 masked，Self-Attention 第一次对 “我” 做计算</p>\n<p>Self-Attention 第二次对 “我是” 做计算</p>\n<p>……</p>\n<p>测试阶段：</p>\n<ol>\n<li>目标词未知，假设目标词是 “我是一个学生”（未知），Self-Attention 第一次对 “我” 做计算</li>\n<li>第二次对 “我是” 做计算</li>\n<li>……</li>\n</ol>\n<p>而测试阶段，没生成一点，获得一点</p>\n<h2 id=\"生成词\"><a class=\"anchor\" href=\"#生成词\">#</a> 生成词</h2>\n<p>&lt;img src=&quot;../../ed - 交互.jpg&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>Linear 层转换成词表的维度</p>\n<p>softmax 得到最大词的概率</p>\n<p>softmax 细话</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5QyU4MCVFNSU5MCU4RSVFOCVCRSU5MyVFNSU4NyVCQS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 最后输出.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<p>单词表</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5QyU4MCVFNyVCQiU4OCVFOCVCRSU5MyVFNSU4NyVCQSVFNyVCQiU5MyVFNiU5RSU5Qy5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 最终输出结果.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;</p>\n<h1 id=\"transformer-的动态流程\"><a class=\"anchor\" href=\"#transformer-的动态流程\">#</a> Transformer 的动态流程</h1>\n<p>机器翻译：德语（中文）翻译成英文</p>\n<h2 id=\"生成一个词\"><a class=\"anchor\" href=\"#生成一个词\">#</a> 生成一个词</h2>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-%E5%8A%A8%E6%80%81%E7%94%9F%E6%88%90.gif\" alt=\"img\" /></p>\n<h2 id=\"生成所有词\"><a class=\"anchor\" href=\"#生成所有词\">#</a> 生成所有词</h2>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-%E5%8A%A8%E6%80%81%E7%BB%93%E6%9E%9C-2.gif\" alt=\"img\" /></p>\n<h2 id=\"transformer-框架-2\"><a class=\"anchor\" href=\"#transformer-框架-2\">#</a> Transformer 框架</h2>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf-%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6.jpg\" alt=\"img\" /></p>\n<h1 id=\"transformer-解码器的两个为什么为什么做掩码-为什么用编码器-解码器注意力\"><a class=\"anchor\" href=\"#transformer-解码器的两个为什么为什么做掩码-为什么用编码器-解码器注意力\">#</a> Transformer 解码器的两个为什么（为什么做掩码、为什么用编码器 - 解码器注意力）</h1>\n<h2 id=\"transformer-的编码器和解码器\"><a class=\"anchor\" href=\"#transformer-的编码器和解码器\">#</a> Transformer 的编码器和解码器</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3RmLSVFNiU5NSVCNCVFNCVCRCU5MyVFNiVBMSU4NiVFNiU5RSVCNi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/tf - 整体框架.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h2 id=\"问题一为什么-decoder-需要做-mask\"><a class=\"anchor\" href=\"#问题一为什么-decoder-需要做-mask\">#</a> 问题一：为什么 Decoder 需要做 Mask</h2>\n<p>机器翻译：源语句（我爱中国），目标语句（I love China）</p>\n<p>为了解决训练阶段和测试阶段的 gap（不匹配）</p>\n<p>训练阶段：解码器会有输入，这个输入是目标语句，就是 I love China，通过已经生成的词，去让解码器更好的生成（每一次都会把所有信息告诉解码器）</p>\n<p>测试阶段：解码器也会有输入，但是此时，测试的时候是不知道目标语句是什么的，这个时候，你每生成一个词，就会有多一个词放入目标语句中，每次生成的时候，都是已经生成的词（测试阶段只会把已经生成的词告诉解码器）</p>\n<p>为了匹配，为了解决这个 gap，masked Self-Attention 就登场了，我在训练阶段，我就做一个 masked，当你生成第一个词，我啥也不告诉你，当你生成第二个词，我告诉第一个词</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2stYXR0ZW50aW9uLW1hcC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h2 id=\"问题二为什么-encoder-给予-decoders-的是-k-v-矩阵\"><a class=\"anchor\" href=\"#问题二为什么-encoder-给予-decoders-的是-k-v-矩阵\">#</a> 问题二：为什么 Encoder 给予 Decoders 的是 K、V 矩阵</h2>\n<p>Q 来源解码器，K=V 来源于编码器</p>\n<p>Q 是查询变量，Q 是已经生成的词</p>\n<p>K=V 是源语句</p>\n<p>当我们生成这个词的时候，通过已经生成的词和源语句做自注意力，就是确定源语句中哪些词对接下来的词的生成更有作用，首先他就能找到当前生成词</p>\n<p>我爱中国</p>\n<p>通过部分（生成的词）去全部（源语句）的里面挑重点</p>\n<p>Q 是源语句，K，V 是已经生成的词，源语句去已经生成的词里找重点 ，找信息，已经生成的词里面压根就没有下一个词</p>\n<p>解决了以前的 seq2seq 框架的问题</p>\n<p>lstm 做编码器（得到词向量 C），再用 lstm 做解码器做生成</p>\n<p>用这种方法去生成词，每一次生成词，都是通过 C 的全部信息去生成</p>\n<p>很多信息对于当前生成词而言都是没有意义的</p>\n<p>用 Pytorch 去构建 Transformer 的源码（）</p>\n<h1 id=\"位置编码公式详细理解补充\"><a class=\"anchor\" href=\"#位置编码公式详细理解补充\">#</a> 位置编码公式详细理解补充</h1>\n<p>Self-Attention：对于每个词而言都是无位置关系，把每个词的顺序打乱，得到的注意力值依然不变</p>\n<p>通过 t1 告诉你，x1 是在前面，x2 在 x1 的后面</p>\n<ul>\n<li>位置编码</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSU5MCU5MSVFOSU4NyU4Ri5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置向量.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<ul>\n<li>位置编码公式</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU4NSVBQyVFNSVCQyU4Ri5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码公式.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>位置编码怎么用</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU5MiU4QyVFOCVBRiU4RCVFNSU5MCU5MSVFOSU4NyU4RiVFNCVCOSU4QiVFNSU5MiU4Qy5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码和词向量之和.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<ul>\n<li>位置编码底层解释</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSVCNSU4QyVFNSU4NSVBNSVFOCVBNyVBMyVFOSU4NyU4QS5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置嵌入解释.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>sin (pos+k) &#x3D; sin (pos)*cos (k) + cos (pos)*sin (k)  # sin 表示的是偶数维度</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>cos (pos+k) &#x3D; cos (pos) cos (k) - sin (pos)*sin (k)  # cos 表示的是奇数维度</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>他特别在 pos+k 是 pos 和 k 的线性组合</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>我爱你 ，现在我做第三个词 “你” 的位置编码</pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>pos &#x3D; 3 &#x3D; 1+2</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>pos + k &#x3D; 3 &#x3D;  1+2 &#x3D; 1*2+1*2</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>pos &#x3D; 10</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>1+9，2+8，3+7</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>这句话变成 “你爱我”，现在我们仍然做第三个词 “我” 的位置编码</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>pos &#x3D; 3 &#x3D; 1+2</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>pos + k &#x3D; 3 &#x3D;  1+2 &#x3D; 1*2+1*2</pre></td></tr></table></figure>",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88Attention%20%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88Attention%20%EF%BC%89/",
            "title": "注意力机制（Attention ）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"attention注意力机制\"><a class=\"anchor\" href=\"#attention注意力机制\">#</a> Attention（注意力机制）</h1>\n<p>你会注意什么？</p>\n<p>大数据（什么数据都有，重要的，不重要的）</p>\n<p>对于重要的数据，我们要使用</p>\n<p>对于不重要的数据，我们不太想使用</p>\n<p>但是，对于一个模型而言（CNN、LSTM），很难决定什么重要，什么不重要</p>\n<p>由此，注意力机制诞生了（有人发现了如何去在深度学习的模型上做注意力）</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/%E4%BA%BA%E7%B1%BB%E7%9A%84%E8%A7%86%E8%A7%89%E6%B3%A8%E6%84%8F%E5%8A%9B.jpg\" alt=\"img\" /></p>\n<p>红色的是科学家们发现，如果给你一张这个图，你眼睛的重点会聚焦在红色区域</p>\n<p>人 --》看脸</p>\n<p>文章看标题</p>\n<p>段落看开头</p>\n<p>后面的落款</p>\n<p>这些红色区域可能包含更多的信息，更重要的信息</p>\n<p>注意力机制：我们会把我们的焦点聚焦在比较重要的事物上</p>\n<h1 id=\"怎么做注意力\"><a class=\"anchor\" href=\"#怎么做注意力\">#</a> 怎么做注意力</h1>\n<p>我（查询对象 Q），这张图（被查询对象 V）</p>\n<p>我看这张图，第一眼，我就会去判断哪些东西对我而言更重要，哪些对我而言又更不重要（去计算 Q 和 V 里的事物的重要度）</p>\n<p>重要度计算，其实是不是就是相似度计算（更接近），点乘其实是求内积（不要关心为什么可以）</p>\n<p>Q，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo>=</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">K =k_1,k_2,\\cdots,k_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ，我们一般使用点乘的方式</p>\n<p>通过点乘的方法计算 Q 和 K 里的每一个事物的相似度，就可以拿到 Q 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">k_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的相似值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，Q 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">k_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的相似值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">s_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，Q 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">k_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的相似值 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>n</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>做一层 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>s</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">softmax(s_1,s_2,\\cdots,s_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 就可以得到概率<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(a_1,a_2,\\cdots,a_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p>进而就可以找出哪个对 Q 而言更重要了</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png\" alt=\"img\" /></p>\n<p>我们还得进行一个汇总，当你使用 Q 查询结束了后，Q 已经失去了它的使用价值了，我们最终还是要拿到这张图片的，只不过现在的这张图片，它多了一些信息（多了于我而言更重要，更不重要的信息在这里）</p>\n<p>V = <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(v_1,v_2,\\cdots,v_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo><mo>∗</mo><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>∗</mo><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><msub><mi>a</mi><mn>2</mn></msub><mo>∗</mo><msub><mi>v</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>a</mi><mi>n</mi></msub><mo>∗</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(a_1,a_2,\\cdots,a_n)*+(v_1,v_2,\\cdots,v_n)=(a_1*v_1+a_2*v_2+\\cdots+a_n*v_n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">+</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.61528em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.61528em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> = V'</p>\n<p>这样的话，就得到了一个新的 V'，这个新的 V' 就包含了，哪些更重要，哪些不重要的信息在里面，然后用 V' 代替 V</p>\n<p>一般 K=V，在 Transformer 里，K!=V 可不可以，可以的，但是 K 和 V 之间一定具有某种联系，这样的 QK 点乘才能指导 V 哪些重要，哪些不重要</p>\n<p>51， 49---》 0.51，0.49</p>\n<p>80/8，20/8 --》 0.9999999999， 0.0000000001</p>\n<h3 id=\"10-3-09-01\"><a class=\"anchor\" href=\"#10-3-09-01\">#</a> 10 / 3 --&gt; 0.9, 0.1</h3>\n<p>a1 和 a2 之间的差额越大，这个概率就越离谱</p>\n<h1 id=\"self-attention自注意力机制\"><a class=\"anchor\" href=\"#self-attention自注意力机制\">#</a> Self-Attention（自注意力机制）</h1>\n<h2 id=\"注意力机制\"><a class=\"anchor\" href=\"#注意力机制\">#</a> 注意力机制</h2>\n<p>看一个物体的时候，我们倾向于一些重点，把我们的焦点放到更重要的信息上</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCQSVCQSVFNyVCMSVCQiVFNyU5QSU4NCVFOCVBNyU4NiVFOCVBNyU4OSVFNiVCMyVBOCVFNiU4NCU4RiVFNSU4QSU5Qi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 人类的视觉注意力.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>第一眼看到这个图，不会说把所有的信息全部看完</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>QK 相乘求相似度，做一个 scale（未来做 softmax 的时候避免出现极端情况）</p>\n<p>然后做 Softmax 得到概率</p>\n<p>新的向量表示了 K 和 V（K==V），然后这种表示还暗含了 Q 的信息（于 Q 而言，K 里面重要的信息），也就是说，挑出了 K 里面的关键点</p>\n<h2 id=\"自-注意力机制self-attention向量\"><a class=\"anchor\" href=\"#自-注意力机制self-attention向量\">#</a> 自 - 注意力机制（Self-Attention）（向量）</h2>\n<p>Self-Attention 的关键点再于，不仅仅是 K<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>≈</mo></mrow><annotation encoding=\"application/x-tex\">\\approx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.48312em;vertical-align:0em;\"></span><span class=\"mrel\">≈</span></span></span></span>V<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>≈</mo></mrow><annotation encoding=\"application/x-tex\">\\approx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.48312em;vertical-align:0em;\"></span><span class=\"mrel\">≈</span></span></span></span>Q 来源于同一个 X，这三者是同源的</p>\n<p>通过 X 找到 X 里面的关键点</p>\n<p>并不是 K=V=Q=X，而是通过三个参数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>Q</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>K</mi></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mi>V</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_Q,W_K,W_V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>接下来的步骤和注意力机制一模一样</p>\n<ol>\n<li>\n<p>Q、K、V 的获取</p>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3Frdi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qkv.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n</li>\n<li>\n<p>Matmul：</p>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1EtSyVFNCVCOSU5OCVFNyVBNyVBRi5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/Q-K 乘积.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n</li>\n<li>\n<p>Scale+Softmax：</p>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3FrLXNjYWxlLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qk-scale.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n</li>\n<li>\n<h3 id=\"matmul\"><a class=\"anchor\" href=\"#matmul\">#</a> Matmul：</h3>\n<ol>\n<li>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3FrLXNvZnRtYXguanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qk-softmax.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</li>\n</ol>\n</li>\n</ol>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示的就是 thinking 的新的向量表示</p>\n<p>对于 thinking，初始词向量为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>现在我通过 thinking  machines 这句话去查询这句话里的每一个单词和 thinking 之间的相似度</p>\n<p>新的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">z_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 依然是 thinking 的词向量表示，只不过这个词向量的表示蕴含了 thinking machines 这句话对于 thinking 而言哪个更重要的信息</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLSVFNSVBNSVCRCVFNSVBNCU4NDIuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention - 好处 2.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:67%;&quot; /&gt;</p>\n<p>不做注意力，its 的词向量就是单纯的 its，没有任何附加信息</p>\n<blockquote>\n<p>也就是说 its 有 law 这层意思，而通过自注意力机制得到新的 its 的词向量，则会包含一定的 laws 和 application 的信息</p>\n</blockquote>\n<h2 id=\"自注意力机制矩阵\"><a class=\"anchor\" href=\"#自注意力机制矩阵\">#</a> 自注意力机制（矩阵）</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1FLVi0lRTclOUYlQTklRTklOTglQjUlRTglQTElQTglRTclQTQlQkEuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV - 矩阵表示.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL1FLVlotJUU3JUJCJTkzJUU2JTlFJTlDLmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKVZ - 结果.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNiVCMyVBOCVFNiU4NCU4RiVFNSU4QSU5QiVFNiU5QyVCQSVFNSU4OCVCNiVFNyU5RiVBOSVFOSU5OCVCNSVFNSU5QiVCRS5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 注意力机制矩阵图.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"self-attention相比较-rnn和lstm的优缺点\"><a class=\"anchor\" href=\"#self-attention相比较-rnn和lstm的优缺点\">#</a> Self-Attention 相比较 RNN 和 LSTM 的优缺点</h1>\n<h2 id=\"rnn\"><a class=\"anchor\" href=\"#rnn\">#</a> RNN</h2>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/RNN-unrolled.png\" alt=\"img\" /></p>\n<p>无法做长序列，当一段话达到 50 个字，效果很差了</p>\n<h2 id=\"lstm\"><a class=\"anchor\" href=\"#lstm\">#</a> LSTM</h2>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/LSTM%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84.jpg\" alt=\"img\" /></p>\n<p>LSTM 通过各种门，遗忘门，选择性的可以记忆之前的信息（200 词）</p>\n<h2 id=\"self-attention-和-rnns-的区别\"><a class=\"anchor\" href=\"#self-attention-和-rnns-的区别\">#</a> Self-Attention 和 RNNs 的区别</h2>\n<p>RNNs 长序列依赖问题，无法做并行</p>\n<p>Self-Attention 得到的新的词向量具有句法特征和语义特征（词向量的表征更完善）</p>\n<h3 id=\"句法特征\"><a class=\"anchor\" href=\"#句法特征\">#</a> 句法特征</h3>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLSVFNSVBNSVCRCVFNSVBNCU4NDEuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention - 好处 1.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:67%;&quot; /&gt;</p>\n<h3 id=\"语义特征\"><a class=\"anchor\" href=\"#语义特征\">#</a> 语义特征</h3>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3NlbGYtYXR0ZW50aW9uLSVFNSVBNSVCRCVFNSVBNCU4NDIuanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/self-attention - 好处 2.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h2 id=\"并行计算\"><a class=\"anchor\" href=\"#并行计算\">#</a> 并行计算</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL3FrLXNvZnRtYXguanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/qk-softmax.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"masked-self-attention掩码自注意力机制\"><a class=\"anchor\" href=\"#masked-self-attention掩码自注意力机制\">#</a> Masked Self-Attention（掩码自注意力机制）</h1>\n<h2 id=\"masked掩码-self-attention-在自注意力模型上面做了改进\"><a class=\"anchor\" href=\"#masked掩码-self-attention-在自注意力模型上面做了改进\">#</a> Masked（掩码） Self-Attention--》在自注意力模型上面做了改进</h2>\n<p>为什么要做这个改进：生成模型，生成单词，一个一个生成的</p>\n<p>当我们做生成任务的时候，我们也想对生成的这个单词做注意力计算，但是，生成的句子是一个一个单词生成的</p>\n<p>I have a dream</p>\n<ol>\n<li>\n<p>I  第一次注意力计算，只有 I</p>\n</li>\n<li>\n<p>I have 第二次，只有 I 和 have</p>\n</li>\n<li>\n<p>I have a</p>\n</li>\n<li>\n<p>I have a dream</p>\n</li>\n<li>\n<p>I have a dream &lt;eos&gt;</p>\n</li>\n</ol>\n<p>掩码自注意力机制应运而生</p>\n<p>掩码后 1</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2stYXR0ZW50aW9uLW1hcC5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>掩码后 2</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL21hc2stYXR0ZW50aW9uLW1hcC1zb2Z0bWF4LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>未来我们讲 Transformer 的时候会详细讲！</p>\n<p>Multi-head Self-Attention。</p>\n<h1 id=\"multi-head-self-attention从空间角度解释为什么做多头\"><a class=\"anchor\" href=\"#multi-head-self-attention从空间角度解释为什么做多头\">#</a> Multi-Head Self-Attention（从空间角度解释为什么做多头）</h1>\n<h2 id=\"multi-head-self-attention多头自注意力\"><a class=\"anchor\" href=\"#multi-head-self-attention多头自注意力\">#</a> Multi-Head Self-Attention（多头自注意力）</h2>\n<p>Z 相比较 X 有了提升，通过 Multi-Head Self-Attention，得到的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi><msup><mrow></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></mrow><annotation encoding=\"application/x-tex\">Z{&#x27;}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mord\"><span class=\"mord\"><span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span> 相比较 Z 又有了进一步提升</p>\n<p>多头自注意力，问题来了，多头是什么，多头的个数用 h 表示，一般<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">h=8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">8</span></span></span></span>，我们通常使用的是 8 头自注意力</p>\n<p>什么是多头</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL211bHRpLWhlYWQtYXR0ZW50aW9uLnBuZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-attention.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>如何多头 1</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLzgtaGVhZC1hdHRlbnRpb24uanBn\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/8-head-attention.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<p>对于 X，我们不是说，直接拿 X 去得到 Z，而是把 X 分成了 8 块（8 头），得到 Z0-Z7</p>\n<p>如何多头 2</p>\n<p>然后把 Z0-Z7 拼接起来，再做一次线性变换（改变维度）得到 Z</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/8-z-%E6%8B%BC%E6%8E%A5.jpg\" alt=\"img\" /></p>\n<p>有什么作用？</p>\n<p>机器学习的本质是什么：y=<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> (wx+b)，在做一件什么事情，非线性变换（把一个看起来不合理的东西，通过某个手段（训练模型），让这个东西变得合理）</p>\n<p>非线性变换的本质又是什么？改变空间上的位置坐标，任何一个点都可以在维度空间上找到，通过某个手段，让一个不合理的点（位置不合理），变得合理</p>\n<p>这就是词向量的本质</p>\n<p>one-hot 编码（0101010）</p>\n<p>word2vec（11，222，33）</p>\n<p>emlo（15，3，2）</p>\n<p>attention（124，2，32）</p>\n<p>multi-head attention（1231，23，3），把 X 切分成 8 块（8 个子空间），这样一个原先在一个位置上的 X，去了空间上 8 个位置，通过对 8 个点进行寻找，找到更合适的位置</p>\n<p>词向量的大小是 512</p>\n<p>假设你的任务，视频向量是 5120，80</p>\n<p>对计算机的性能提出了要求</p>\n<h2 id=\"多头流程图\"><a class=\"anchor\" href=\"#多头流程图\">#</a> 多头流程图</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HL211bHRpLWhlYWQtJUU2JThCJUJDJUU2JThFJUE1LmpwZw==\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head - 拼接.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h1 id=\"positional-encoding-为什么-self-attention-需要位置编码\"><a class=\"anchor\" href=\"#positional-encoding-为什么-self-attention-需要位置编码\">#</a> Positional Encoding （为什么 Self-Attention 需要位置编码）</h1>\n<h2 id=\"attention\"><a class=\"anchor\" href=\"#attention\">#</a> Attention</h2>\n<p>优点：</p>\n<ol>\n<li>解决了长序列依赖问题</li>\n<li>可以并行</li>\n</ol>\n<p>缺点：</p>\n<ol>\n<li>\n<p>开销变大了</p>\n</li>\n<li>\n<p>既然可以并行，也就是说，词与词之间不存在顺序关系（打乱一句话，这句话里的每个词的词向量依然不会变），即无位置关系（既然没有，我就加一个，通过位置编码的形式加）</p>\n</li>\n</ol>\n<p>位置编码的问题</p>\n<h2 id=\"为什么需要位置编码\"><a class=\"anchor\" href=\"#为什么需要位置编码\">#</a> 为什么需要位置编码</h2>\n<h2 id=\"位置编码怎么做的\"><a class=\"anchor\" href=\"#位置编码怎么做的\">#</a> 位置编码怎么做的</h2>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSU5MCU5MSVFOSU4NyU4Ri5qcGc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置向量.jpg</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h2 id=\"具体做法\"><a class=\"anchor\" href=\"#具体做法\">#</a> 具体做法</h2>\n<ul>\n<li>做法 1</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU4NSVBQyVFNSVCQyU4Ri5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码公式.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<ul>\n<li>做法 2</li>\n</ul>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNyVCQyU5NiVFNyVBMCU4MSVFNSU5MiU4QyVFOCVBRiU4RCVFNSU5MCU5MSVFOSU4NyU4RiVFNCVCOSU4QiVFNSU5MiU4Qy5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置编码和词向量之和.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n<h2 id=\"为什么这么做有用\"><a class=\"anchor\" href=\"#为什么这么做有用\">#</a> 为什么这么做有用</h2>\n<p>pos+K=5，我在计算第 5 个单词的位置编码的时候</p>\n<p>pos=1，k=4</p>\n<p>pos=2，k=3</p>\n<p>&lt;img src=&quot;<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbWdtZC5vc3MtY24tc2hhbmdoYWkuYWxpeXVuY3MuY29tL0JFUlRfSU1HLyVFNCVCRCU4RCVFNyVCRCVBRSVFNSVCNSU4QyVFNSU4NSVBNSVFOCVBNyVBMyVFOSU4NyU4QS5wbmc=\">https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/ 位置嵌入解释.png</span>&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</p>\n",
            "tags": [
                "NER"
            ]
        },
        {
            "id": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/08%20ELMo%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%8F%8C%E5%90%91LSTM%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E8%AF%8D%E5%90%91%E9%87%8F%E5%A4%9A%E4%B9%89%E9%97%AE%E9%A2%98%EF%BC%89/",
            "url": "http://qiji5211.com/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/08%20ELMo%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%8F%8C%E5%90%91LSTM%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E8%AF%8D%E5%90%91%E9%87%8F%E5%A4%9A%E4%B9%89%E9%97%AE%E9%A2%98%EF%BC%89/",
            "title": "ELMo模型（双向LSTM模型解决词向量多义问题）",
            "date_published": "2024-02-07T09:30:58.000Z",
            "content_html": "<h1 id=\"word2vec-模型\"><a class=\"anchor\" href=\"#word2vec-模型\">#</a> Word2Vec 模型</h1>\n<p>NNLM 模型（是不是在预测下一个词，副产品是词向量）</p>\n<p>Word2Vec 模型：专门做词向量</p>\n<ol>\n<li>CBOW</li>\n<li>Skip-gram</li>\n</ol>\n<p>![image-20220614193540503](../../Library/Application Support/typora-user-images/image-20220614193540503.png)</p>\n<p>apple，苹果，</p>\n<h1 id=\"elmo\"><a class=\"anchor\" href=\"#elmo\">#</a> ELMo</h1>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/we%E5%A4%9A%E4%B9%89%E8%AF%8D%E9%97%AE%E9%A2%98.jpg\" alt=\"img\" /></p>\n<p>elmo 解决多义词问题</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/word2vec.jpg\" alt=\"img\" /></p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/%E5%9F%BA%E4%BA%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84emedding.jpg\" alt=\"img\" /></p>\n<p>ELMo（专门做词向量，通过预训练）</p>\n<p>不只是训练一个 Q 矩阵，我还可以把这个次的上下文信息融入到这个 Q 矩阵中</p>\n<p>左边的 LSTM 获取 E2 的上文信息，右边就是下文信息</p>\n<p>x1,x2, x4,x5 --&gt; Word2Vec x1+x2+x4+x5 ---&gt; 预测那一个词</p>\n<p>获取上下文信息后，把三层的信息进行一个叠加</p>\n<p>E1+E2+E3 = K1 一个新的词向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>≈</mo></mrow><annotation encoding=\"application/x-tex\">\\approx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.48312em;vertical-align:0em;\"></span><span class=\"mrel\">≈</span></span></span></span> E1</p>\n<p>E2,E3 相当于两个上下文信息</p>\n<p>E1+E2+E3+E4</p>\n<p>K1 包含了第一个词的词向量包含单词特征、句法特征、语义特征</p>\n<p>怎么用</p>\n<p>E2，E3 不同，E1+E2+E3 不同</p>\n<p>apple --》 我吃了一个 苹果 -- 》 [1,20,10]</p>\n<p>apple --》我在用苹果手机 --》[1,10,20]</p>\n<p><img data-src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/elmo%E8%AE%AD%E7%BB%83%E5%90%8E%E7%9A%84%E4%BD%BF%E7%94%A8.jpg\" alt=\"img\" /></p>\n<p>LSTM 无法并行，长期依赖</p>\n<p>Attention</p>\n",
            "tags": [
                "NER"
            ]
        }
    ]
}